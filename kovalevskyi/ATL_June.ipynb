{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're looking at all June flights departing from ATL (Atlanta) between 2006 and 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME=os.environ['HOME']\n",
    "HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(HOME, \"workspace/data\")\n",
    "ALL_ATL_JUNE = os.path.join(DATA_DIR, 'atl_june.csv')\n",
    "TRAIN_FILE=os.path.join(DATA_DIR, 'atl_june_train.csv')\n",
    "TEST_FILE=os.path.join(DATA_DIR, 'atl_june_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403358"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_RECORDS = !cat $ALL_ATL_JUNE | wc -l\n",
    "NUM_RECORDS = int(NUM_RECORDS[0]) - 1\n",
    "NUM_TRAIN = 80000\n",
    "NUM_TEST = 1000\n",
    "NUM_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_YEAR</th>\n",
       "      <th>FL_MONTH</th>\n",
       "      <th>FL_DOM</th>\n",
       "      <th>FL_DOW</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_CODE</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>8.000000e+04</td>\n",
       "      <td>8.000000e+04</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011.408238</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.570662</td>\n",
       "      <td>3.958788</td>\n",
       "      <td>2314.884613</td>\n",
       "      <td>1.039704e+06</td>\n",
       "      <td>1.278425e+06</td>\n",
       "      <td>1461.624937</td>\n",
       "      <td>15.034200</td>\n",
       "      <td>20.634438</td>\n",
       "      <td>1489.702075</td>\n",
       "      <td>1515.102238</td>\n",
       "      <td>6.061637</td>\n",
       "      <td>1552.658788</td>\n",
       "      <td>11.969088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>644.620450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.441472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.632857</td>\n",
       "      <td>1.967826</td>\n",
       "      <td>1825.793593</td>\n",
       "      <td>9.996253e-01</td>\n",
       "      <td>1.520593e+05</td>\n",
       "      <td>463.718150</td>\n",
       "      <td>38.671364</td>\n",
       "      <td>11.416061</td>\n",
       "      <td>498.195315</td>\n",
       "      <td>540.071555</td>\n",
       "      <td>4.558473</td>\n",
       "      <td>501.811703</td>\n",
       "      <td>41.843313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>471.980764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2006.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.039703e+06</td>\n",
       "      <td>1.013501e+06</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2008.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>864.750000</td>\n",
       "      <td>1.039703e+06</td>\n",
       "      <td>1.129802e+06</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1128.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1148.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "      <td>1.039703e+06</td>\n",
       "      <td>1.294502e+06</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1512.000000</td>\n",
       "      <td>1537.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1558.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4317.000000</td>\n",
       "      <td>1.039705e+06</td>\n",
       "      <td>1.410001e+06</td>\n",
       "      <td>1859.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1927.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>743.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7425.000000</td>\n",
       "      <td>1.039705e+06</td>\n",
       "      <td>1.591902e+06</td>\n",
       "      <td>2350.000000</td>\n",
       "      <td>1207.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1221.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4502.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FL_YEAR  FL_MONTH        FL_DOM        FL_DOW        FL_NUM  \\\n",
       "count  80000.000000   80000.0  80000.000000  80000.000000  80000.000000   \n",
       "mean    2011.408238       6.0     15.570662      3.958788   2314.884613   \n",
       "std        3.441472       0.0      8.632857      1.967826   1825.793593   \n",
       "min     2006.000000       6.0      1.000000      1.000000      1.000000   \n",
       "25%     2008.000000       6.0      8.000000      2.000000    864.750000   \n",
       "50%     2011.000000       6.0     16.000000      4.000000   1704.000000   \n",
       "75%     2014.000000       6.0     23.000000      6.000000   4317.000000   \n",
       "max     2017.000000       6.0     30.000000      7.000000   7425.000000   \n",
       "\n",
       "       ORIGIN_AIRPORT_SEQ_ID  DEST_AIRPORT_SEQ_ID  CRS_DEP_TIME     DEP_DELAY  \\\n",
       "count           8.000000e+04         8.000000e+04  80000.000000  80000.000000   \n",
       "mean            1.039704e+06         1.278425e+06   1461.624937     15.034200   \n",
       "std             9.996253e-01         1.520593e+05    463.718150     38.671364   \n",
       "min             1.039703e+06         1.013501e+06    530.000000    -54.000000   \n",
       "25%             1.039703e+06         1.129802e+06   1035.000000     -3.000000   \n",
       "50%             1.039703e+06         1.294502e+06   1455.000000      0.000000   \n",
       "75%             1.039705e+06         1.410001e+06   1859.000000     15.000000   \n",
       "max             1.039705e+06         1.591902e+06   2350.000000   1207.000000   \n",
       "\n",
       "           TAXI_OUT    WHEELS_OFF     WHEELS_ON       TAXI_IN  CRS_ARR_TIME  \\\n",
       "count  80000.000000  80000.000000  80000.000000  80000.000000  80000.000000   \n",
       "mean      20.634438   1489.702075   1515.102238      6.061637   1552.658788   \n",
       "std       11.416061    498.195315    540.071555      4.558473    501.811703   \n",
       "min        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%       14.000000   1051.000000   1128.000000      4.000000   1148.000000   \n",
       "50%       18.000000   1512.000000   1537.000000      5.000000   1558.000000   \n",
       "75%       24.000000   1927.000000   1950.000000      7.000000   2000.000000   \n",
       "max      221.000000   2400.000000   2400.000000    154.000000   2359.000000   \n",
       "\n",
       "          ARR_DELAY  CANCELLED  CANCELLATION_CODE  DIVERTED      DISTANCE  \n",
       "count  80000.000000    80000.0                0.0   80000.0  80000.000000  \n",
       "mean      11.969088        0.0                NaN       0.0    644.620450  \n",
       "std       41.843313        0.0                NaN       0.0    471.980764  \n",
       "min      -51.000000        0.0                NaN       0.0     79.000000  \n",
       "25%      -10.000000        0.0                NaN       0.0    356.000000  \n",
       "50%       -1.000000        0.0                NaN       0.0    547.000000  \n",
       "75%       16.000000        0.0                NaN       0.0    743.000000  \n",
       "max     1221.000000        0.0                NaN       0.0   4502.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ALL_ATL_JUNE)\n",
    "df_sample = df.sample(frac=1.0, random_state=1) # pd.sample() also shuffles the records\n",
    "df_sample[:NUM_TRAIN].to_csv(TRAIN_FILE, index=False)\n",
    "df_sample[NUM_TRAIN: NUM_TRAIN + NUM_TEST].to_csv(TEST_FILE, index=False)\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "df_test = pd.read_csv(TEST_FILE)\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_YEAR</th>\n",
       "      <th>FL_MONTH</th>\n",
       "      <th>FL_DOM</th>\n",
       "      <th>FL_DOW</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_CODE</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2011.324000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.821000</td>\n",
       "      <td>3.910000</td>\n",
       "      <td>2303.853000</td>\n",
       "      <td>1.039704e+06</td>\n",
       "      <td>1.276233e+06</td>\n",
       "      <td>1450.721000</td>\n",
       "      <td>14.46700</td>\n",
       "      <td>20.545000</td>\n",
       "      <td>1474.533000</td>\n",
       "      <td>1495.111000</td>\n",
       "      <td>6.047000</td>\n",
       "      <td>1548.802000</td>\n",
       "      <td>11.156000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>657.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.413308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.683453</td>\n",
       "      <td>1.977324</td>\n",
       "      <td>1828.160539</td>\n",
       "      <td>9.966189e-01</td>\n",
       "      <td>1.493613e+05</td>\n",
       "      <td>462.847873</td>\n",
       "      <td>35.83821</td>\n",
       "      <td>11.331389</td>\n",
       "      <td>501.343349</td>\n",
       "      <td>542.315992</td>\n",
       "      <td>3.996594</td>\n",
       "      <td>497.349923</td>\n",
       "      <td>39.101184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>526.401998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2006.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.039703e+06</td>\n",
       "      <td>1.013503e+06</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>-47.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2008.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>871.750000</td>\n",
       "      <td>1.039703e+06</td>\n",
       "      <td>1.130801e+06</td>\n",
       "      <td>1020.750000</td>\n",
       "      <td>-3.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1043.000000</td>\n",
       "      <td>1115.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1140.750000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1673.000000</td>\n",
       "      <td>1.039703e+06</td>\n",
       "      <td>1.289201e+06</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1507.500000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4344.500000</td>\n",
       "      <td>1.039705e+06</td>\n",
       "      <td>1.409802e+06</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1907.250000</td>\n",
       "      <td>1928.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1944.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7348.000000</td>\n",
       "      <td>1.039705e+06</td>\n",
       "      <td>1.591902e+06</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>317.00000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4502.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FL_YEAR  FL_MONTH       FL_DOM       FL_DOW       FL_NUM  \\\n",
       "count  1000.000000    1000.0  1000.000000  1000.000000  1000.000000   \n",
       "mean   2011.324000       6.0    15.821000     3.910000  2303.853000   \n",
       "std       3.413308       0.0     8.683453     1.977324  1828.160539   \n",
       "min    2006.000000       6.0     1.000000     1.000000     1.000000   \n",
       "25%    2008.000000       6.0     8.000000     2.000000   871.750000   \n",
       "50%    2011.000000       6.0    16.000000     4.000000  1673.000000   \n",
       "75%    2014.000000       6.0    23.000000     6.000000  4344.500000   \n",
       "max    2017.000000       6.0    30.000000     7.000000  7348.000000   \n",
       "\n",
       "       ORIGIN_AIRPORT_SEQ_ID  DEST_AIRPORT_SEQ_ID  CRS_DEP_TIME   DEP_DELAY  \\\n",
       "count           1.000000e+03         1.000000e+03   1000.000000  1000.00000   \n",
       "mean            1.039704e+06         1.276233e+06   1450.721000    14.46700   \n",
       "std             9.966189e-01         1.493613e+05    462.847873    35.83821   \n",
       "min             1.039703e+06         1.013503e+06    620.000000   -47.00000   \n",
       "25%             1.039703e+06         1.130801e+06   1020.750000    -3.00000   \n",
       "50%             1.039703e+06         1.289201e+06   1450.000000     0.00000   \n",
       "75%             1.039705e+06         1.409802e+06   1850.000000    14.00000   \n",
       "max             1.039705e+06         1.591902e+06   2336.000000   317.00000   \n",
       "\n",
       "          TAXI_OUT   WHEELS_OFF    WHEELS_ON      TAXI_IN  CRS_ARR_TIME  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000   1000.000000   \n",
       "mean     20.545000  1474.533000  1495.111000     6.047000   1548.802000   \n",
       "std      11.331389   501.343349   542.315992     3.996594    497.349923   \n",
       "min       0.000000     2.000000     3.000000     0.000000      5.000000   \n",
       "25%      14.000000  1043.000000  1115.000000     4.000000   1140.750000   \n",
       "50%      18.000000  1507.500000  1522.000000     5.000000   1600.000000   \n",
       "75%      24.000000  1907.250000  1928.250000     7.000000   1944.000000   \n",
       "max     126.000000  2359.000000  2400.000000    52.000000   2359.000000   \n",
       "\n",
       "         ARR_DELAY  CANCELLED  CANCELLATION_CODE  DIVERTED     DISTANCE  \n",
       "count  1000.000000     1000.0                0.0    1000.0  1000.000000  \n",
       "mean     11.156000        0.0                NaN       0.0   657.659000  \n",
       "std      39.101184        0.0                NaN       0.0   526.401998  \n",
       "min     -55.000000        0.0                NaN       0.0    83.000000  \n",
       "25%     -10.000000        0.0                NaN       0.0   341.000000  \n",
       "50%      -1.000000        0.0                NaN       0.0   547.000000  \n",
       "75%      15.000000        0.0                NaN       0.0   745.000000  \n",
       "max     307.000000        0.0                NaN       0.0  4502.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Was already closed or didn't exist. That's fine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    print(\"OK. Was already closed or didn't exist. That's fine.\")\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Tensorflow input_function\n",
    "An input function is a function that takes no arguments and returns a graph that produces records from a dataset or its iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = ['FL_DATE', 'FL_YEAR', 'FL_MONTH', 'FL_DOM', 'FL_DOW', 'UNIQUE_CARRIER', 'FL_NUM',\n",
    "       'ORIGIN_AIRPORT_SEQ_ID', 'DEST_AIRPORT_SEQ_ID', 'ORIGIN', 'DEST',\n",
    "       'CRS_DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON',\n",
    "       'TAXI_IN', 'CRS_ARR_TIME', 'ARR_DELAY', 'CANCELLED',\n",
    "       'CANCELLATION_CODE', 'DIVERTED', 'DISTANCE']\n",
    "SELECT_COLUMNS=[1,4, 5,10,11,12,17,18,22]\n",
    "SELECT_FEATURES = ['FL_YEAR', 'FL_DOW', 'UNIQUE_CARRIER', 'DEST', 'CRS_DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'DISTANCE']\n",
    "DEFAULTS = [[\"-\"], [], [], [], [], [\"-\"], [\"-\"], [\"-\"], [\"-\"], [\"-\"], [\"-\"], [], [], [], [], [], [], [], [], [], ['NONE'], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decode_csv(col_names, select_indexes, defaults, label_name) :\n",
    "    selected_defaults = [defaults[i] for i in select_indexes]\n",
    "    def _decode_csv(row): \n",
    "        cols = tf.decode_csv(row, select_cols=select_indexes, \n",
    "                             record_defaults=selected_defaults)\n",
    "        decoded = dict(zip([col_names[i] for i in select_indexes], cols))\n",
    "        label = decoded.pop(label_name)\n",
    "        return decoded, label\n",
    "    return _decode_csv\n",
    "\n",
    "        \n",
    "def make_input_fn(file_name, headers, col_names, label_name, indexes, defaults, transform=None, batch_size=1, repeat=1):\n",
    "    \n",
    "    decode_csv = make_decode_csv(col_names, indexes, defaults, label_name)\n",
    "    \n",
    "    def _input_fn():\n",
    "        text_lines = tf.data.TextLineDataset(file_name)\n",
    "        if headers:\n",
    "            text_lines=text_lines.skip(1)\n",
    "        decoded = text_lines.map(decode_csv)\n",
    "\n",
    "        if transform is not None:\n",
    "            decoded = decoded.map(transform)\n",
    "        \n",
    "        features = decoded.repeat(repeat).batch(batch_size).make_one_shot_iterator().get_next()\n",
    "        return features\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "See how lines of csv are parsed into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = [tf.constant([0]), tf.constant([0]), tf.constant(['CHF'])]\n",
    "decode_csv = make_decode_csv(['a', 'b', 'c'], [0,1,2], defaults, 'c')\n",
    "row = tf.constant([\"10,20,Dollar\", \"20,30,SGD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, labels = decode_csv(row)\n",
    "feats['a'].eval(), labels.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "Any additional transformation like e.g. one-hot encoding or bucketizing is done in this transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(feats, labels):\n",
    "    \n",
    "    dow = feats['FL_DOW']\n",
    "    dow = tf.cast(dow, tf.int64)\n",
    "    dow_hot = tf.one_hot(dow-1, 7, dtype=tf.int64)\n",
    "    feats['FL_DOW'] = dow_hot\n",
    "\n",
    "    dep_time = feats['CRS_DEP_TIME'] / 100.0\n",
    "    dep_time = tf.cast(dep_time, tf.int64)\n",
    "    dt_hot = tf.one_hot(dep_time, 24, dtype=tf.int64)\n",
    "    feats['CRS_DEP_TIME'] = dt_hot\n",
    "    \n",
    "    arr_time = feats['CRS_ARR_TIME'] / 100.0\n",
    "    arr_time = tf.cast(arr_time, tf.int64)\n",
    "    at_hot = tf.one_hot(arr_time, 24, dtype=tf.int64)\n",
    "    feats['CRS_ARR_TIME'] = at_hot\n",
    "\n",
    "    dist = feats['DISTANCE'] / 1000.0\n",
    "    feats['DISTANCE'] = dist\n",
    "    \n",
    "    dep_d = feats['DEP_DELAY']\n",
    "    feats['DEP_DELAY'] = dep_d\n",
    "    \n",
    "    return feats, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "The input function returns a pair consisting of a dictionary of input tensors and a label tensor.\n",
    "These tensors are actually datasets, that produce the respective next batch, when evaluated. That's how we avoid loading the entire dataset into memory for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = make_input_fn(TRAIN_FILE,\n",
    "    True, COLUMNS, 'ARR_DELAY', SELECT_COLUMNS, DEFAULTS, transform, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, delay = input_fn()\n",
    "all_tensors = [feats[name] for name in SELECT_FEATURES]\n",
    "all_tensors.append(delay)\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(2):\n",
    "        print(sess.run(all_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare that to what the equivalent pandas dataframe shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[0:4][['FL_YEAR', 'FL_DOW', 'UNIQUE_CARRIER', 'DEST', 'CRS_DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'ARR_DELAY', 'DISTANCE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! That seems to work! The input function produces the same values that we can see in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "First, we'll only be looking at departure delay and distance to destination to predict arrival delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_dep_delay = fc.numeric_column('DEP_DELAY', dtype=tf.float32)\n",
    "fc_distance = fc.numeric_column('DISTANCE', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = tf.estimator.LinearRegressor(feature_columns=[fc_dep_delay, fc_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_fn = make_input_fn(TEST_FILE,\n",
    "    True, COLUMNS, 'ARR_DELAY', SELECT_COLUMNS, DEFAULTS, transform, NUM_TEST, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = make_input_fn(TRAIN_FILE,\n",
    "    True, COLUMNS, 'ARR_DELAY', SELECT_COLUMNS, DEFAULTS, transform, BATCH_SIZE, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "Let's see whether our forecast is any good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(pred, test_file, num_test):\n",
    "    \"\"\"\n",
    "    pred: the result of regressor.predict()\n",
    "    test_file\n",
    "    \"\"\"\n",
    "    dataframe=pd.read_csv(test_file)\n",
    "    predicted = [pred.next()['predictions'][0] for i in range (num_test)]\n",
    "    np_pred = np.array(predicted)\n",
    "    lbls = list(dataframe[0:num_test]['ARR_DELAY'])\n",
    "    np_lbls = np.array(lbls)\n",
    "    avg_err = np.average(np.abs(np_lbls - np_pred))\n",
    "    rmse = np.sqrt(np.average(np.square(np_lbls - np_pred)))\n",
    "    pd.DataFrame(np_lbls - np_pred).plot.hist(bins=40)\n",
    "    print\n",
    "    print(\"Average error: {}, RMSE: {}\". format(avg_err, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_fn = make_input_fn(\n",
    "    TEST_FILE, True, COLUMNS, 'ARR_DELAY', \n",
    "    SELECT_COLUMNS, DEFAULTS, transform, NUM_TEST, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = regressor.predict(pred_input_fn)\n",
    "test_prediction(res, TEST_FILE, NUM_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking more features into account\n",
    "We see that predictions are not too shabby, however we may get better by taking day of week and time of departure and arrival into account..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_crs_dep_time = fc.categorical_column_with_identity('CRS_DEP_TIME', 24)\n",
    "fc_crs_arr_time = fc.categorical_column_with_identity('CRS_ARR_TIME', 24)\n",
    "fc_dow = fc.categorical_column_with_identity('FL_DOW', 7)\n",
    "\n",
    "feature_columns=[\n",
    "    fc_dep_delay, \n",
    "    fc_distance, \n",
    "    fc_crs_dep_time, \n",
    "    fc_crs_arr_time,\n",
    "    fc_dow]\n",
    "\n",
    "regressor2 = tf.estimator.LinearRegressor(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor2.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = regressor2.predict(pred_input_fn)\n",
    "test_prediction(res, TEST_FILE, NUM_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
