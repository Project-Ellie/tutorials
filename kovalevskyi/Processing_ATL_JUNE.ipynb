{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n",
      "/usr/local/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: ImportWarning: Not importing directory '/usr/local/lib/python2.7/site-packages/scipy/spatial/qhull': missing __init__.py\n",
      "  from .qhull import *\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/usr/local/lib/python2.7/site-packages/scipy/optimize/_minimize.py:37: ImportWarning: Not importing directory '/usr/local/lib/python2.7/site-packages/scipy/optimize/lbfgsb': missing __init__.py\n",
      "  from .lbfgsb import _minimize_lbfgsb\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/cluster/supervised.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py:31: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import tempfile\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import apache_beam as beam\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam.impl as beam_impl\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "import google.datalab.bigquery as dlbq\n",
    "\n",
    "from tools import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT='going-tfx'\n",
    "BUCKET='going-tfx'\n",
    "DATASET='examples'\n",
    "TMPDIR='/tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Raw data in Bigquery\n",
    "We collected the raw data that we use from various sources into a single denormalized table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>...</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_T</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_W</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-06-01</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>US Airways Inc.: US (Merged with America West ...</td>\n",
       "      <td>610</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>712</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>CLT</td>\n",
       "      <td>35.21</td>\n",
       "      <td>-80.94</td>\n",
       "      <td>CHARLOTTE/DOUGLAS INTERNATION</td>\n",
       "      <td>78.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-06-01</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>620</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>749</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ORF</td>\n",
       "      <td>36.89</td>\n",
       "      <td>-76.20</td>\n",
       "      <td>NORFOLK REGIONAL ARPT</td>\n",
       "      <td>80.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-06-01</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>620</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>740</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MCO</td>\n",
       "      <td>28.42</td>\n",
       "      <td>-81.30</td>\n",
       "      <td>ORLANDO INTERNATIONAL AIRPORT</td>\n",
       "      <td>77.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  YEAR  MONTH  DAY  DEP_DOW  \\\n",
       "0  2002-06-01  2002      6    1        7   \n",
       "1  2002-06-01  2002      6    1        7   \n",
       "2  2002-06-01  2002      6    1        7   \n",
       "\n",
       "                                             AIRLINE  DEP_T  DEP  DEP_LAT  \\\n",
       "0  US Airways Inc.: US (Merged with America West ...    610  ATL    33.63   \n",
       "1                           Delta Air Lines Inc.: DL    620  ATL    33.63   \n",
       "2                           Delta Air Lines Inc.: DL    620  ATL    33.63   \n",
       "\n",
       "   DEP_LON     ...       WND_SPD_DEP ARR_T  ARR_DELAY  ARR  ARR_LAT  ARR_LON  \\\n",
       "0   -84.42     ...               6.9   712      -12.0  CLT    35.21   -80.94   \n",
       "1   -84.42     ...               6.9   749       -1.0  ORF    36.89   -76.20   \n",
       "2   -84.42     ...               6.9   740        9.0  MCO    28.42   -81.30   \n",
       "\n",
       "                           ARR_W MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  \n",
       "0  CHARLOTTE/DOUGLAS INTERNATION          78.3           9.5          2.7  \n",
       "1          NORFOLK REGIONAL ARPT          80.9           9.7          9.4  \n",
       "2  ORLANDO INTERNATIONAL AIRPORT          77.4           9.6          5.7  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery aj_sample\n",
    "select * FROM `going-tfx.examples.ATL_JUNE_RAW` limit 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'YEAR', 'MONTH', 'DAY', 'DEP_DOW', 'AIRLINE', 'DEP_T', 'DEP', 'DEP_LAT', 'DEP_LON', 'DEP_DELAY', 'DEP_W', 'MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', 'ARR_T', 'ARR_DELAY', 'ARR', 'ARR_LAT', 'ARR_LON', 'ARR_W', 'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR']\n"
     ]
    }
   ],
   "source": [
    "ALL_COLUMNS = [str(key) for key in aj_sample.keys()]\n",
    "print(ALL_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_COLUMNS = ALL_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Repeatable random subsets \n",
    "\n",
    "### Here's how we create repeatable random subsets for training, evaluation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_query(total, lower, upper):\n",
    "    return \"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM `going-tfx.examples.ATL_JUNE_RAW` \n",
    "\n",
    "        where\n",
    "          MOD(ABS(FARM_FINGERPRINT(\n",
    "            CONCAT(DATE,AIRLINE,ARR)\n",
    "          )) + DEP_T, {0}) >= {1} \n",
    "        and\n",
    "          MOD(ABS(FARM_FINGERPRINT(\n",
    "            CONCAT( DATE, AIRLINE, ARR)\n",
    "           )) + DEP_T, {0}) < {2} \n",
    "    \"\"\".format(total, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_queries(fractions, rate=0.1):\n",
    "    start = 0\n",
    "    total = int(sum(fractions) / rate)\n",
    "    res = []\n",
    "    for f in fractions:\n",
    "        f_ = int(f) \n",
    "        q = sample_query(total, start, start+f_)\n",
    "        start = start + f_\n",
    "        res.append(q)\n",
    "    return dict(zip(['train', 'eval', 'test'], res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = sample_queries([80,10,10], .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT\n",
      "            *\n",
      "        FROM `going-tfx.examples.ATL_JUNE_RAW` \n",
      "\n",
      "        where\n",
      "          MOD(ABS(FARM_FINGERPRINT(\n",
      "            CONCAT(DATE,AIRLINE,ARR)\n",
      "          )) + DEP_T, 1000) >= 80 \n",
      "        and\n",
      "          MOD(ABS(FARM_FINGERPRINT(\n",
      "            CONCAT( DATE, AIRLINE, ARR)\n",
      "           )) + DEP_T, 1000) < 90 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(queries['eval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â A super-small random subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 40 examples. Showing first three:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>...</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_T</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_W</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-06-07</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>842</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>949</td>\n",
       "      <td>16.0</td>\n",
       "      <td>SAV</td>\n",
       "      <td>32.12</td>\n",
       "      <td>-81.20</td>\n",
       "      <td>SAVANNAH/HILTON HEAD INTL AIR</td>\n",
       "      <td>79.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>2130</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2354</td>\n",
       "      <td>45.0</td>\n",
       "      <td>PVD</td>\n",
       "      <td>41.72</td>\n",
       "      <td>-71.42</td>\n",
       "      <td>PROVIDENCE T F GREEN ARPT</td>\n",
       "      <td>74.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-06-22</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>America West Airlines Inc.: HP (Merged with US...</td>\n",
       "      <td>805</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>916</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>PHX</td>\n",
       "      <td>33.43</td>\n",
       "      <td>-112.01</td>\n",
       "      <td>PHOENIX SKY HARBOR INTL AIRPO</td>\n",
       "      <td>102.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  YEAR  MONTH  DAY  DEP_DOW  \\\n",
       "0  2004-06-07  2004      6    7        2   \n",
       "1  2006-06-27  2006      6   27        3   \n",
       "2  2005-06-22  2005      6   22        4   \n",
       "\n",
       "                                             AIRLINE  DEP_T  DEP  DEP_LAT  \\\n",
       "0                           Delta Air Lines Inc.: DL    842  ATL    33.63   \n",
       "1                           Delta Air Lines Inc.: DL   2130  ATL    33.63   \n",
       "2  America West Airlines Inc.: HP (Merged with US...    805  ATL    33.63   \n",
       "\n",
       "   DEP_LON     ...       WND_SPD_DEP ARR_T  ARR_DELAY  ARR  ARR_LAT  ARR_LON  \\\n",
       "0   -84.42     ...               4.4   949       16.0  SAV    32.12   -81.20   \n",
       "1   -84.42     ...               6.3  2354       45.0  PVD    41.72   -71.42   \n",
       "2   -84.42     ...               6.1   916      -25.0  PHX    33.43  -112.01   \n",
       "\n",
       "                           ARR_W MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  \n",
       "0  SAVANNAH/HILTON HEAD INTL AIR          79.4           9.8          5.7  \n",
       "1      PROVIDENCE T F GREEN ARPT          74.7          10.0         10.1  \n",
       "2  PHOENIX SKY HARBOR INTL AIRPO         102.4          10.0          8.5  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_query = sample_query(10000, 0, 1)\n",
    "sample = dlbq.Query(tiny_query).execute().result().to_dataframe()\n",
    "print('Only {} examples. Showing first three:'.format(len(sample)))\n",
    "sample[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Reading from Bigquery into a beam pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_COLUMNS = ['DATE', 'AIRLINE', 'DEP', 'DEP_W', 'ARR', 'ARR_W']\n",
    "INT_COLUMNS = ['YEAR', 'MONTH', 'DAY', 'DEP_DOW', 'DEP_T', 'ARR_T']\n",
    "FLOAT_COLUMNS = ['DEP_LAT', 'DEP_LON', 'DEP_DELAY', 'MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', 'ARR_DELAY', 'ARR_LAT', 'ARR_LON', 'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_schema = {}\n",
    "\n",
    "for t, cols in [(tf.string, STRING_COLUMNS), (tf.float32, FLOAT_COLUMNS), (tf.int64, INT_COLUMNS)]:\n",
    "    raw_data_schema.update({\n",
    "        col : dataset_schema.ColumnSchema(t, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for col in cols})\n",
    "raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema(raw_data_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_test_mode = True\n",
    "OUTPUT_DIR=\"./out\"\n",
    "job_name = 'tft_tutorial' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "\n",
    "options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': job_name,\n",
    "    'project': PROJECT,\n",
    "    'max_num_workers': 24,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True,\n",
    "    'requirements_file': 'requirements.txt'\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "if in_test_mode:\n",
    "    RUNNER = 'DirectRunner'\n",
    "else:\n",
    "    RUNNER = 'DataflowRunner'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Developing the pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### This simple pipeline reads, transforms and emits the result into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_pipeline(query, preprocessing_fn, output_columns, out_name = 'atl_june_transformed', write_header=False):\n",
    "    \n",
    "    header=\",\".join(output_columns) if write_header else None\n",
    "    \n",
    "    out_prefix = os.path.join(TMPDIR, out_name)\n",
    "    with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "        with beam_impl.Context(temp_dir=tempfile.mkdtemp()):\n",
    "            \n",
    "            \n",
    "            #   Read from Big Query\n",
    "            #\n",
    "            raw_data = p | \"ReadFromBigQuery\"  >> beam.io.Read(beam.io.BigQuerySource(query=query, use_standard_sql=True)) \n",
    "            raw_dataset = (raw_data, raw_data_metadata)\n",
    "\n",
    "            \n",
    "            #   Analyze and transform by calling a single function that has all the tft.transforms in it\n",
    "            #\n",
    "            t_dataset, t_fn = (raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "            t_data, t_metadata = t_dataset\n",
    "            \n",
    "            \n",
    "            # Encode back to CSV file(s)\n",
    "            #\n",
    "            csv_encode = tft.coders.CsvCoder(output_columns, t_metadata.schema).encode    \n",
    "            res = (t_data \n",
    "                   | beam.Map(csv_encode)\n",
    "                   | beam.io.WriteToText(file_path_prefix=out_prefix, header=header))\n",
    "\n",
    "            \n",
    "    # Return a pandas dataframe containing the result\n",
    "    #\n",
    "    resfile = !ls $TMPDIR | grep $out_name\n",
    "    resfile = resfile[0]\n",
    "    resfile = os.path.join(TMPDIR, resfile)\n",
    "    return pd.read_csv(resfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 1: Do nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing(inputs):\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/apache_beam/runners/direct/direct_runner.py:360: DeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  pipeline.replace_all(_get_transform_overrides(pipeline.options))\n",
      "WARNING:root:Dataset going-tfx:temp_dataset_66722c25887b4c25980ec0bac414cd8b does not exist so we will create it as temporary with location=US\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>...</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_T</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_W</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-14</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1405</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1529</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>TPA</td>\n",
       "      <td>27.97</td>\n",
       "      <td>-82.53</td>\n",
       "      <td>TAMPA INTERNATIONAL AIRPORT</td>\n",
       "      <td>82.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-06-27</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>ExpressJet Airlines Inc.: EV</td>\n",
       "      <td>1025</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1047</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>PNS</td>\n",
       "      <td>30.47</td>\n",
       "      <td>-87.18</td>\n",
       "      <td>PENSACOLA REGIONAL AP</td>\n",
       "      <td>79.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-06-23</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1030</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1147</td>\n",
       "      <td>7.0</td>\n",
       "      <td>RDU</td>\n",
       "      <td>35.87</td>\n",
       "      <td>-78.78</td>\n",
       "      <td>RALEIGH-DURHAM INTERNATIONAL</td>\n",
       "      <td>78.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  YEAR  MONTH  DAY  DEP_DOW                       AIRLINE  DEP_T  \\\n",
       "0  2009-06-14  2009      6   14        1      Delta Air Lines Inc.: DL   1405   \n",
       "1  2004-06-27  2004      6   27        1  ExpressJet Airlines Inc.: EV   1025   \n",
       "2  2002-06-23  2002      6   23        1      Delta Air Lines Inc.: DL   1030   \n",
       "\n",
       "   DEP  DEP_LAT  DEP_LON     ...       WND_SPD_DEP ARR_T  ARR_DELAY  ARR  \\\n",
       "0  ATL    33.63   -84.42     ...               6.5  1529       -1.0  TPA   \n",
       "1  ATL    33.63   -84.42     ...               5.0  1047       -9.0  PNS   \n",
       "2  ATL    33.63   -84.42     ...               9.8  1147        7.0  RDU   \n",
       "\n",
       "   ARR_LAT  ARR_LON                         ARR_W MEAN_TEMP_ARR  MEAN_VIS_ARR  \\\n",
       "0    27.97   -82.53   TAMPA INTERNATIONAL AIRPORT          82.5          10.0   \n",
       "1    30.47   -87.18         PENSACOLA REGIONAL AP          79.7          10.0   \n",
       "2    35.87   -78.78  RALEIGH-DURHAM INTERNATIONAL          78.6           9.0   \n",
       "\n",
       "   WND_SPD_ARR  \n",
       "0          4.3  \n",
       "1          4.8  \n",
       "2          4.6  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = exec_pipeline(tiny_query, do_nothing, ALL_COLUMNS, write_header=True)\n",
    "res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 2: Select only the useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_COLUMNS=[\n",
    "    'YEAR', 'MONTH', 'DEP_DOW', 'AIRLINE', \n",
    "    'DEP_T', 'DEP', 'DEP_LAT', 'DEP_LON', 'DEP_DELAY', \n",
    "    'MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', \n",
    "    'ARR_DELAY', \n",
    "    'ARR', 'ARR_LAT', 'ARR_LON', \n",
    "    'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WND_SPD_DEP': 4.4, 'WND_SPD_ARR': 5.7, 'MEAN_TEMP_ARR': 79.4, 'DEP_DELAY': -2.0, 'DEP': 'ATL', 'ARR_LON': -81.2, 'MEAN_VIS_DEP': 6.0, 'DEP_T': 842, 'ARR': 'SAV', 'DEP_LON': -84.42, 'DEP_DOW': 2, 'MEAN_VIS_ARR': 9.8, 'ARR_LAT': 32.12, 'AIRLINE': 'Delta Air Lines Inc.: DL', 'YEAR': 2004, 'ARR_DELAY': 16.0, 'DEP_LAT': 33.63, 'MONTH': 6, 'MEAN_TEMP_DEP': 75.2}\n"
     ]
    }
   ],
   "source": [
    "def make_select_cols(select_columns):\n",
    "    def _select_cols(row):\n",
    "        return {key: row[key] for key in select_columns}\n",
    "    return _select_cols\n",
    "\n",
    "one_row = sample.to_dict(orient='records')[0]\n",
    "print(make_select_cols(SELECTED_COLUMNS)(one_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_9107adf43cb54a898ebf5673ab1564f7 does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1030</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>RDU</td>\n",
       "      <td>35.87</td>\n",
       "      <td>-78.78</td>\n",
       "      <td>78.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1425</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>74.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>CAE</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-81.11</td>\n",
       "      <td>75.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1150</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>19.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>DFW</td>\n",
       "      <td>32.89</td>\n",
       "      <td>-97.03</td>\n",
       "      <td>75.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  DEP_DOW                   AIRLINE  DEP_T  DEP  DEP_LAT  \\\n",
       "0  2002      6        1  Delta Air Lines Inc.: DL   1030  ATL    33.63   \n",
       "1  2002      6        2  Delta Air Lines Inc.: DL   1425  ATL    33.63   \n",
       "2  2002      6        2  Delta Air Lines Inc.: DL   1150  ATL    33.63   \n",
       "\n",
       "   DEP_LON  DEP_DELAY  MEAN_TEMP_DEP  MEAN_VIS_DEP  WND_SPD_DEP  ARR_DELAY  \\\n",
       "0   -84.42       -1.0           74.5           6.9          9.8        7.0   \n",
       "1   -84.42       -1.0           74.6          10.0          6.1      -12.0   \n",
       "2   -84.42       19.0           73.1           9.9          6.2       37.0   \n",
       "\n",
       "   ARR  ARR_LAT  ARR_LON  MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  \n",
       "0  RDU    35.87   -78.78           78.6           9.0          4.6  \n",
       "1  CAE    33.93   -81.11           75.7           9.9          2.9  \n",
       "2  DFW    32.89   -97.03           75.8           9.9          3.3  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = exec_pipeline(tiny_query, make_select_cols(SELECTED_COLUMNS), SELECTED_COLUMNS, write_header=True)\n",
    "res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Adding combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_haversine(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    def radians(a):\n",
    "        return a * math.pi / 180.0\n",
    "\n",
    "    radius = 6371.0\n",
    "    dlat = radians (lat2 - lat1) \n",
    "    dlon = radians (lon2 - lon1)\n",
    "    a = (tf.sin(dlat / 2.0) * tf.sin(dlat/2.0) +\n",
    "         tf.cos(radians(lat1)) * tf.cos(radians(lat2)) *\n",
    "         tf.sin(dlon / 2.0) * tf.sin(dlon / 2.0))\n",
    "    c = 2.0 * tf.atan2(tf.sqrt(a), tf.sqrt(1.0 - a))\n",
    "    return radius * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_combined(row):\n",
    "    dep_lat = row['DEP_LAT']\n",
    "    dep_lon = row['DEP_LON']\n",
    "    arr_lat = row['ARR_LAT']\n",
    "    arr_lon = row['ARR_LON']\n",
    "    row['DIFF_LAT'] = arr_lat - dep_lat\n",
    "    row['DIFF_LON'] = arr_lon - dep_lon\n",
    "    row['DISTANCE'] = tf_haversine(arr_lat, arr_lon, dep_lat, dep_lon)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_85851f21148444439d86847321109210 does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>...</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Comair Inc.: OH</td>\n",
       "      <td>931</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>CAK</td>\n",
       "      <td>40.91</td>\n",
       "      <td>-81.44</td>\n",
       "      <td>67.8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.279999</td>\n",
       "      <td>2.979996</td>\n",
       "      <td>851.21136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1405</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>TPA</td>\n",
       "      <td>27.97</td>\n",
       "      <td>-82.53</td>\n",
       "      <td>82.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-5.660002</td>\n",
       "      <td>1.889999</td>\n",
       "      <td>654.69806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1030</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>RDU</td>\n",
       "      <td>35.87</td>\n",
       "      <td>-78.78</td>\n",
       "      <td>78.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.239998</td>\n",
       "      <td>5.639999</td>\n",
       "      <td>572.19543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  DEP_DOW                   AIRLINE  DEP_T  DEP  DEP_LAT  \\\n",
       "0  2004      6        5           Comair Inc.: OH    931  ATL    33.63   \n",
       "1  2009      6        1  Delta Air Lines Inc.: DL   1405  ATL    33.63   \n",
       "2  2002      6        1  Delta Air Lines Inc.: DL   1030  ATL    33.63   \n",
       "\n",
       "   DEP_LON  DEP_DELAY  MEAN_TEMP_DEP    ...      ARR_DELAY  ARR  ARR_LAT  \\\n",
       "0   -84.42        0.0           73.4    ...          -16.0  CAK    40.91   \n",
       "1   -84.42        2.0           75.7    ...           -1.0  TPA    27.97   \n",
       "2   -84.42       -1.0           74.5    ...            7.0  RDU    35.87   \n",
       "\n",
       "  ARR_LON  MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  DIFF_LAT  DIFF_LON  \\\n",
       "0  -81.44           67.8           9.6          8.8  7.279999  2.979996   \n",
       "1  -82.53           82.5          10.0          4.3 -5.660002  1.889999   \n",
       "2  -78.78           78.6           9.0          4.6  2.239998  5.639999   \n",
       "\n",
       "    DISTANCE  \n",
       "0  851.21136  \n",
       "1  654.69806  \n",
       "2  572.19543  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_columns = SELECTED_COLUMNS + ['DIFF_LAT', 'DIFF_LON', 'DISTANCE']\n",
    "\n",
    "def pre_processor(row):\n",
    "    row = make_select_cols(SELECTED_COLUMNS)(row)\n",
    "    return add_combined(row)\n",
    "\n",
    "res = exec_pipeline(tiny_query, pre_processor, select_columns, write_header=True)\n",
    "res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 4: Scaling floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_floats(row):\n",
    "    for c in ['MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', 'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR', 'DEP_DELAY',\n",
    "             'DIFF_LAT', 'DIFF_LON', 'DISTANCE']:\n",
    "        row[c] = tft.scale_to_0_1(row[c])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = SELECTED_COLUMNS + ['DIFF_LAT', 'DIFF_LON', 'DISTANCE']\n",
    "\n",
    "def pre_processor(row):\n",
    "    row = row.copy()\n",
    "    row = make_select_cols(SELECTED_COLUMNS)(row)\n",
    "    row = add_combined(row)\n",
    "    row = scale_floats(row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_e7f0acbf500d4bb8b7149fc0f3d76d4e does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>...</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>842</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.33125</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>SAV</td>\n",
       "      <td>32.12</td>\n",
       "      <td>-81.20</td>\n",
       "      <td>0.507495</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.222973</td>\n",
       "      <td>0.354622</td>\n",
       "      <td>0.773389</td>\n",
       "      <td>0.044136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>2130</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.246637</td>\n",
       "      <td>0.21250</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>PVD</td>\n",
       "      <td>41.72</td>\n",
       "      <td>-71.42</td>\n",
       "      <td>0.406852</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.892437</td>\n",
       "      <td>0.976715</td>\n",
       "      <td>0.424967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>America West Airlines Inc.: HP (Merged with US...</td>\n",
       "      <td>805</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.23125</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>PHX</td>\n",
       "      <td>33.43</td>\n",
       "      <td>-112.01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.412162</td>\n",
       "      <td>0.428011</td>\n",
       "      <td>0.132848</td>\n",
       "      <td>0.802009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  DEP_DOW                                            AIRLINE  \\\n",
       "0  2004      6        2                           Delta Air Lines Inc.: DL   \n",
       "1  2006      6        3                           Delta Air Lines Inc.: DL   \n",
       "2  2005      6        4  America West Airlines Inc.: HP (Merged with US...   \n",
       "\n",
       "   DEP_T  DEP  DEP_LAT  DEP_LON  DEP_DELAY  MEAN_TEMP_DEP    ...     \\\n",
       "0    842  ATL    33.63   -84.42   0.013453        0.33125    ...      \n",
       "1   2130  ATL    33.63   -84.42   0.246637        0.21250    ...      \n",
       "2    805  ATL    33.63   -84.42   0.013453        0.23125    ...      \n",
       "\n",
       "   ARR_DELAY  ARR  ARR_LAT ARR_LON  MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  \\\n",
       "0       16.0  SAV    32.12  -81.20       0.507495          0.96     0.222973   \n",
       "1       45.0  PVD    41.72  -71.42       0.406852          1.00     0.520270   \n",
       "2      -25.0  PHX    33.43 -112.01       1.000000          1.00     0.412162   \n",
       "\n",
       "   DIFF_LAT  DIFF_LON  DISTANCE  \n",
       "0  0.354622  0.773389  0.044136  \n",
       "1  0.892437  0.976715  0.424967  \n",
       "2  0.428011  0.132848  0.802009  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = exec_pipeline(tiny_query, pre_processor, select_columns, write_header=True)\n",
    "res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create the big files\n",
    "Creating the files for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-transform"
     ]
    }
   ],
   "source": [
    "!cat dataflow_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_pipeline_prod (preprocessing_fn, output_columns, fractions, sample_rate, runner='DirectRunner', write_header=False):\n",
    "    \n",
    "    header=\",\".join(output_columns) if write_header else None\n",
    "    \n",
    "    tmpdir='gs://{}/tmp'.format(BUCKET)\n",
    "    proddir='gs://{}/prod'.format(BUCKET)\n",
    "\n",
    "    job_name = 'tft-tutorial' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "\n",
    "    options = {\n",
    "        'staging_location': tmpdir,\n",
    "        'temp_location': tmpdir,\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'max_num_workers': 24,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True,\n",
    "        'requirements_file': 'dataflow_requirements.txt'\n",
    "    }\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    \n",
    "    with beam.Pipeline(runner, options=opts) as p:\n",
    "        with beam_impl.Context(temp_dir=tmpdir):\n",
    "            \n",
    "            queries = sample_queries(fractions, sample_rate)\n",
    "\n",
    "            #   Read training data from Big Query\n",
    "            #\n",
    "            raw_data = p | \"ReadFromBigQuery_train\"  >> beam.io.Read(beam.io.BigQuerySource(query=queries['train'], use_standard_sql=True)) \n",
    "            raw_dataset = (raw_data, raw_data_metadata)\n",
    "\n",
    "            \n",
    "            #   Analyze and transform by calling a single function that has all the tft.transforms in it\n",
    "            #\n",
    "            t_dataset, transform_fn = (raw_dataset \n",
    "                                       | \"AnalyzeAndTransform\" >> beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "            t_data, t_metadata = t_dataset\n",
    "            \n",
    "            \n",
    "            # Encode back to CSV file(s)\n",
    "            #\n",
    "            train_prefix = os.path.join(proddir, 'atl_june_train')\n",
    "            csv_encode = tft.coders.CsvCoder(output_columns, t_metadata.schema).encode    \n",
    "            res = (t_data \n",
    "                   | \"EncodeTraining\" >> beam.Map(csv_encode)\n",
    "                   | \"WriteTraining\" >> beam.io.WriteToText(file_path_prefix=train_prefix, header=header))\n",
    "\n",
    "\n",
    "            #   Read eval data from Big Query\n",
    "            #\n",
    "            raw_data = p | \"ReadFromBigQuery_eval\"  >> beam.io.Read(beam.io.BigQuerySource(query=queries['eval'], use_standard_sql=True)) \n",
    "            raw_dataset = (raw_data, raw_data_metadata)\n",
    "\n",
    "            \n",
    "            #   Transform the eval dataset with the transform function derived above\n",
    "            #\n",
    "            t_dataset = ((raw_dataset, transform_fn) \n",
    "                         | \"TransformEval\" >> beam_impl.TransformDataset())\n",
    "            t_data, _ = t_dataset\n",
    "            \n",
    "            \n",
    "            # Encode back to CSV file(s)\n",
    "            #\n",
    "            eval_prefix = os.path.join(proddir, 'atl_june_eval')\n",
    "            csv_encode = tft.coders.CsvCoder(output_columns, t_metadata.schema).encode    \n",
    "            res = (t_data \n",
    "                   | \"EncodeEval\" >> beam.Map(csv_encode)\n",
    "                   | \"WriteEval\" >> beam.io.WriteToText(file_path_prefix=eval_prefix, header=header))\n",
    "\n",
    "            \n",
    "            # save transformation function to disk for use at serving time\n",
    "            #\n",
    "            transform_fn | 'WriteTransformFn' >> transform_fn_io.WriteTransformFn(\n",
    "                os.path.join(proddir, 'metadata'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From an excellent blog on the subject:\n",
    "[The blog](https://cloud.google.com/blog/products/ai-machine-learning/pre-processing-tensorflow-pipelines-tftransform-google-cloud)\n",
    "\n",
    "[Github](https://github.com/Fematich/tftransform-demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transform_output = tft.TFTransformOutput(working_dir)\n",
    "serving_input_fn = _make_serving_input_fn(tf_transform_output)\n",
    "exported_model_dir = os.path.join(working_dir, EXPORTED_MODEL_DIR)\n",
    "estimator.export_savedmodel(exported_model_dir, serving_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be re-usable code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_serving_input_fn(tf_transform_output):\n",
    "  raw_feature_spec = RAW_DATA_METADATA.schema.as_feature_spec()\n",
    "  raw_feature_spec.pop(LABEL_KEY)\n",
    "\n",
    "  def serving_input_fn():\n",
    "    raw_input_fn = input_fn_utils.build_parsing_serving_input_fn(\n",
    "        raw_feature_spec)\n",
    "    raw_features, _, default_inputs = raw_input_fn()\n",
    "    transformed_features = tf_transform_output.transform_raw_features(\n",
    "        raw_features)\n",
    "    return input_fn_utils.InputFnOps(transformed_features, None, default_inputs)\n",
    "\n",
    "  return serving_input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up before we start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f /tmp/*_june*\n",
    "!ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://going-tfx/prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://going-tfx/prod/#1541699087434906...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00003-of-00025#1541699111140688...\n",
      "Removing gs://going-tfx/prod/atl_june_eval-00000-of-00003#1541699109975135...\n",
      "Removing gs://going-tfx/prod/atl_june_eval-00001-of-00003#1541699109990940...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00006-of-00025#1541699111165386...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00000-of-00025#1541699111140030...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00007-of-00025#1541699111196358...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00002-of-00025#1541699111177539...\n",
      "Removing gs://going-tfx/prod/atl_june_eval-00002-of-00003#1541699110058062...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00008-of-00025#1541699111236032...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00001-of-00025#1541699111208878...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00004-of-00025#1541699111158326...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00012-of-00025#1541699111221294...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00005-of-00025#1541699111221359...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00009-of-00025#1541699111255836...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00014-of-00025#1541699111179285...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00010-of-00025#1541699111173908...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00013-of-00025#1541699111167361...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00015-of-00025#1541699111177632...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00011-of-00025#1541699111203894...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00016-of-00025#1541699111310147...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00017-of-00025#1541699111179455...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00018-of-00025#1541699111265129...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00019-of-00025#1541699111201640...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00020-of-00025#1541699111121704...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00021-of-00025#1541699111203297...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00022-of-00025#1541699111197923...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00023-of-00025#1541699111137944...\n",
      "Removing gs://going-tfx/prod/atl_june_train-00024-of-00025#1541699111125325...\n",
      "Removing gs://going-tfx/prod/metadata/#1541699087815743...\n",
      "Removing gs://going-tfx/prod/metadata/transform_fn/#1541699088498446...\n",
      "Removing gs://going-tfx/prod/metadata/transform_fn/saved_model.pb#1541699089359884...\n",
      "Removing gs://going-tfx/prod/metadata/transform_fn/variables/#1541699090313146...\n",
      "Removing gs://going-tfx/prod/metadata/transformed_metadata/#1541699094240549...\n",
      "Removing gs://going-tfx/prod/metadata/transformed_metadata/v1-json/#1541699094556126...\n",
      "Removing gs://going-tfx/prod/metadata/transformed_metadata/v1-json/schema.json#1541699631126249...\n",
      "/ [36/36 objects] 100% Done                                                     \n",
      "Operation completed over 36 objects.                                             \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -rf gs://going-tfx/prod\n",
    "_ = !gsutil -m rm -rf gs://going-tfx/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This takes about two minutes. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_a3346b84198e490186858412e68834a5 does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Dataset going-tfx:temp_dataset_3370a2accdaf43988fb89cbdd00b1322 does not exist so we will create it as temporary with location=US\n"
     ]
    }
   ],
   "source": [
    "exec_pipeline_prod (preprocessing_fn=pre_processor, output_columns=select_columns, fractions=[80, 10, 10], sample_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### This executes in dataflow and takes some 12 - 20 minutes\n",
    "But if you watch the graph in the dataflow console, you see that the job lives until the VM is shutdown. The files may be available a bit earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -rf gs://going-tfx/prod\n",
    "_ = !gsutil -m rm -rf gs://going-tfx/tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_pipeline_prod (preprocessing_fn=pre_processor, output_columns=select_columns, fractions=[90, 5, 5], sample_rate=1.0, runner = 'DataflowRunner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://going-tfx/prod/\n",
      "gs://going-tfx/prod/atl_june_eval-00000-of-00001\n",
      "gs://going-tfx/prod/atl_june_train-00000-of-00005\n",
      "gs://going-tfx/prod/atl_june_train-00001-of-00005\n",
      "gs://going-tfx/prod/atl_june_train-00002-of-00005\n",
      "gs://going-tfx/prod/atl_june_train-00003-of-00005\n",
      "gs://going-tfx/prod/atl_june_train-00004-of-00005\n",
      "\n",
      "gs://going-tfx/prod/metadata/:\n",
      "gs://going-tfx/prod/metadata/\n",
      "gs://going-tfx/prod/metadata/transform_fn/\n",
      "gs://going-tfx/prod/metadata/transformed_metadata/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://going-tfx/prod/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Copy the files into local directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir /tmp/prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://going-tfx/prod/atl_june_eval-00000-of-00001...\n",
      "/ [1/1 files][  2.7 MiB/  2.7 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/2.7 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp gs://going-tfx/prod/atl_june_eval* /tmp/prod/\n",
    "_ = !gsutil -m cp gs://going-tfx/prod/atl_june_train* /tmp/prod/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Have a look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_COLUMNS = [\n",
    "    'YEAR', 'MONTH', 'DEP_DOW', 'AIRLINE', \n",
    "    'DEP_T', 'DEP', 'DEP_LAT', 'DEP_LON', 'DEP_DELAY',\n",
    "    'MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', \n",
    "    'ARR_DELAY', 'ARR', 'ARR_LAT', 'ARR_LON', \n",
    "    'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR', 'DIFF_LAT', 'DIFF_LON', 'DISTANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 /tmp/prod/atl_june_train-00001-of-00025\n"
     ]
    }
   ],
   "source": [
    "a_training_file = !ls /tmp/prod/atl_june_train-00001-of-*\n",
    "a_training_file = a_training_file[0]\n",
    "!wc -l $a_training_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(a_training_file, names=select_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2006.870000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.945000</td>\n",
       "      <td>1443.381000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.158073</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.849453</td>\n",
       "      <td>0.352209</td>\n",
       "      <td>12.648000</td>\n",
       "      <td>37.684470</td>\n",
       "      <td>-81.868910</td>\n",
       "      <td>0.486703</td>\n",
       "      <td>0.423871</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.459730</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.063288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.940024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.973796</td>\n",
       "      <td>470.859704</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.081216</td>\n",
       "      <td>0.186673</td>\n",
       "      <td>0.182565</td>\n",
       "      <td>0.141484</td>\n",
       "      <td>36.774889</td>\n",
       "      <td>2.941718</td>\n",
       "      <td>1.352395</td>\n",
       "      <td>0.118834</td>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.030320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.099274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.000000</td>\n",
       "      <td>32.890000</td>\n",
       "      <td>-84.660000</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.349436</td>\n",
       "      <td>0.786727</td>\n",
       "      <td>0.033353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.121065</td>\n",
       "      <td>0.491596</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>35.210000</td>\n",
       "      <td>-82.890000</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.381720</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.402807</td>\n",
       "      <td>0.805735</td>\n",
       "      <td>0.033353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1446.500000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.128329</td>\n",
       "      <td>0.630252</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.040000</td>\n",
       "      <td>-81.850000</td>\n",
       "      <td>0.505435</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.490913</td>\n",
       "      <td>0.816903</td>\n",
       "      <td>0.066784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1805.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.154964</td>\n",
       "      <td>0.769958</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.434109</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>39.990000</td>\n",
       "      <td>-80.940000</td>\n",
       "      <td>0.574275</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.512768</td>\n",
       "      <td>0.826675</td>\n",
       "      <td>0.083416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>41.400000</td>\n",
       "      <td>-80.040000</td>\n",
       "      <td>0.760869</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.545204</td>\n",
       "      <td>0.836340</td>\n",
       "      <td>0.107747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              YEAR   MONTH      DEP_DOW        DEP_T  DEP_LAT  DEP_LON  \\\n",
       "count  1000.000000  1000.0  1000.000000  1000.000000  1000.00  1000.00   \n",
       "mean   2006.870000     6.0     3.945000  1443.381000    33.63   -84.42   \n",
       "std       2.940024     0.0     1.973796   470.859704     0.00     0.00   \n",
       "min    2002.000000     6.0     1.000000   530.000000    33.63   -84.42   \n",
       "25%    2004.000000     6.0     2.000000  1015.000000    33.63   -84.42   \n",
       "50%    2007.000000     6.0     4.000000  1446.500000    33.63   -84.42   \n",
       "75%    2010.000000     6.0     6.000000  1805.000000    33.63   -84.42   \n",
       "max    2011.000000     6.0     7.000000  2340.000000    33.63   -84.42   \n",
       "\n",
       "         DEP_DELAY  MEAN_TEMP_DEP  MEAN_VIS_DEP  WND_SPD_DEP    ARR_DELAY  \\\n",
       "count  1000.000000    1000.000000   1000.000000  1000.000000  1000.000000   \n",
       "mean      0.158073       0.633105      0.849453     0.352209    12.648000   \n",
       "std       0.081216       0.186673      0.182565     0.141484    36.774889   \n",
       "min       0.099274       0.000000      0.000000     0.000000   -29.000000   \n",
       "25%       0.121065       0.491596      0.765625     0.255814    -7.000000   \n",
       "50%       0.128329       0.630252      0.921875     0.348837     1.000000   \n",
       "75%       0.154964       0.769958      0.984375     0.434109    17.000000   \n",
       "max       0.813559       1.000000      1.000000     1.000000   273.000000   \n",
       "\n",
       "           ARR_LAT      ARR_LON  MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  \\\n",
       "count  1000.000000  1000.000000    1000.000000   1000.000000  1000.000000   \n",
       "mean     37.684470   -81.868910       0.486703      0.423871     0.005624   \n",
       "std       2.941718     1.352395       0.118834      0.073301     0.002173   \n",
       "min      32.890000   -84.660000       0.070652      0.129032     0.001300   \n",
       "25%      35.210000   -82.890000       0.405797      0.381720     0.004000   \n",
       "50%      39.040000   -81.850000       0.505435      0.451613     0.005201   \n",
       "75%      39.990000   -80.940000       0.574275      0.483871     0.007001   \n",
       "max      41.400000   -80.040000       0.760869      0.489247     0.014001   \n",
       "\n",
       "          DIFF_LAT     DIFF_LON     DISTANCE  \n",
       "count  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.459730     0.816700     0.063288  \n",
       "std       0.067672     0.014523     0.030320  \n",
       "min       0.349436     0.786727     0.033353  \n",
       "25%       0.402807     0.805735     0.033353  \n",
       "50%       0.490913     0.816903     0.066784  \n",
       "75%       0.512768     0.826675     0.083416  \n",
       "max       0.545204     0.836340     0.107747  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
