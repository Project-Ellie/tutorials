{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Models With Synthetic Data\n",
    "The advantage of synthetic data is that we know the prior or ground truth and we know exactly how concealed it is. That helps us to determine with certainty that an algorithm is per se capable of discovering the ground truth. If an algorithm fails on the easy task of learning from synthetic data, then it won't be good in real life. The opposite, unfortunately, is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "from tools import print_progress, array_in, create_input_data\n",
    "\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Noisy Samples From A Well-Known Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a*x+b\n",
    "def make_lin(a, b, rnd):\n",
    "    def _f_a(x):\n",
    "        mu = a*x + b\n",
    "        return rnd(mu)\n",
    "    return _f_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Two linear but noisy signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = make_lin(2, 1, lambda mu: np.random.normal(loc=mu, scale=1.0))\n",
    "f_b = make_lin(-.5, -1.5, lambda mu: np.random.normal(loc=mu, scale=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A look at one of the signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([f_a(1) for i in range(1000)])\n",
    "df.plot.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we create a data set/frame representing $f_a(x)+f_b(y)$ as a random variable that depends on random variables $x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v1(size):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'f': f_data, 'p': f_perf})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, this is equivalent to saying that the ground truth is:\n",
    "\n",
    "$$ f(x, y) = 2x - \\frac{1}{2} y - \\frac{1}{2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.399682</td>\n",
       "      <td>-0.400144</td>\n",
       "      <td>9.614239</td>\n",
       "      <td>6.499435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.836593</td>\n",
       "      <td>1.228568</td>\n",
       "      <td>-5.998465</td>\n",
       "      <td>-4.787471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.130946</td>\n",
       "      <td>0.613711</td>\n",
       "      <td>-7.276137</td>\n",
       "      <td>-9.068748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.340600</td>\n",
       "      <td>1.570992</td>\n",
       "      <td>-0.682609</td>\n",
       "      <td>1.395703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.207173</td>\n",
       "      <td>2.263344</td>\n",
       "      <td>8.689191</td>\n",
       "      <td>6.782673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         f         p\n",
       "0  3.399682 -0.400144  9.614239  6.499435\n",
       "1 -1.836593  1.228568 -5.998465 -4.787471\n",
       "2 -4.130946  0.613711 -7.276137 -9.068748\n",
       "3  1.340600  1.570992 -0.682609  1.395703\n",
       "4  4.207173  2.263344  8.689191  6.782673"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_data_frame_v1(NUM_RECORDS)\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Linear Regressor From Scratch With Tensorflow\n",
    "Let's train a self-made tensorflow linear regressor with the synthetic data to see whether it finds the coefficients above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Was already closed or didn't exist. That's fine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    print(\"OK. Was already closed or didn't exist. That's fine.\")\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating The Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, x_dim, lr):\n",
    "\n",
    "        # Variables for the parameters: weights M and bias b\n",
    "        self.M = tf.Variable(tf.zeros(shape=(1, x_dim)))\n",
    "        self.b = tf.Variable(0.)\n",
    "\n",
    "        # Placeholders for x and labels\n",
    "        self.x = tf.placeholder(shape=(x_dim,None), dtype=tf.float32)\n",
    "        self.lbls = tf.placeholder(shape=(1,None), dtype=tf.float32)\n",
    "\n",
    "        # The prediction and the distance (loss)\n",
    "        self.f = tf.matmul(self.M, self.x) + self.b\n",
    "        self.d = tf.losses.mean_squared_error(self.lbls, self.f)\n",
    "\n",
    "        # The gradients\n",
    "        self.nM = tf.gradients(self.d, self.M)\n",
    "        self.nb = tf.gradients(self.d, self.b)\n",
    "\n",
    "        # The optimizers\n",
    "        self.aM = tf.assign_add( self.M, tf.multiply(self.nM[0],-lr))\n",
    "        self.ab = tf.assign_add( self.b, tf.multiply(self.nb[0], -lr))\n",
    "\n",
    "        # The initializer\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def train(self, sess, x_data, labels_data, num_steps):        \n",
    "        sess.run(self.init)\n",
    "        for i in range(num_steps):\n",
    "            _, dist, _, _, _, _ = sess.run([self.f, self.d, self.nM, self.nb, self.aM, self.ab], \n",
    "                                           feed_dict = {self.x: x_data, self.lbls: labels_data})\n",
    "            print_progress(\"- Loss: {}\", dist)\n",
    "        return dist\n",
    "    \n",
    "    def predict(self, sess, x_data):\n",
    "        pred = sess.run(self.f, feed_dict={self.x: x_data})\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Perform The Training And Examine The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [list(df_train['x']), list(df_train['y'])]\n",
    "lbls_data = [list(df_train['f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.0531539916992188"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.053154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = Linear(x_dim=2, lr=0.01)\n",
    "linear1.train(sess, input_data, lbls_data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the parameters to be close to $2, -0.5, -0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.001272  , -0.50020266]], dtype=float32), -0.5086103]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([linear1.M, linear1.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now the tensor f represents the hypothesis. Let's evaluate it with some fresh test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = create_data_frame_v1(size=10000)\n",
    "test_data = [list(df_test['x']), list(df_test['y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear1.predict(sess=sess, x_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.421837</td>\n",
       "      <td>2.721789</td>\n",
       "      <td>7.242147</td>\n",
       "      <td>6.982780</td>\n",
       "      <td>6.979243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.632382</td>\n",
       "      <td>-4.875022</td>\n",
       "      <td>11.584552</td>\n",
       "      <td>11.202274</td>\n",
       "      <td>11.200543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.912983</td>\n",
       "      <td>2.531394</td>\n",
       "      <td>0.848731</td>\n",
       "      <td>0.060269</td>\n",
       "      <td>0.052307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.086742</td>\n",
       "      <td>-2.603373</td>\n",
       "      <td>-6.433733</td>\n",
       "      <td>-5.371798</td>\n",
       "      <td>-5.383807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.583154</td>\n",
       "      <td>-0.700489</td>\n",
       "      <td>-4.770781</td>\n",
       "      <td>-5.316064</td>\n",
       "      <td>-5.327818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.104859</td>\n",
       "      <td>-3.152265</td>\n",
       "      <td>-6.209662</td>\n",
       "      <td>-5.133586</td>\n",
       "      <td>-5.145506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.323252</td>\n",
       "      <td>4.547638</td>\n",
       "      <td>-13.472069</td>\n",
       "      <td>-9.420323</td>\n",
       "      <td>-9.434083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.887259</td>\n",
       "      <td>1.600672</td>\n",
       "      <td>3.725684</td>\n",
       "      <td>4.474182</td>\n",
       "      <td>4.468920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.785658</td>\n",
       "      <td>-4.228159</td>\n",
       "      <td>6.173240</td>\n",
       "      <td>7.185396</td>\n",
       "      <td>7.181186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.316506</td>\n",
       "      <td>-4.560759</td>\n",
       "      <td>-3.414165</td>\n",
       "      <td>-2.852632</td>\n",
       "      <td>-2.863264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y          f          p  predictions\n",
       "0  4.421837  2.721789   7.242147   6.982780     6.979243\n",
       "1  4.632382 -4.875022  11.584552  11.202274    11.200543\n",
       "2  0.912983  2.531394   0.848731   0.060269     0.052307\n",
       "3 -3.086742 -2.603373  -6.433733  -5.371798    -5.383807\n",
       "4 -2.583154 -0.700489  -4.770781  -5.316064    -5.327818\n",
       "5 -3.104859 -3.152265  -6.209662  -5.133586    -5.145506\n",
       "6 -3.323252  4.547638 -13.472069  -9.420323    -9.434083\n",
       "7  2.887259  1.600672   3.725684   4.474182     4.468920\n",
       "8  2.785658 -4.228159   6.173240   7.185396     7.181186\n",
       "9 -2.316506 -4.560759  -3.414165  -2.852632    -2.863264"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'] = predictions[0]\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see without surprise that the predictions are typically closer to the ground truth than to the noisy signal. This means we have enough data to average out the noise and reveal the ground truth. A look at the distribution of the errors reveals pure noise around 0. That's typically a good sign that our network has understood the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAFMVJREFUeJzt3X2QZXV95/H3R0TwKU4ILZmdhx3Moi4m4WEbJMu6hRATxES0KmGxNkoImzEJulrLJg5kdzWVpYrsGgluNlQmgIIhUYIirGDWEYkpq5aHAUceZZ1VDDMiMzEoEFxY4Lt/3DN4Iae7b0/f0+d29/tVdavP+d1z7v3emun+3N85v/M7qSokSXqu5/VdgCRpMhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaPb/vAhbiwAMPrA0bNvRdhiQtKbfeeuvfVtXUXNst6YDYsGEDW7du7bsMSVpSknxzlO08xCRJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqtaSvpJb6sGHTtc9av++8N/VUidStznoQSfZPcnOSryS5K8nvNO0fTfKNJNuax+FNe5J8OMn2JLcnObKr2iRJc+uyB/E4cHxVPZpkX+BLST7bPPebVXXlc7Z/I3BI83gtcGHzU5LUg84CoqoKeLRZ3bd51Cy7nAxc1ux3Y5JVSVZX1QNd1SiNw/AhJw83aTnp9CR1kn2SbAN2AVuq6qbmqXObw0jnJ9mvaVsD3D+0+46mTZLUg04DoqqeqqrDgbXA0Ul+HDgbeDVwFHAA8L75vGaSjUm2Jtm6e/fusdcsSRpYlGGuVfVd4AbgxKp6oAYeBz4CHN1sthNYN7Tb2qbtua+1uaqmq2p6amrO+11Ivdmw6dpnHtJS1OUopqkkq5rlFwJvAL6aZHXTFuAtwJ3NLtcA72hGMx0DfM/zD5LUny5HMa0GLk2yD4MguqKqPpPkC0mmgADbgF9rtr8OOAnYDjwGnN5hbZKkOXQ5iul24IiW9uNn2L6AM7uqR5I0P15JLfXIIbKaZAaEtAgMAi1FBoS0yGYa1WSIaNI4m6skqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplVdSS2PkvR+0nNiDkCS1MiAkSa0MCElSKwNCktTKgJAktXIUkzSBvDeEJoE9CElSq84CIsn+SW5O8pUkdyX5nab94CQ3Jdme5BNJXtC079esb2+e39BVbZKkuXXZg3gcOL6qDgMOB05Mcgzwe8D5VfVPgIeAM5rtzwAeatrPb7aTVrwNm6595iEtps4CogYebVb3bR4FHA9c2bRfCrylWT65Wad5/oQk6ao+SdLsOj0HkWSfJNuAXcAW4P8A362qJ5tNdgBrmuU1wP0AzfPfA36ky/okSTPrdBRTVT0FHJ5kFXAV8OqFvmaSjcBGgPXr1y/05aRncfSQ9AOLMoqpqr4L3AD8FLAqyZ5gWgvsbJZ3AusAmudfBnyn5bU2V9V0VU1PTU11XrskrVRdjmKaanoOJHkh8AbgHgZB8QvNZqcBVzfL1zTrNM9/oaqqq/okSbPr8hDTauDSJPswCKIrquozSe4GPp7kPwNfBi5utr8Y+FiS7cDfAad2WJs0Jw83aaXrLCCq6nbgiJb2rwNHt7T/X+AXu6pHkjQ/XkktSWrlXExaMTxkJM2PPQhJUit7ENIInOZCK5E9CElSKwNCktTKgJAktTIgJEmtDAhJUitHMWnFc4SS1M4ehCSplQEhSWplQEiSWnkOQivSUj3v4HxSWkz2ICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSq84CIsm6JDckuTvJXUne07R/IMnOJNuax0lD+5ydZHuSe5P8bFe1SZLm1uV1EE8CZ1XVbUleCtyaZEvz3PlV9cHhjZMcCpwKvAb4R8Dnk7yyqp7qsEZJ0gw660FU1QNVdVuz/AhwD7Bmll1OBj5eVY9X1TeA7cDRXdUnSZrdopyDSLIBOAK4qWl6V5Lbk1yS5IebtjXA/UO77WD2QJEkdajzgEjyEuCTwHur6mHgQuDHgMOBB4Dfn+frbUyyNcnW3bt3j71eaanYsOnaZx5SFzoNiCT7MgiHy6vqUwBV9WBVPVVVTwN/wg8OI+0E1g3tvrZpe5aq2lxV01U1PTU11WX5krSidTmKKcDFwD1V9aGh9tVDm70VuLNZvgY4Ncl+SQ4GDgFu7qo+SdLsuhzFdCzwduCOJNuatnOAtyU5HCjgPuCdAFV1V5IrgLsZjIA60xFMktSfzgKiqr4EpOWp62bZ51zg3K5qkiSNziupJUmtDAhJUisDQpLUyoCQJLXyntTSMuN9qzUu9iAkSa1GCogkP9F1IZKkyTJqD+KPktyc5DeSvKzTiiRJE2GkgKiq1wH/msFcSbcm+bMkb+i0MklSr0Y+SV1VX0vyH4CtwIeBI5r5ls7ZMxGfpMniCWstxKjnIH4yyfkMbvpzPPDzVfVPm+XzO6xPktSTUXsQ/w24iEFv4ft7GqvqW02vQlKPvCeEujBqQLwJ+P6e2VWTPA/Yv6oeq6qPdVadJKk3owbE54GfBh5t1l8EfA74510UJY2L36ylvTfqMNf9q2pPONAsv6ibkiRJk2DUgPj7JEfuWUnyz4Dvz7K9JGmJG/UQ03uBv0jyLQY3AfpR4F91VpWksXPIq+ZrpICoqluSvBp4VdN0b1X9v+7KkiT1bT6zuR4FbGj2OTIJVXVZJ1VJkno3UkAk+RjwY8A24KmmuQADQpKWqVF7ENPAoVVVo75wknUMAuQgBmGyuaouSHIA8AkGvZH7gFOq6qFm2o4LgJOAx4BfrqrbRn0/SdJ4jTqK6U4GJ6bn40ngrKo6FDgGODPJocAm4PqqOgS4vlkHeCNwSPPYCFw4z/eTJI3RqD2IA4G7k9wMPL6nsarePNMOVfUA8ECz/EiSe4A1wMnAcc1mlwJ/Bbyvab+s6aXcmGRVktXN60iSFtmoAfGBhbxJkg3AEcBNwEFDf/S/zeAQFAzC4/6h3XY0bc8KiCQbGfQwWL9+/ULKkiTNYtT7QXyRwfmCfZvlW4CRzg8keQnwSeC9VfXwc163GJyfGFlVba6q6aqanpqams+ukqR5GHW6718FrgT+uGlaA3x6hP32ZRAOlw/dM+LBJKub51cDu5r2nQxuSLTH2qZNktSDUU9SnwkcCzwMg5sHAS+fbYdmVNLFwD1V9aGhp64BTmuWTwOuHmp/RwaOAb7n+QdJ6s+o5yAer6onBn/zIcnzmfvQ0LHA24E7kmxr2s4BzgOuSHIG8E3glOa56xgMcd3OYJjr6aN+CEnS+I0aEF9Mcg7wwuZe1L8B/I/ZdqiqLzGYt6nNCS3bF4OeiiRpAowaEJuAM4A7gHcy+LZ/UVdFSQvhPSCk8Rh1sr6ngT9pHpKWOGd21ShGnYvpG7Scc6iqV4y9IknSRJjPXEx77A/8InDA+MuRJE2KUS+U+87QY2dV/QFgv1SSlrFRDzEdObT6PAY9ivncS0KStMSM+kf+94eWn6SZpnvs1UiSJsaoo5he33UhkqTJMuohpn832/PPmUpDWhQO1ZS6NZ9RTEcxmC8J4OeBm4GvdVGUpMVj0GomowbEWuDIqnoEIMkHgGur6pe6KkyS1K9RZ3M9CHhiaP0JfnCjH0nSMjRqD+Iy4OYkVzXrb2Fwu1BJ0jI16iimc5N8Fnhd03R6VX25u7IkSX0b9RATwIuAh6vqAmBHkoM7qkmSNAFGHeb6fgYjmV4FfATYF/hTBjcFknrnFN/S+I3ag3gr8Gbg7wGq6lvAS7sqSpLUv1ED4onmjm8FkOTF3ZUkSZoEowbEFUn+GFiV5FeBz+PNgyRpWRt1FNMHm3tRP8zgPMR/qqotnVYmNbzSV+rHnD2IJPskuaGqtlTVb1bVvx8lHJJckmRXkjuH2j6QZGeSbc3jpKHnzk6yPcm9SX527z+SJGkc5gyIqnoKeDrJy+b52h8FTmxpP7+qDm8e1wEkORQ4FXhNs88fJdlnnu8nSRqjUa+kfhS4I8kWmpFMAFX1b2faoar+OsmGEV//ZODjVfU48I0k24Gjgf814v6SpDEbNSA+1TzG4V1J3gFsBc6qqoeANcCNQ9vsaNr+gSQbgY0A69evH1NJkqTnmjUgkqyvqr+pqnHNu3Qh8LsMhsv+LoM71f3KfF6gqjYDmwGmp6drTHVpifCCOGnxzHUO4tN7FpJ8cqFvVlUPVtVTVfU0g2GyRzdP7QTWDW26tmmTJPVkroDI0PIrFvpmSVYPrb4V2DPC6Rrg1CT7NXM8HcLghkSSpJ7MdQ6iZlieU5I/B44DDkyyA3g/cFySw5vXug94J0BV3ZXkCuBu4EngzGb0lCSpJ3MFxGFJHmbQk3hhs0yzXlX1QzPtWFVva2m+eJbtzwXOnaMeSdIimTUgqsprEaQVyivYNZ/7QUiSVhADQpLUyoCQJLUa9UpqaWxGObbtBXFS/wwISc8wmDXMQ0ySpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVl5JrYnhVbzSZDEgJM3Je0OsTB5ikiS1MiAkSa06C4gklyTZleTOobYDkmxJ8rXm5w837Uny4STbk9ye5Miu6pIkjabLcxAfBf4QuGyobRNwfVWdl2RTs/4+4I3AIc3jtcCFzU8tc56YliZXZz2Iqvpr4O+e03wycGmzfCnwlqH2y2rgRmBVktVd1SZJmttin4M4qKoeaJa/DRzULK8B7h/abkfTJknqSW8nqauqgJrvfkk2JtmaZOvu3bs7qEySBIsfEA/uOXTU/NzVtO8E1g1tt7Zp+weqanNVTVfV9NTUVKfFStJKttgBcQ1wWrN8GnD1UPs7mtFMxwDfGzoUJUnqQWejmJL8OXAccGCSHcD7gfOAK5KcAXwTOKXZ/DrgJGA78Bhweld1SZJG01lAVNXbZnjqhJZtCzizq1okjc9MQ5OdgmP5cS4mSWPx3OAwMJY+p9qQJLUyICRJrTzEpEXhlBrS0mMPQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktXKqDUmdc4rwpckehCSplT0ISZ1wgsalz4BQZ/wDIS1tHmKSJLUyICRJrXo5xJTkPuAR4CngyaqaTnIA8AlgA3AfcEpVPdRHfZIW3/AhSUc3TYY+exCvr6rDq2q6Wd8EXF9VhwDXN+uSpJ5M0knqk4HjmuVLgb8C3tdXMdo7npiWlo++ehAFfC7JrUk2Nm0HVdUDzfK3gYP6KU2SBP31IP5FVe1M8nJgS5KvDj9ZVZWk2nZsAmUjwPr167uvVJJWqF56EFW1s/m5C7gKOBp4MMlqgObnrhn23VxV01U1PTU1tVglS9KKs+gBkeTFSV66Zxn4GeBO4BrgtGaz04CrF7s2SdIP9HGI6SDgqiR73v/Pquovk9wCXJHkDOCbwCk91Ka94Ilp7S3/70y2RQ+Iqvo6cFhL+3eAExa7HklSO6+kliS1MiAkSa0MCElSq0m6klpLiCcXpeXPgJA0cZy4bzJ4iEmS1MoehGb03MNIfpNTH+xN9McehCSplT0IjcwT09LKYkBIWjI83LS4PMQkSWplQEiSWnmIaYWyqy5pLgaEnsUT0Voq/JLTPQ8xSZJa2YNYhub7zcpeg6Q2BsQyZzdcK8EoX3L8/z9/BsQKYk9B0nwYEEuYvQNp4fw9mpkBsUzYO5A0bhMXEElOBC4A9gEuqqrzei6pd37Dkfq1Un8HJyogkuwD/HfgDcAO4JYk11TV3f1WNl4L+c9mT0FaOH+PRjNRAQEcDWyvqq8DJPk4cDKwrAJC0uIbJRRWak9hJpMWEGuA+4fWdwCv7eKNxvkfYVzfRvxWI02O+f4+zvQ3ZZw33lrsAEtVdf4mo0ryC8CJVfVvmvW3A6+tqncNbbMR2Nisvgq4d55vcyDwt2Mod1L4eSabn2fyLbfPNMrn+cdVNTXXC01aD2InsG5ofW3T9oyq2gxs3ts3SLK1qqb3dv9J4+eZbH6eybfcPtM4P8+kzcV0C3BIkoOTvAA4Fbim55okaUWaqB5EVT2Z5F3A/2QwzPWSqrqr57IkaUWaqIAAqKrrgOs6fIu9Pjw1ofw8k83PM/mW22ca2+eZqJPUkqTJMWnnICRJE2LFBkSSdyf5apK7kvyXvusZhyRnJakkB/Zdy0Ik+a/Nv83tSa5KsqrvmvZGkhOT3Jtke5JNfdezEEnWJbkhyd3N78x7+q5pHJLsk+TLST7Tdy0LlWRVkiub3517kvzUQl9zRQZEktczuEL7sKp6DfDBnktasCTrgJ8B/qbvWsZgC/DjVfWTwP8Gzu65nnkbmjbmjcChwNuSHNpvVQvyJHBWVR0KHAOcucQ/zx7vAe7pu4gxuQD4y6p6NXAYY/hcKzIggF8HzquqxwGqalfP9YzD+cBvAUv+pFJVfa6qnmxWb2RwPcxS88y0MVX1BLBn2pglqaoeqKrbmuVHGPzxWdNvVQuTZC3wJuCivmtZqCQvA/4lcDFAVT1RVd9d6Ouu1IB4JfC6JDcl+WKSo/ouaCGSnAzsrKqv9F1LB34F+GzfReyFtmljlvQf1D2SbACOAG7qt5IF+wMGX6qe7ruQMTgY2A18pDlkdlGSFy/0RSdumOu4JPk88KMtT/02g899AIOu8lHAFUleURM8pGuOz3MOg8NLS8Zsn6eqrm62+W0GhzYuX8zaNLMkLwE+Cby3qh7uu569leTngF1VdWuS4/quZwyeDxwJvLuqbkpyAbAJ+I8LfdFlqap+eqbnkvw68KkmEG5O8jSD+Ut2L1Z98zXT50nyEwy+PXwlCQwOx9yW5Oiq+vYiljgvs/37ACT5ZeDngBMmObhnMee0MUtNkn0ZhMPlVfWpvutZoGOBNyc5Cdgf+KEkf1pVv9RzXXtrB7Cjqvb06q5kEBALslIPMX0aeD1AklcCL2CJTtZVVXdU1curakNVbWDwH+XISQ6HuTQ3jfot4M1V9Vjf9eylZTVtTAbfPi4G7qmqD/Vdz0JV1dlVtbb5nTkV+MISDgea3/f7k7yqaTqBMdwmYdn2IOZwCXBJkjuBJ4DTlui31OXqD4H9gC1Nr+jGqvq1fkuan2U4bcyxwNuBO5Jsa9rOaWY+0GR4N3B584Xk68DpC31Br6SWJLVaqYeYJElzMCAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLU6v8DOws+VOzo+gIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test['f'] - df_test['predictions']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensorflow LinearRegressor Estimator\n",
    "Now we'll reproduce this with the high-level estimator API. Surprisingly, the calculations here take much longer than in the basic approach above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(df_train, shuffle=True, num_epochs=100, y=df_train['f'], batch_size=NUM_RECORDS)\n",
    "feature_columns = [\n",
    "    fc.numeric_column('x', dtype=tf.float32),\n",
    "    fc.numeric_column('y', dtype=tf.float32)\n",
    "]\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/cy/7hf1bx3113n2tbn4fvbjx0pc0000gn/T/tmp183sakuq\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/cy/7hf1bx3113n2tbn4fvbjx0pc0000gn/T/tmp183sakuq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 5, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12b668780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, config=config )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Perform the training on the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/cy/7hf1bx3113n2tbn4fvbjx0pc0000gn/T/tmp183sakuq/model.ckpt.\n",
      "INFO:tensorflow:loss = 377856.8, step = 1\n",
      "INFO:tensorflow:global_step/sec: 7.87774\n",
      "INFO:tensorflow:loss = 183399.25, step = 6 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3908\n",
      "INFO:tensorflow:loss = 123422.55, step = 11 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5092\n",
      "INFO:tensorflow:loss = 89214.734, step = 16 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.42879\n",
      "INFO:tensorflow:loss = 67536.66, step = 21 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.45852\n",
      "INFO:tensorflow:loss = 53648.39, step = 26 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.44646\n",
      "INFO:tensorflow:loss = 44181.844, step = 31 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.05176\n",
      "INFO:tensorflow:loss = 37611.24, step = 36 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.27736\n",
      "INFO:tensorflow:loss = 32533.021, step = 41 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3518\n",
      "INFO:tensorflow:loss = 29356.66, step = 46 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4399\n",
      "INFO:tensorflow:loss = 26966.238, step = 51 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0994\n",
      "INFO:tensorflow:loss = 24959.41, step = 56 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7811\n",
      "INFO:tensorflow:loss = 23753.627, step = 61 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1627\n",
      "INFO:tensorflow:loss = 22974.166, step = 66 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3853\n",
      "INFO:tensorflow:loss = 22359.207, step = 71 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2519\n",
      "INFO:tensorflow:loss = 21731.098, step = 76 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4553\n",
      "INFO:tensorflow:loss = 21335.025, step = 81 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6286\n",
      "INFO:tensorflow:loss = 21239.354, step = 86 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1213\n",
      "INFO:tensorflow:loss = 21035.191, step = 91 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1278\n",
      "INFO:tensorflow:loss = 20808.258, step = 96 (0.276 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/cy/7hf1bx3113n2tbn4fvbjx0pc0000gn/T/tmp183sakuq/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20760.562.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x12b668b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.train(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparing The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_test = tf.estimator.inputs.pandas_input_fn(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = regressor.predict(input_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/cy/7hf1bx3113n2tbn4fvbjx0pc0000gn/T/tmp183sakuq/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pred_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.421837</td>\n",
       "      <td>2.721789</td>\n",
       "      <td>7.242147</td>\n",
       "      <td>6.982780</td>\n",
       "      <td>6.979243</td>\n",
       "      <td>6.737907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.632382</td>\n",
       "      <td>-4.875022</td>\n",
       "      <td>11.584552</td>\n",
       "      <td>11.202274</td>\n",
       "      <td>11.200543</td>\n",
       "      <td>10.947616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.912983</td>\n",
       "      <td>2.531394</td>\n",
       "      <td>0.848731</td>\n",
       "      <td>0.060269</td>\n",
       "      <td>0.052307</td>\n",
       "      <td>0.003874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.086742</td>\n",
       "      <td>-2.603373</td>\n",
       "      <td>-6.433733</td>\n",
       "      <td>-5.371798</td>\n",
       "      <td>-5.383807</td>\n",
       "      <td>-5.212363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.583154</td>\n",
       "      <td>-0.700489</td>\n",
       "      <td>-4.770781</td>\n",
       "      <td>-5.316064</td>\n",
       "      <td>-5.327818</td>\n",
       "      <td>-5.184055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.104859</td>\n",
       "      <td>-3.152265</td>\n",
       "      <td>-6.209662</td>\n",
       "      <td>-5.133586</td>\n",
       "      <td>-5.145506</td>\n",
       "      <td>-4.973069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.323252</td>\n",
       "      <td>4.547638</td>\n",
       "      <td>-13.472069</td>\n",
       "      <td>-9.420323</td>\n",
       "      <td>-9.434083</td>\n",
       "      <td>-9.249619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.887259</td>\n",
       "      <td>1.600672</td>\n",
       "      <td>3.725684</td>\n",
       "      <td>4.474182</td>\n",
       "      <td>4.468920</td>\n",
       "      <td>4.311946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.785658</td>\n",
       "      <td>-4.228159</td>\n",
       "      <td>6.173240</td>\n",
       "      <td>7.185396</td>\n",
       "      <td>7.181186</td>\n",
       "      <td>7.029784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.316506</td>\n",
       "      <td>-4.560759</td>\n",
       "      <td>-3.414165</td>\n",
       "      <td>-2.852632</td>\n",
       "      <td>-2.863264</td>\n",
       "      <td>-2.734170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y          f          p  predictions  pred_estimator\n",
       "0  4.421837  2.721789   7.242147   6.982780     6.979243        6.737907\n",
       "1  4.632382 -4.875022  11.584552  11.202274    11.200543       10.947616\n",
       "2  0.912983  2.531394   0.848731   0.060269     0.052307        0.003874\n",
       "3 -3.086742 -2.603373  -6.433733  -5.371798    -5.383807       -5.212363\n",
       "4 -2.583154 -0.700489  -4.770781  -5.316064    -5.327818       -5.184055\n",
       "5 -3.104859 -3.152265  -6.209662  -5.133586    -5.145506       -4.973069\n",
       "6 -3.323252  4.547638 -13.472069  -9.420323    -9.434083       -9.249619\n",
       "7  2.887259  1.600672   3.725684   4.474182     4.468920        4.311946\n",
       "8  2.785658 -4.228159   6.173240   7.185396     7.181186        7.029784\n",
       "9 -2.316506 -4.560759  -3.414165  -2.852632    -2.863264       -2.734170"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_estimator = [f['predictions'][0] for f in generator]\n",
    "df_test['pred_estimator'] = pred_estimator\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pre-canned estimator arrives at (almost) the same results as our hand-made linear regressor. Not that we had a doubt, though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning From Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that the ground truth is a totally unexpected function of the week day and time of day. That could happen e.g., if you measure the humidity and fail to realize that your sensor is near a dry-cleaner's. Let's assume the dry-cleaner's have peek hours on Mon, Tue, Wed from 18:00h to 21:00 and Fri, Sat from 14:00h to 16:00h. During those hours humidity is significantly higher due to the steam produced there. \n",
    "\n",
    "First, let's create a dataset that reflects that situation. Day of week and hour of day shall be represented by categorical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe with days of week and hour-of-day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a constant, if the hour of week \n",
    "conditions = np.array([\n",
    "    (0, 18), (0, 19), (0, 20), (0, 21), # Mondays\n",
    "    (1, 18), (1, 19), (1, 20), (1, 21), # Tuesdays\n",
    "    (2, 18), (2, 19), (2, 20), (2, 21), # Wednesdays\n",
    "    # closed on Thursdays\n",
    "    (4, 14), (4, 15), (4, 16),          # Fridays\n",
    "    (5, 14), (5, 15), (5, 16)           # Saturdays\n",
    "    # closed on Sundays\n",
    "    ])\n",
    "\n",
    "def make_noisy_amplitude_function(amplitude):\n",
    "    def _f(c1, c2):\n",
    "        zipped = zip(c1,c2)\n",
    "        res = array_in(zipped, conditions)        \n",
    "        return res * (np.random.normal( 0 * res, .2 ) + amplitude)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v2(size, amplitude=5.0):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    dow_data = np.random.randint(7, size=size)\n",
    "    hod_data = np.random.randint(24, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    \n",
    "    f_special = make_noisy_amplitude_function(amplitude)(dow_data, hod_data)\n",
    "\n",
    "    f_total = f_data + f_special\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'dow': dow_data, 'hod': hod_data, 'f_orig': f_data, 'p': f_perf, 'special': f_special, 'f': f_total})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dow</th>\n",
       "      <th>hod</th>\n",
       "      <th>f_orig</th>\n",
       "      <th>p</th>\n",
       "      <th>special</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.434463</td>\n",
       "      <td>2.611624</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.723552</td>\n",
       "      <td>-0.936887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.723552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.515673</td>\n",
       "      <td>1.674799</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-3.378942</td>\n",
       "      <td>-2.368745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.378942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.762068</td>\n",
       "      <td>-0.257951</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.573010</td>\n",
       "      <td>-7.895161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.573010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.293598</td>\n",
       "      <td>0.114673</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-7.986032</td>\n",
       "      <td>-5.144533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.986032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.942051</td>\n",
       "      <td>1.991502</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.574093</td>\n",
       "      <td>-9.379854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.574093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.647159</td>\n",
       "      <td>0.453196</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>2.567720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.729679</td>\n",
       "      <td>-4.162701</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>-9.673458</td>\n",
       "      <td>-7.878008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.673458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.388270</td>\n",
       "      <td>4.353431</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>-5.276994</td>\n",
       "      <td>-7.453255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.276994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.936654</td>\n",
       "      <td>1.052962</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4.992209</td>\n",
       "      <td>4.846827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.992209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.657399</td>\n",
       "      <td>1.929293</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.013177</td>\n",
       "      <td>-0.149848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-3.483456</td>\n",
       "      <td>3.254133</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>-9.240877</td>\n",
       "      <td>-9.093978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.240877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.901805</td>\n",
       "      <td>0.760880</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9.167588</td>\n",
       "      <td>8.923170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.167588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.678610</td>\n",
       "      <td>-4.483805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.880276</td>\n",
       "      <td>3.099122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.880276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.761952</td>\n",
       "      <td>3.136413</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.188926</td>\n",
       "      <td>-0.544302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.815532</td>\n",
       "      <td>4.844921</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.993123</td>\n",
       "      <td>0.708603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.993123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3.799962</td>\n",
       "      <td>-4.041785</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>-4.635633</td>\n",
       "      <td>-6.079032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.635633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.013944</td>\n",
       "      <td>-4.293043</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.128083</td>\n",
       "      <td>3.674409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.128083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.628499</td>\n",
       "      <td>4.738225</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>6.895222</td>\n",
       "      <td>6.387886</td>\n",
       "      <td>9.892573</td>\n",
       "      <td>16.787795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.730700</td>\n",
       "      <td>-0.054843</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.263551</td>\n",
       "      <td>4.988822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.263551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-3.110574</td>\n",
       "      <td>-3.197846</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>-6.167035</td>\n",
       "      <td>-5.122224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.167035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         y  dow  hod    f_orig         p   special          f\n",
       "0   0.434463  2.611624    0   14 -0.723552 -0.936887  0.000000  -0.723552\n",
       "1  -0.515673  1.674799    0   12 -3.378942 -2.368745  0.000000  -3.378942\n",
       "2  -3.762068 -0.257951    3   20 -6.573010 -7.895161  0.000000  -6.573010\n",
       "3  -2.293598  0.114673    1   13 -7.986032 -5.144533  0.000000  -7.986032\n",
       "4  -3.942051  1.991502    0   12 -6.574093 -9.379854  0.000000  -6.574093\n",
       "5   1.647159  0.453196    6    5  0.781300  2.567720  0.000000   0.781300\n",
       "6  -4.729679 -4.162701    6   17 -9.673458 -7.878008  0.000000  -9.673458\n",
       "7  -2.388270  4.353431    0   15 -5.276994 -7.453255  0.000000  -5.276994\n",
       "8   2.936654  1.052962    5    9  4.992209  4.846827  0.000000   4.992209\n",
       "9   0.657399  1.929293    1    7  1.013177 -0.149848  0.000000   1.013177\n",
       "10 -3.483456  3.254133    5   17 -9.240877 -9.093978  0.000000  -9.240877\n",
       "11  4.901805  0.760880    6   12  9.167588  8.923170  0.000000   9.167588\n",
       "12  0.678610 -4.483805    1    0  1.880276  3.099122  0.000000   1.880276\n",
       "13  0.761952  3.136413    5   13  0.188926 -0.544302  0.000000   0.188926\n",
       "14  1.815532  4.844921    0    9  2.993123  0.708603  0.000000   2.993123\n",
       "15 -3.799962 -4.041785    5   13 -4.635633 -6.079032  0.000000  -4.635633\n",
       "16  1.013944 -4.293043    5    0  3.128083  3.674409  0.000000   3.128083\n",
       "17  4.628499  4.738225    1   20  6.895222  6.387886  9.892573  16.787795\n",
       "18  2.730700 -0.054843    0    3  3.263551  4.988822  0.000000   3.263551\n",
       "19 -3.110574 -3.197846    3   13 -6.167035 -5.122224  0.000000  -6.167035"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v2 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "df_train_v2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create a data set suitable for training\n",
    "In the following, our assumption that it is particular hours on particular days makes this problem a candidate for the categorical features 'hour of day' and 'day of week'. Hence, in a first step, let's take those two features into account. For that, we have to one-hot encode those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinals = list(df_train_v2['dow'])\n",
    "one_hot_dows = np.transpose(np.eye(7)[ordinals])\n",
    "one_hot_dows[:7,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = list(df_train_v2['hod'])\n",
    "one_hot_hods = np.transpose(np.eye(24)[ordinals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (2, 20000) + (7, 20000) + (24, 20000) = (33, 20000)\n"
     ]
    }
   ],
   "source": [
    "input_numerical = [list(df_train_v2['x']), list(df_train_v2['y'])]\n",
    "lbls_data = [list(df_train_v2['f'])]\n",
    "input_data = np.append(input_numerical, one_hot_dows, axis=0)\n",
    "input_data = np.append(input_data, one_hot_hods, axis=0)\n",
    "print(\"shapes: {} + {} + {} = {}\".format(np.shape(input_numerical), np.shape(one_hot_dows), np.shape(one_hot_hods), np.shape(input_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 33 columns, 31 of which only sparsely populated. That's ok for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43446255, -0.51567307, -3.7620684 , -2.29359801],\n",
       "       [ 2.61162374,  1.6747987 , -0.25795063,  0.11467317],\n",
       "       [ 1.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hereafter, we'll use create_input_data from the tools file to achieve just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_input_data(df, select_feats=[], oh_feats={}, cross_feats=[]):    \n",
      "    \"\"\"\n",
      "    create a list of input columns from pandas raw data\n",
      "    df: a pandas dataframe containing raw input data\n",
      "    select_feats: an array containing the names of features to be selected without transformation\n",
      "    oh_feats: a dictionary containing the names and sizes of discrete numerical features that are to be one-hot encoded\n",
      "    cross_feats: a list of oh_feats consisting of two discrete features to cross\n",
      "    \"\"\"\n",
      "\n",
      "    def _safe_append(l, r):\n",
      "        if l == [] or l is None:\n",
      "            return r\n",
      "        else:\n",
      "            return np.append(l, r, axis=0)\n",
      "\n",
      "    res = [list(df[n]) for n in select_feats]\n",
      "    \n",
      "    for k in oh_feats:\n",
      "        res = _safe_append(res, one_hot(df[k], oh_feats[k]))\n",
      "\n",
      "    for c in cross_feats:\n",
      "        keys = list(c.keys())\n",
      "        keys.sort()\n",
      "        \n",
      "        lk, ls = keys[0], c[keys[0]]\n",
      "        rk, rs = keys[1], c[keys[1]]\n",
      "        lhs = one_hot(df[lk], ls)\n",
      "        rhs = one_hot(df[rk], rs)\n",
      "        cross = [(lhs[:,i].reshape(ls,1) * rhs[:,i].reshape(1,rs)).reshape(rs*ls) for i in range(len(df))]\n",
      "        cross = np.transpose(cross)\n",
      "        res = _safe_append(res, cross)\n",
      "\n",
      "    return res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(create_input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create the network and start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use once more our self-made linear regressor. Below is the code that we hade previously, only this time augmented by the 24 + 7 new input features from the categorical columns. Observe that we train a long time with a lot more data, and the training loss still doesn't improve much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_DIM = 2 # namely x and y\n",
    "WEEKDAY_DIM = 7 # obviously\n",
    "HOUR_OF_DAY_DIM = 24\n",
    "X_DIM = NUMERICAL_DIM + WEEKDAY_DIM + HOUR_OF_DAY_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 8.156059265136719"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.156059"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear2 = Linear(X_DIM, .01)\n",
    "linear2.train(sess, input_data, lbls_data, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That loss is significantly larger than the one that we experienced in the simple case. So either the signal/noise ratio is worse (we know it isn't) or there's some signal in the data that we don't recognize yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sometimes the distribution of the prediction errors reveals additional facts of the problems that our network has. Usually we'll need large enough samples to allow for sufficient statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predicted</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.825540</td>\n",
       "      <td>-4.442504</td>\n",
       "      <td>-3.782084</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.329561</td>\n",
       "      <td>-9.379998</td>\n",
       "      <td>-9.279288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.774609</td>\n",
       "      <td>-10.276996</td>\n",
       "      <td>-9.495276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.276895</td>\n",
       "      <td>-1.121980</td>\n",
       "      <td>-0.968489</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.294388</td>\n",
       "      <td>6.978662</td>\n",
       "      <td>5.994357</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-7.229097</td>\n",
       "      <td>-8.510607</td>\n",
       "      <td>-8.382927</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.506073</td>\n",
       "      <td>4.695551</td>\n",
       "      <td>9.622369</td>\n",
       "      <td>9.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.755718</td>\n",
       "      <td>6.656700</td>\n",
       "      <td>7.401284</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-7.178016</td>\n",
       "      <td>-5.693405</td>\n",
       "      <td>-1.123306</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4.965578</td>\n",
       "      <td>-6.644349</td>\n",
       "      <td>-6.017790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p  predicted   special\n",
       "0  -4.825540  -4.442504  -3.782084  0.000000\n",
       "1  -6.329561  -9.379998  -9.279288  0.000000\n",
       "2 -10.774609 -10.276996  -9.495276  0.000000\n",
       "3  -2.276895  -1.121980  -0.968489  0.000000\n",
       "4   5.294388   6.978662   5.994357  0.000000\n",
       "5  -7.229097  -8.510607  -8.382927  0.000000\n",
       "6  12.506073   4.695551   9.622369  9.999974\n",
       "7   5.755718   6.656700   7.401284  0.000000\n",
       "8  -7.178016  -5.693405  -1.123306  0.000000\n",
       "9  -4.965578  -6.644349  -6.017790  0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_v2 = create_data_frame_v2(size = 20000, amplitude=10)\n",
    "test_data = create_input_data(df=df_test_v2, select_feats=['x','y'], oh_feats={'dow': 7, 'hod': 24})\n",
    "\n",
    "pred = linear2.predict(x_data=test_data, sess=sess)\n",
    "df_test_v2['predicted'] = pred[0]\n",
    "df_test_v2[['f', 'p', 'predicted', 'special']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test_v2['predicted'] - df_test_v2['f']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the error distribution that there's some really interesting stuff going on. This is almost certainly a hint that our data contains structure that we didn't discover yet. This distribution is telling: For the majority of the data - the large bump - we have a tendency to over-predict. For some minority though we significantly under-predict. This is a typical sign that the linear regression is finding a weak compromise between two distinct and somehow unrelated distributions that make up our total input data.\n",
    "\n",
    "Obviously, although or network actually had all the information it needed, simply adding the categorical features didn't allow it to learn the specific characteristic, namely the \"and\" relationship like in: \"The humidity is higher, when it's Wednesday *and* it's 18:00h\". \n",
    "\n",
    "Feature crossings and embeddings to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example: This is Wednesday, 08:00h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday = np.array([[0,0,1,0,0,0,0]])\n",
    "at_0800 = np.zeros((1,24))\n",
    "at_0800[0,8] = 1\n",
    "wednesday, at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossing categorical features $a$ and $b$ means: Put a 1 only where both $a$ and $b$ have a one. Put zeros anywhere else. Python broadcasting helps us achieve that with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday_at_0800 = wednesday.T * at_0800\n",
    "wednesday_at_0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = np.reshape(wednesday_at_0800, newshape=(1,-1))\n",
    "np.argmax(cross) == 2 * 24 + 8 # Wed * 24 + at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets a little more involved when dealing with a batch of feature pairs as you can see in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dows = np.array([[0,0,1,0,0,0,0],[0,0,0,0,0,1,0]])\n",
    "hods = np.zeros((2,24))\n",
    "hods[0,8] = 1\n",
    "hods[1,16] = 1\n",
    "dows, hods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(dows[i].reshape(7,1) * hods[i].reshape(1,24)).reshape(168) for i in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now, instead of feeding both features independently we feed the feature cross into our linear regression model. Note that we need a lot of data to have sufficient statistics for each hour of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 20000), 20000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_RECORDS = 20000\n",
    "\n",
    "df_train_v3 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "input_data_v3 = create_input_data(df=df_train_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "lbls_data_v3 = [list(df_train_v3['f'])]\n",
    "input_data_v3.shape, len(lbls_data_v3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.077442169189453"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0774422"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_v3 = Linear(lr=.05, x_dim=170)\n",
    "regressor_v3.train(sess=sess, num_steps=4000, x_data=input_data_v3, labels_data=lbls_data_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can see that the loss function has indeed gone down dramatically. Now let's examine the error statistics on some fresh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_v3 = create_data_frame_v2(size = 20000, amplitude=10.0)\n",
    "input_data_test_v3 = create_input_data(df=df_test_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "preds = regressor_v3.predict(sess=sess, x_data=input_data_test_v3)\n",
    "\n",
    "errors = preds[0] - df_test_v3['f']\n",
    "df_test_v3['preds'] = preds[0]\n",
    "df_test_v3['err'] = errors\n",
    "df_test_v3['err'].plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, there's some subtle asymmetry in the error distribution, depending on how long you trained, but we can see that the characteristic second bump has disappeared. When we look at the weights associated with the 168 different hours of a week, we spot a few larger positive values amongst otherwise smaller negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.92451054, -0.9105595 , -0.7312683 , -0.99688226, -0.82971704,\n",
       "       -0.9796364 , -1.0322107 , -0.7919396 , -0.9527571 , -0.83081305,\n",
       "       -0.8958984 , -1.1073065 , -0.8674313 , -1.0217636 , -0.8798526 ,\n",
       "       -1.0595101 , -0.9710994 , -0.9295249 ,  8.123133  ,  8.147578  ,\n",
       "        8.058648  ,  7.983456  , -1.0556803 , -1.027305  , -0.9248636 ,\n",
       "       -0.9859836 , -0.82457083, -0.8321773 , -1.0499196 , -0.87207127,\n",
       "       -0.947699  , -0.86126167, -0.95848054, -0.9792089 , -1.045009  ,\n",
       "       -1.064327  , -0.93257385, -0.99947834, -1.1326177 , -0.9904683 ,\n",
       "       -0.7458987 , -1.0242755 ,  7.9645324 ,  8.168488  ,  7.723741  ,\n",
       "        8.146595  , -1.1398586 , -1.1344804 , -0.98596895, -1.0821922 ,\n",
       "       -0.71281946, -1.1208999 , -1.0399061 , -0.9765209 , -0.8167832 ,\n",
       "       -1.0876834 , -0.7790154 , -0.9157768 , -1.1180328 , -1.0416971 ,\n",
       "       -0.8730049 , -1.0084373 , -1.1433038 , -1.0723602 , -1.0801103 ,\n",
       "       -0.93582433,  8.107384  ,  8.155861  ,  8.008792  ,  7.757335  ,\n",
       "       -0.85199356, -0.9803269 , -0.94283867, -0.9840081 , -0.7489897 ,\n",
       "       -0.94832605, -1.0091559 , -0.9808731 , -0.919946  , -1.0263878 ,\n",
       "       -1.0453731 , -0.8758226 , -0.8415308 , -1.0424273 , -0.92115057,\n",
       "       -0.96765345, -1.0533527 , -1.0767367 , -0.91994476, -0.93905795,\n",
       "       -1.0989368 , -1.19071   , -0.9833116 , -1.1140475 , -0.988632  ,\n",
       "       -1.1811286 , -0.8195832 , -1.1491923 , -1.1514249 , -0.9695134 ,\n",
       "       -0.979766  , -0.85492736, -1.0220361 , -1.0422839 , -0.9821452 ,\n",
       "       -0.9227496 , -0.7754158 , -1.0945932 , -1.0193996 , -1.012043  ,\n",
       "        8.251155  ,  8.360069  ,  8.1040745 , -0.7086211 , -0.96290857,\n",
       "       -1.0297557 , -1.0191088 , -1.0627153 , -1.1265033 , -1.0697111 ,\n",
       "       -0.6533825 , -1.0063968 , -0.9657451 , -1.0264463 , -0.9735221 ,\n",
       "       -1.0256922 , -1.1541448 , -0.9370887 , -1.0466963 , -1.0248761 ,\n",
       "       -0.7083373 , -1.0560411 , -0.9410085 , -0.8884615 ,  8.142945  ,\n",
       "        8.177367  ,  8.120462  , -0.83838344, -0.8577857 , -1.0459346 ,\n",
       "       -0.71018994, -1.0159345 , -0.90269953, -1.0486947 , -1.0387725 ,\n",
       "       -0.8562905 , -0.7452074 , -0.96747535, -0.93895286, -0.9667377 ,\n",
       "       -0.8836553 , -0.9882548 , -0.9882449 , -1.0356299 , -0.958836  ,\n",
       "       -0.91102797, -1.0106868 , -0.98913574, -0.86154336, -0.87688667,\n",
       "       -0.8059427 , -1.0209804 , -0.9935925 , -0.9159556 , -1.0026686 ,\n",
       "       -1.1255628 , -0.85760087, -0.9333978 ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = regressor_v3.M.eval()\n",
    "weights_t = weights.squeeze()[2:]\n",
    "weights_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes of the larger values allow us to discover exactly those hours of week during which the dry-cleaner anomalies are observed. The network truly learned when these anomalies are typically observed and adds some more humidity in its prediction during those times of the week. Ain't that cool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.75, 18), array([ 0, 18])),\n",
       " ((0.7916666666666666, 19), array([ 0, 19])),\n",
       " ((0.8333333333333334, 20), array([ 0, 20])),\n",
       " ((0.875, 21), array([ 0, 21])),\n",
       " ((1.75, 18), array([ 1, 18])),\n",
       " ((1.7916666666666667, 19), array([ 1, 19])),\n",
       " ((1.8333333333333333, 20), array([ 1, 20])),\n",
       " ((1.875, 21), array([ 1, 21])),\n",
       " ((2.75, 18), array([ 2, 18])),\n",
       " ((2.7916666666666665, 19), array([ 2, 19])),\n",
       " ((2.8333333333333335, 20), array([ 2, 20])),\n",
       " ((2.875, 21), array([ 2, 21])),\n",
       " ((4.583333333333333, 14), array([ 4, 14])),\n",
       " ((4.625, 15), array([ 4, 15])),\n",
       " ((4.666666666666667, 16), array([ 4, 16])),\n",
       " ((5.583333333333333, 14), array([ 5, 14])),\n",
       " ((5.625, 15), array([ 5, 15])),\n",
       " ((5.666666666666667, 16), array([ 5, 16]))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [i for i in range(168) if weights_t[i] > 1]\n",
    "how_detected = [(i / 24, i % 24 ) for i in indexes]\n",
    "how_detected = sorted(how_detected, key=lambda d: d[0])\n",
    "list(zip(how_detected, conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the left, the hours of the week as detected by the network, to the left the conditions that lead to the anomalies in the data. A perfect fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 19, 20, 21, 42, 43, 44, 45, 66, 67, 68, 69, 110, 111, 112, 134, 135, 136]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.75, 18),\n",
       " (0.7916666666666666, 19),\n",
       " (0.8333333333333334, 20),\n",
       " (0.875, 21),\n",
       " (1.75, 18),\n",
       " (1.7916666666666667, 19),\n",
       " (1.8333333333333333, 20),\n",
       " (1.875, 21),\n",
       " (2.75, 18),\n",
       " (2.7916666666666665, 19),\n",
       " (2.8333333333333335, 20),\n",
       " (2.875, 21),\n",
       " (4.583333333333333, 14),\n",
       " (4.625, 15),\n",
       " (4.666666666666667, 16),\n",
       " (5.583333333333333, 14),\n",
       " (5.625, 15),\n",
       " (5.666666666666667, 16)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i // 24, i % 24 ) for i in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
