{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from google.cloud import bigquery as bq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'airline', 'airline_code', 'departure_airport', 'departure_state', 'departure_lat', 'departure_lon', 'arrival_airport', 'arrival_state', 'arrival_lat', 'arrival_lon', 'departure_schedule', 'departure_actual', 'departure_delay', 'arrival_schedule', 'arrival_actual', 'arrival_delay']\n"
     ]
    }
   ],
   "source": [
    "KEYS = 'date,airline,airline_code,departure_airport,departure_state,departure_lat,departure_lon,arrival_airport,arrival_state,arrival_lat,arrival_lon,departure_schedule,departure_actual,departure_delay,arrival_schedule,arrival_actual,arrival_delay'\n",
    "KEYS = KEYS.split(',')\n",
    "print(KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 ATL_1_4_9.csv > atl_1_4_9.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = PipelineOptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention: Mind The Transforms' Return Values!\n",
    "The important thing to notice in designing ```Transform```s is that ParDo Transforms always have an outer list of what they return. See ```ParseToList``` below for illustration. ```Map``` functions return the result as they computed it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseToList(beam.DoFn):\n",
    "\n",
    "    def process(self, element):\n",
    "        return [element.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnFilter(beam.DoFn): \n",
    "    \n",
    "    def __init__(self, index, predicate):\n",
    "        \"\"\"\n",
    "        param index: the index of the column to be compared against in the the file\n",
    "        param predicate: a function taking a single argument and returning a boolean\n",
    "        \"\"\"\n",
    "        super(beam.DoFn, self).__init__()\n",
    "        self.predicate = predicate\n",
    "        self.index = index\n",
    "    def process(self, element):\n",
    "        if self.predicate(element[self.index]):\n",
    "            return [element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-04-01,MQ,20398,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,2000,1955,-5,2110,2033,-37\n",
      "2009-04-01,MQ,20398,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1325,1324,-1,1435,1414,-21\n",
      "2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,704,700,-4,813,748,-25\n",
      "2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1705,1658,-7,1821,1757,-24\n",
      "2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1009,1004,-5,1118,1127,9\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline(options=options) as p:\n",
    "    lines = p | 'ReadFile' >> beam.io.ReadFromText('atl_1_4_9.csv',skip_header_lines=1)\n",
    "    out = (lines\n",
    "        | \"Parser\" >> beam.ParDo(ParseToList()) \n",
    "        | \"Filter\" >> beam.ParDo(ColumnFilter(KEYS.index('arrival_airport'), lambda x: x == 'ORD')) \n",
    "        | \"ToCommaSepString\" >> beam.Map(lambda e: \",\".join(e))\n",
    "        | \"Write\" >> beam.io.WriteToText(\"out.csv\"))\n",
    "!cat out.csv-00000-of-00001\n",
    "! rm -rf out.csv-00000-of-00001 beam-temp-out.csv* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "If you just want to play around with no IO on either end just pipe an array into your chain of transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('atl_1_4_9.csv') as f:\n",
    "    content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009-04-01,MQ,20398,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,2000,1955,-5,2110,2033,-37\\n',\n",
       " '2009-04-01,MQ,20398,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1325,1324,-1,1435,1414,-21\\n',\n",
       " '2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,704,700,-4,813,748,-25\\n',\n",
       " '2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1705,1658,-7,1821,1757,-24\\n',\n",
       " '2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1009,1004,-5,1118,1127,9\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(content         \n",
    " | \"Parser\" >> beam.ParDo(ParseToList()) \n",
    " | \"Filter\" >> beam.ParDo(ColumnFilter(KEYS.index('arrival_airport'), lambda x: x == 'ORD'))\n",
    " | \"ToCommaSepString\" >> beam.Map(lambda e: \",\".join(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Combiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,airline,airline_code,departure_airport,departure_state,departure_lat,departure_lon,arrival_airport,arrival_state,arrival_lat,arrival_lon,departure_schedule,departure_actual,departure_delay,arrival_schedule,arrival_actual,arrival_delay\n",
      "2009-04-01,F9,20436,ATL,GA,33.63,-84.42,DEN,CO,39.86,-104.67,944,939,-5,1110,1110,0\n",
      "2009-04-01,F9,20436,ATL,GA,33.63,-84.42,DEN,CO,39.86,-104.67,1600,1629,29,1724,1815,51\n",
      "2009-04-01,F9,20436,ATL,GA,33.63,-84.42,DEN,CO,39.86,-104.67,1920,1920,0,2046,2049,3\n",
      "2009-04-01,MQ,20398,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,2000,1955,-5,2110,2033,-37\n",
      "2009-04-01,MQ,20398,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1325,1324,-1,1435,1414,-21\n",
      "2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,704,700,-4,813,748,-25\n",
      "2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1705,1658,-7,1821,1757,-24\n",
      "2009-04-01,UA,19977,ATL,GA,33.63,-84.42,ORD,IL,41.98,-87.9,1009,1004,-5,1118,1127,9\n",
      "2009-04-01,CO,19704,ATL,GA,33.63,-84.42,EWR,NJ,40.69,-74.16,1915,2057,102,2146,2331,105\n"
     ]
    }
   ],
   "source": [
    "!cat atl_1_4_9.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORD,-19.6\n",
      "EWR,105.0\n",
      "DEN,18.0\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline(options=options) as p:\n",
    "    lines = p | 'ReadFile' >> beam.io.ReadFromText('atl_1_4_9.csv',skip_header_lines=1)\n",
    "    out = (lines\n",
    "        | \"Parser\" >> beam.ParDo(ParseToList()) \n",
    "        | \"Select\" >> beam.Map(lambda elem: (elem[KEYS.index('arrival_airport')],int(elem[KEYS.index('arrival_delay')])))\n",
    "        | \"Group_by_dep\" >> beam.GroupByKey()\n",
    "        | \"Average\" >> beam.Map(lambda e: (e[0], np.sum(e[1], dtype='float')/len(e[1])))\n",
    "        | \"ToCommaSepString\" >> beam.Map(lambda e: \"{},{}\".format(e[0],e[1]))\n",
    "        | \"Write\" >> beam.io.WriteToText(\"out.csv\"))\n",
    "!cat out.csv-00000-of-00001\n",
    "! rm -rf out.csv-00000-of-00001 beam-temp-out.csv* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5] | beam.CombineGlobally(lambda l: sum(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Reading from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  num_babies\n",
      "0  2003     4096092\n",
      "1  2004     4118907\n",
      "2  2008     4255156\n",
      "3  2006     4273225\n",
      "4  2002     4027376\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  year,\n",
    "  COUNT(1) as num_babies\n",
    "FROM\n",
    "  publicdata.samples.natality\n",
    "WHERE\n",
    "  year > 2000\n",
    "GROUP BY\n",
    "  year\n",
    "\"\"\"\n",
    "df = pd.read_gbq(query,\n",
    "                     project_id='going-tfx',\n",
    "                     dialect='standard')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "SELECT\n",
    "  ORIGIN,\n",
    "  FL_YEAR,\n",
    "  FL_MONTH,\n",
    "  FL_DOW,\n",
    "  UNIQUE_CARRIER,\n",
    "  DEST,\n",
    "  CRS_ARR_TIME,\n",
    "  DEP_DELAY,\n",
    "  ARR_DELAY\n",
    "FROM `going-tfx.examples.ATL_JUNE` \n",
    "where\n",
    "  MOD(ABS(FARM_FINGERPRINT(\n",
    "    CONCAT(\n",
    "      STRING(TIMESTAMP(FL_DATE)),\n",
    "      UNIQUE_CARRIER,\n",
    "      DEST\n",
    "    )\n",
    "  )) + CRS_ARR_TIME, 10000) = 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>FL_YEAR</th>\n",
       "      <th>FL_MONTH</th>\n",
       "      <th>FL_DOW</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DL</td>\n",
       "      <td>CHS</td>\n",
       "      <td>947</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1217</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1304</td>\n",
       "      <td>7</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DL</td>\n",
       "      <td>MSP</td>\n",
       "      <td>2335</td>\n",
       "      <td>8</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>EV</td>\n",
       "      <td>CAK</td>\n",
       "      <td>1259</td>\n",
       "      <td>-8</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DL</td>\n",
       "      <td>PIT</td>\n",
       "      <td>1923</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>EV</td>\n",
       "      <td>CHO</td>\n",
       "      <td>1626</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DL</td>\n",
       "      <td>RIC</td>\n",
       "      <td>1907</td>\n",
       "      <td>-5</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>UA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>2040</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DL</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2304</td>\n",
       "      <td>35</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN  FL_YEAR  FL_MONTH  FL_DOW UNIQUE_CARRIER DEST  CRS_ARR_TIME  \\\n",
       "0    ATL     2006         6       1             DL  CHS           947   \n",
       "1    ATL     2007         6       1             DL  PHX          1217   \n",
       "2    ATL     2008         6       1             FL  BOS          1304   \n",
       "3    ATL     2010         6       1             DL  MSP          2335   \n",
       "4    ATL     2010         6       1             EV  CAK          1259   \n",
       "5    ATL     2015         6       1             DL  PIT          1923   \n",
       "6    ATL     2015         6       1             EV  CHO          1626   \n",
       "7    ATL     2016         6       1             DL  RIC          1907   \n",
       "8    ATL     2017         6       1             UA  IAH          2040   \n",
       "9    ATL     2017         6       1             DL  LAX          2304   \n",
       "\n",
       "   DEP_DELAY  ARR_DELAY  \n",
       "0          3         -5  \n",
       "1         -1          3  \n",
       "2          7         -5  \n",
       "3          8         -2  \n",
       "4         -8        -21  \n",
       "5          0         -9  \n",
       "6         -3         -4  \n",
       "7         -5        -22  \n",
       "8         -4         -1  \n",
       "9         35         -2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_gbq(query,\n",
    "                     project_id='going-tfx',\n",
    "                     dialect='standard')\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORIGIN',\n",
       " 'FL_YEAR',\n",
       " 'FL_MONTH',\n",
       " 'FL_DOW',\n",
       " 'UNIQUE_CARRIER',\n",
       " 'DEST',\n",
       " 'CRS_ARR_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'ARR_DELAY']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = list(df.keys())\n",
    "KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "options=beam.options.pipeline_options.PipelineOptions().from_dictionary({'project': 'going-tfx'})\n",
    "#options.get_all_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = list(df.keys())\n",
    "def toCsvRow (dict): \n",
    "    row = [str(dict[c]) for c in KEYS]\n",
    "    return \",\".join(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_987c731d90db47628fa978e61d9a21c2 does not exist so we will create it as temporary with location=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL,2012,6,5,AA,DFW,855,-8,-8\n",
      "ATL,2006,6,1,DL,CHS,947,3,-5\n",
      "ATL,2010,6,1,DL,MSP,2335,8,-2\n",
      "ATL,2016,6,1,DL,RIC,1907,-5,-22\n",
      "ATL,2017,6,1,DL,LAX,2304,35,-2\n",
      "ATL,2015,6,1,DL,PIT,1923,0,-9\n",
      "ATL,2007,6,1,DL,PHX,1217,-1,3\n",
      "ATL,2015,6,2,DL,LGA,1915,84,104\n",
      "ATL,2010,6,2,DL,ABQ,1204,-1,-11\n",
      "ATL,2008,6,2,DL,ORD,800,-7,-5\n",
      "ATL,2008,6,3,DL,RSW,1603,-1,-3\n",
      "ATL,2011,6,4,DL,LGA,1259,4,-8\n",
      "ATL,2011,6,4,DL,MCO,1640,3,6\n",
      "ATL,2014,6,4,DL,LAS,1107,-1,-2\n",
      "ATL,2010,6,5,DL,LAS,1245,-3,-8\n",
      "ATL,2017,6,5,DL,MDW,946,-1,-10\n",
      "ATL,2016,6,6,DL,SGF,2107,3,-4\n",
      "ATL,2012,6,6,DL,BWI,1433,-2,-3\n",
      "ATL,2011,6,6,DL,COS,2021,-2,-21\n",
      "ATL,2017,6,6,DL,SLC,2127,33,61\n",
      "ATL,2011,6,6,DL,CHS,935,-2,1\n",
      "ATL,2013,6,7,DL,EYW,1933,-3,-23\n",
      "ATL,2011,6,7,DL,EYW,1709,-5,0\n",
      "ATL,2015,6,1,EV,CHO,1626,-3,-4\n",
      "ATL,2010,6,1,EV,CAK,1259,-8,-21\n",
      "ATL,2012,6,2,EV,ROA,1044,12,9\n",
      "ATL,2012,6,2,EV,VPS,1522,-4,-9\n",
      "ATL,2006,6,2,EV,FNT,1601,2,0\n",
      "ATL,2007,6,3,EV,MDT,2300,181,185\n",
      "ATL,2011,6,4,EV,CRW,2148,-3,-3\n",
      "ATL,2012,6,4,EV,CHO,1631,18,1\n",
      "ATL,2013,6,6,EV,EWN,1335,-5,2\n",
      "ATL,2009,6,7,EV,FAY,1229,-3,-5\n",
      "ATL,2008,6,7,EV,TYS,1040,-5,-15\n",
      "ATL,2008,6,1,FL,BOS,1304,7,-5\n",
      "ATL,2010,6,2,FL,TPA,826,-6,-19\n",
      "ATL,2008,6,2,FL,SAN,2121,-2,-6\n",
      "ATL,2009,6,2,FL,MEM,1312,32,39\n",
      "ATL,2008,6,4,FL,MSP,1819,9,-33\n",
      "ATL,2008,6,4,FL,MEM,2321,120,113\n",
      "ATL,2009,6,4,FL,SJU,1244,13,8\n",
      "ATL,2007,6,5,FL,MSY,2032,-1,-10\n",
      "ATL,2010,6,5,FL,FLL,1213,-1,2\n",
      "ATL,2006,6,5,MQ,ORD,1430,70,87\n",
      "ATL,2017,6,1,UA,IAH,2040,-4,-1\n",
      "ATL,2017,6,5,UA,IAH,1327,270,266\n",
      "ATL,2009,6,3,XE,IAH,2217,-7,-23\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline(options=options) as p:\n",
    "    rows = p | 'read' >> beam.io.Read(beam.io.BigQuerySource(query=query, use_standard_sql=True))\n",
    "    (rows | \"encode\" >> beam.Map(toCsvRow) \\\n",
    "    | \"Write\" >> beam.io.WriteToText(\"out.csv\"))\n",
    "!cat out.csv-00000-of-00001\n",
    "! rm -rf out.csv-00000-of-00001 beam-temp-out.csv* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
