{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Models With Synthetic Data\n",
    "The advantage of synthetic data is that we know the prior or ground truth and we know exactly how concealed it is. That helps us to determine with certainty that an algorithm is per se capable of discovering the ground truth. If an algorithm fails on the easy task of learning from synthetic data, then it won't be good in real life. The opposite, unfortunately, is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "from tools import print_progress, array_in, create_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Noisy Samples From A Well-Known Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a*x+b\n",
    "def make_lin(a, b, rnd):\n",
    "    def _f_a(x):\n",
    "        mu = a*x + b\n",
    "        return rnd(mu)\n",
    "    return _f_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Two linear but noisy signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = make_lin(2, 1, lambda mu: np.random.normal(loc=mu, scale=1.0))\n",
    "f_b = make_lin(-.5, -1.5, lambda mu: np.random.normal(loc=mu, scale=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A look at one of the signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([f_a(1) for i in range(1000)])\n",
    "df.plot.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we create a data set/frame representing $f_a(x)+f_b(y)$ as a random variable that depends on random variables $x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v1(size):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'f': f_data, 'p': f_perf})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, this is equivalent to saying that the ground truth is:\n",
    "\n",
    "$$ f(x, y) = 2x - \\frac{1}{2} y - \\frac{1}{2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.619054</td>\n",
       "      <td>-3.947384</td>\n",
       "      <td>-1.068410</td>\n",
       "      <td>2.621126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.792281</td>\n",
       "      <td>1.694921</td>\n",
       "      <td>-0.036683</td>\n",
       "      <td>-4.536574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.225374</td>\n",
       "      <td>-3.211580</td>\n",
       "      <td>-1.020884</td>\n",
       "      <td>1.339622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.555113</td>\n",
       "      <td>-4.633877</td>\n",
       "      <td>-2.330410</td>\n",
       "      <td>-1.053888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.889884</td>\n",
       "      <td>-5.900456</td>\n",
       "      <td>-3.100828</td>\n",
       "      <td>-1.602402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f         p         x         y\n",
       "0 -6.619054 -3.947384 -1.068410  2.621126\n",
       "1  1.792281  1.694921 -0.036683 -4.536574\n",
       "2 -3.225374 -3.211580 -1.020884  1.339622\n",
       "3 -2.555113 -4.633877 -2.330410 -1.053888\n",
       "4 -5.889884 -5.900456 -3.100828 -1.602402"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_data_frame_v1(NUM_RECORDS)\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Linear Regressor From Scratch With Tensorflow\n",
    "Let's train a self-made tensorflow linear regressor with the synthetic data to see whether it finds the coefficients above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Was already closed or didn't exist. That's fine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    print(\"OK. Was already closed or didn't exist. That's fine.\")\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating The Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, x_dim, lr):\n",
    "\n",
    "        # Variables for the parameters: weights M and bias b\n",
    "        self.M = tf.Variable(tf.zeros(shape=(1, x_dim)))\n",
    "        self.b = tf.Variable(0.)\n",
    "\n",
    "        # Placeholders for x and labels\n",
    "        self.x = tf.placeholder(shape=(x_dim,None), dtype=tf.float32)\n",
    "        self.lbls = tf.placeholder(shape=(1,None), dtype=tf.float32)\n",
    "\n",
    "        # The prediction and the distance (loss)\n",
    "        self.f = tf.matmul(self.M, self.x) + self.b\n",
    "        self.d = tf.losses.mean_squared_error(self.lbls, self.f)\n",
    "\n",
    "        # The gradients\n",
    "        self.nM = tf.gradients(self.d, self.M)\n",
    "        self.nb = tf.gradients(self.d, self.b)\n",
    "\n",
    "        # The optimizers\n",
    "        self.aM = tf.assign_add( self.M, tf.multiply(self.nM[0],-lr))\n",
    "        self.ab = tf.assign_add( self.b, tf.multiply(self.nb[0], -lr))\n",
    "\n",
    "        # The initializer\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def train(self, sess, x_data, labels_data, num_steps):        \n",
    "        sess.run(self.init)\n",
    "        for i in range(num_steps):\n",
    "            _, dist, _, _, _, _ = sess.run([self.f, self.d, self.nM, self.nb, self.aM, self.ab], \n",
    "                                           feed_dict = {self.x: x_data, self.lbls: labels_data})\n",
    "            print_progress(\"- Loss: {}\", dist)\n",
    "        return dist\n",
    "    \n",
    "    def predict(self, sess, x_data):\n",
    "        pred = sess.run(self.f, feed_dict={self.x: x_data})\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Perform The Training And Examine The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [list(df_train['x']), list(df_train['y'])]\n",
    "lbls_data = [list(df_train['f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 1.9946308136"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9946308"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = Linear(x_dim=2, lr=0.01)\n",
    "linear1.train(sess, input_data, lbls_data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the parameters to be close to $2, -0.5, -0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9982556 , -0.49578294]], dtype=float32), -0.4844272]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([linear1.M, linear1.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now the tensor f represents the hypothesis. Let's evaluate it with some fresh test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = create_data_frame_v1(size=10000)\n",
    "test_data = [list(df_test['x']), list(df_test['y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear1.predict(sess=sess, x_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.302367</td>\n",
       "      <td>-7.437540</td>\n",
       "      <td>-4.550783</td>\n",
       "      <td>-4.328052</td>\n",
       "      <td>-7.432281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.568293</td>\n",
       "      <td>4.357425</td>\n",
       "      <td>3.248688</td>\n",
       "      <td>3.279901</td>\n",
       "      <td>4.381163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.862282</td>\n",
       "      <td>-10.037311</td>\n",
       "      <td>-3.811622</td>\n",
       "      <td>3.828134</td>\n",
       "      <td>-9.998946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.625595</td>\n",
       "      <td>6.463635</td>\n",
       "      <td>4.061283</td>\n",
       "      <td>2.317860</td>\n",
       "      <td>6.481897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.247317</td>\n",
       "      <td>-2.602588</td>\n",
       "      <td>-0.333457</td>\n",
       "      <td>2.871345</td>\n",
       "      <td>-2.574324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.381897</td>\n",
       "      <td>-1.736223</td>\n",
       "      <td>-0.174087</td>\n",
       "      <td>1.776098</td>\n",
       "      <td>-1.712857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.854462</td>\n",
       "      <td>-0.364786</td>\n",
       "      <td>-0.376819</td>\n",
       "      <td>-1.777705</td>\n",
       "      <td>-0.356053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.150018</td>\n",
       "      <td>8.095863</td>\n",
       "      <td>4.725606</td>\n",
       "      <td>1.710697</td>\n",
       "      <td>8.110406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.006145</td>\n",
       "      <td>-1.552918</td>\n",
       "      <td>0.466763</td>\n",
       "      <td>3.972886</td>\n",
       "      <td>-1.521405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.429570</td>\n",
       "      <td>2.996367</td>\n",
       "      <td>1.335520</td>\n",
       "      <td>-1.650657</td>\n",
       "      <td>3.002650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions\n",
       "0  -7.302367  -7.437540 -4.550783 -4.328052    -7.432281\n",
       "1   5.568293   4.357425  3.248688  3.279901     4.381163\n",
       "2 -10.862282 -10.037311 -3.811622  3.828134    -9.998946\n",
       "3   5.625595   6.463635  4.061283  2.317860     6.481897\n",
       "4  -4.247317  -2.602588 -0.333457  2.871345    -2.574324\n",
       "5  -1.381897  -1.736223 -0.174087  1.776098    -1.712857\n",
       "6  -0.854462  -0.364786 -0.376819 -1.777705    -0.356053\n",
       "7   8.150018   8.095863  4.725606  1.710697     8.110406\n",
       "8  -2.006145  -1.552918  0.466763  3.972886    -1.521405\n",
       "9   1.429570   2.996367  1.335520 -1.650657     3.002650"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'] = predictions[0]\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see without surprise that the predictions are typically closer to the ground truth than to the noisy signal. This means we have enough data to average out the noise and reveal the ground truth. A look at the distribution of the errors reveals pure noise around 0. That's typically a good sign that our network has understood the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFMdJREFUeJzt3XuwZWV55/HvzwYBLxEZWtLpSw7OoA6acJlDY8o4ozAmiMbGqsRATRQJsU0CRmuoiQ2ZGZ3KUEUyRILjhLIVIhgSwqAIEUzSKKVlVQAbRK4x9iiGblu6YwQkOBDgmT/2OrAHV/fZ57LO2uec76dq117rXZf9LOh9nv1e1rtSVUiS9GzP6TsASdJ4MkFIklqZICRJrUwQkqRWJghJUisThCSplQlCktTKBCFJamWCkCS12qfvAObi4IMPromJib7DkKRF5dZbb/2Hqlo53X6LOkFMTEywdevWvsOQpEUlybdH2c8mJklSKxOEJKmVCUKS1MoEIUlqZYKQJLUyQUiSWpkgJEmtTBCSpFYmCElSq87upE6yP/AlYL/mc66qqg8k+QTw74CHml3fWVW3JwlwIXAi8GhTfltX8UkLaWLTdU8v33fem3qMRBpdl1NtPAYcV1WPJNkX+HKSzzXb/lNVXfWs/d8IHNa8jgUuat4lST3orImpBh5pVvdtXrWXQzYAlzXH3QQcmGRVV/FJkvau0z6IJCuS3A7sArZU1c3NpnOT3JHkgiT7NWWrgfuHDt/elD37nBuTbE2ydffu3V2GL0nLWqcJoqqerKojgTXA+iSvAs4GXgEcAxwEvH+G59xcVZNVNbly5bSz1UoLamLTdU+/pMVuQUYxVdWDwI3ACVW1s2lGegz4Y2B9s9sOYO3QYWuaMklSD7ocxbQS+OeqejDJAcAbgN9Lsqqqdjajlk4C7moOuRY4M8kVDDqnH6qqnV3FJ80XawtaqrocxbQKuDTJCgY1lSur6rNJvtAkjwC3A7/e7H89gyGu2xgMcz2tw9gkSdPoLEFU1R3AUS3lx+1h/wLO6CoeSdLMLOpHjkqLkTfNabEwQUgdsW9Ci51zMUmSWpkgJEmtTBCSpFb2QUg9ssNa48wahCSplQlCktTKJiZpTOypuclmKPXFGoQkqZU1CGkRsTahhWQNQpLUygQhSWplgpAktTJBSJJa2UktLVJ2WKtr1iAkSa2sQUgz5HMetFxYg5AktTJBSJJadZYgkuyf5JYkX0tyd5L/1pQfmuTmJNuS/HmS5zbl+zXr25rtE13FJkmaXpc1iMeA46rqCOBI4IQkrwZ+D7igqv4V8H3g9Gb/04HvN+UXNPtJknrSWYKogUea1X2bVwHHAVc15ZcCJzXLG5p1mu3HJ0lX8UmS9q7TPogkK5LcDuwCtgD/B3iwqp5odtkOrG6WVwP3AzTbHwL+Rcs5NybZmmTr7t27uwxfkpa1Toe5VtWTwJFJDgSuBl4xD+fcDGwGmJycrLmeT1oKvGlOXViQ+yCq6sEkNwI/AxyYZJ+mlrAG2NHstgNYC2xPsg/wIuB7CxGfNG6810LjoMtRTCubmgNJDgDeANwL3Aj8YrPbqcA1zfK1zTrN9i9UlTUESepJlzWIVcClSVYwSERXVtVnk9wDXJHkvwNfBS5u9r8Y+GSSbcA/Aid3GJs0I/6i13LUWYKoqjuAo1rKvwmsbyn/v8AvdRWPJGlmvJNaktTKBCFJamWCkCS1MkFIklr5PAhpDxy5pOXOGoQkqZUJQpLUyiYmaYlxXibNF2sQkqRWJghJUisThCSplQlCktTKBCFJamWCkCS1MkFIklp5H4Q0xOk1pGdYg5AktTJBSJJamSAkSa1MEJKkVp0liCRrk9yY5J4kdyd5b1P+wSQ7ktzevE4cOubsJNuSfD3Jz3cVm7RcTGy67umXNFNdjmJ6Ajirqm5L8kLg1iRbmm0XVNX5wzsnORw4GXgl8BPADUleVlVPdhijJGkPOksQVbUT2Nks/yDJvcDqvRyyAbiiqh4DvpVkG7Ae+JuuYtTy5ZTY0vQWpA8iyQRwFHBzU3RmkjuSXJLkxU3ZauD+ocO205JQkmxMsjXJ1t27d3cYtSQtb50niCQvAD4FvK+qHgYuAv4lcCSDGsYfzOR8VbW5qiaranLlypXzHq8kaaDTBJFkXwbJ4fKq+jRAVT1QVU9W1VPAxxg0IwHsANYOHb6mKZMk9aDLUUwBLgburaoPDZWvGtrtrcBdzfK1wMlJ9ktyKHAYcEtX8UmS9q7LUUyvAd4O3Jnk9qbsHOCUJEcCBdwHvBugqu5OciVwD4MRUGc4gkmS+tPlKKYvA2nZdP1ejjkXOLermCRJo/NOaklSK6f71rLnXcZSO2sQkqRWJghJUiubmKRlwulFNFMmCGkZMlloFDYxSZJajZQgkvxU14FIksbLqDWIP0pyS5LfTPKiTiOSJI2FkRJEVb0W+A8MJtO7NcmfJnlDp5FJkno1cid1VX0jyX8GtgIfBo5qJuQ7Z2qmVmnc2Bkrzd6ofRA/neQC4F7gOOAXqupfN8sXdBifJKkno9Yg/ifwcQa1hR9OFVbVd5pahSRpiRk1QbwJ+OHU9NtJngPsX1WPVtUnO4tOktSbUUcx3QAcMLT+vKZMkrREjZog9q+qR6ZWmuXndROSJGkcjJog/inJ0VMrSf4N8MO97C9JWuRG7YN4H/C/k3yHwVPifhz45c6ikiT1bqQEUVVfSfIK4OVN0der6p+7C0uS1LeZzOZ6DDDRHHN0Eqrqsk6ikiT1btQb5T4JnA/8LINEcQwwOc0xa5PcmOSeJHcneW9TflCSLUm+0by/uClPkg8n2ZbkjuE+D0nSwhu1BjEJHF5VNYNzPwGcVVW3JXkhgzmctgDvBD5fVecl2QRsAt4PvBE4rHkdC1zUvEvzwmdPSzMz6iimuxh0TI+sqnZW1W3N8g8YTNOxGtgAXNrsdilwUrO8AbisBm4CDkyyaiafKUmaP6PWIA4G7klyC/DYVGFVvWWUg5NMAEcBNwOHVNXOZtN3gUOa5dXA/UOHbW/Kdg6VkWQjsBFg3bp1I4YvSZqpURPEB2f7AUleAHwKeF9VPTyYAHagqirJTJqtqKrNwGaAycnJGR0rSRrdqMNcv5jkJ4HDquqGJM8DVkx3XJJ9GSSHy4emBH8gyaqq2tk0Ie1qyncweN7ElDVNmSSpB6OOYnoXcBXw0aZoNfCZaY4JcDFwb1V9aGjTtcCpzfKpwDVD5e9oRjO9GnhoqClK0gKY2HTd0y9p1CamM4D1DPoQph4e9JJpjnkN8HbgziS3N2XnAOcBVyY5Hfg28LZm2/XAicA24FHgtFEvQpI0/0ZNEI9V1eNT/QdJ9gH22v5fVV9mMC1Hm+Nb9i8GiUiSNAZGTRBfTHIOcEDzLOrfBP6iu7AkLRSbk7Qno94HsQnYDdwJvJtBc5BPkpOkJWzUUUxPAR9rXpKkZWCkBJHkW7T0OVTVS+c9IknSWJjJXExT9gd+CTho/sORZme4Hf2+897UYyTS0jFSH0RVfW/otaOq/hDwWyhJS9ioTUzDU28/h0GNYibPkpAkLTKj/pH/g6HlJ4D7eOYGN0nSEjTqKKbXdx2IJGm8jNrE9B/3tv1Zcy1JkpaAmYxiOobBhHoAvwDcAnyji6AkSf0bNUGsAY5ungxHkg8C11XVr3QVmCSpX6NOtXEI8PjQ+uM88yQ4SdISNGoN4jLgliRXN+sn8cxzpSVJS9Coo5jOTfI54LVN0WlV9dXuwpIk9W3UJiaA5wEPV9WFwPYkh3YUkyRpDIz6yNEPAO8Hzm6K9gX+pKugJEn9G7UG8VbgLcA/AVTVd4AXdhWUJKl/oyaIx5tHghZAkud3F5IkaRyMmiCuTPJR4MAk7wJuwIcHSdKSNuoopvObZ1E/DLwc+K9VtWVvxyS5BHgzsKuqXtWUfRB4F4PHlwKcU1XXN9vOBk4HngR+q6r+auaXI2m++IwNTZsgkqwAbmgm7NtrUniWTwAfYXAPxbALqur8Z33G4cDJwCuBnwBuSPKyqnpyBp8nSZpH0yaIqnoyyVNJXlRVD4164qr6UpKJEXffAFxRVY8B30qyDVgP/M2onydNGf7lK2n2Rr2T+hHgziRbaEYyAVTVb83iM89M8g5gK3BWVX0fWA3cNLTP9qZMktSTURPEp5vXXF0E/C6D0VC/y+BBRL86kxMk2QhsBFi3bt08hCRpOvZHLE97TRBJ1lXV31fVvMy7VFUPDJ37Y8Bnm9UdwNqhXdc0ZW3n2AxsBpicnKz5iEuS9KOmG+b6mamFJJ+a64clWTW0+lbgrmb5WuDkJPs1U3gcxuB5E5KknkzXxJSh5ZfO5MRJ/gx4HXBwku3AB4DXJTmSQRPTfcC7Aarq7iRXAvcweOb1GY5gkqR+TZcgag/L06qqU1qKL97L/ucC587kMyRJ3ZkuQRyR5GEGNYkDmmWa9aqqH+s0OklSb/aaIKpqxUIFIkkaLzN5HoQkaRkZ9T4IqTeOwZf6YQ1CktTKBCFJamUTk6QZsclv+TBBaFFxplZp4djEJElqZYKQJLUyQUiSWpkgJEmtTBCSpFYmCElSKxOEJKmVCUKS1MoEIUlqZYKQJLVyqg1Js+a8TEubNQhJUqvOEkSSS5LsSnLXUNlBSbYk+Ubz/uKmPEk+nGRbkjuSHN1VXJKk0XTZxPQJ4CPAZUNlm4DPV9V5STY16+8H3ggc1ryOBS5q3rVMOWur1L/OahBV9SXgH59VvAG4tFm+FDhpqPyyGrgJODDJqq5ikyRNb6H7IA6pqp3N8neBQ5rl1cD9Q/ttb8okST3pbRRTVVWSmulxSTYCGwHWrVs373FJmp1nNws6qmnxW+gaxANTTUfN+66mfAewdmi/NU3Zj6iqzVU1WVWTK1eu7DRYSVrOFjpBXAuc2iyfClwzVP6OZjTTq4GHhpqiJEk96KyJKcmfAa8DDk6yHfgAcB5wZZLTgW8Db2t2vx44EdgGPAqc1lVckqTRdJYgquqUPWw6vmXfAs7oKhaNL+/ElcaXd1JLklqZICRJrZysT2PDu6el8WINQpLUygQhSWplE5OkTjhCbfGzBiFJamUNQgvOzujlzZrF4mENQpLUyhqEpM5Za1ycrEFIklqZICRJrUwQkqRWJghJUisThCSplQlCktTKBCFJauV9EJLGgndYjx8ThKTeeAPdeLOJSZLUqpcaRJL7gB8ATwJPVNVkkoOAPwcmgPuAt1XV9/uIT5LUbw3i9VV1ZFVNNuubgM9X1WHA55t1SVJPxqmJaQNwabN8KXBSj7FI0rLXVyd1AX+dpICPVtVm4JCq2tls/y5wSE+xqQN2RkqLT18J4merakeSlwBbkvzt8MaqqiZ5/IgkG4GNAOvWres+UklapnppYqqqHc37LuBqYD3wQJJVAM37rj0cu7mqJqtqcuXKlQsVsiQtOwueIJI8P8kLp5aBnwPuAq4FTm12OxW4ZqFjkyQ9o48mpkOAq5NMff6fVtVfJvkKcGWS04FvA2/rITbNI/sdNFveVT0eFjxBVNU3gSNayr8HHL/Q8UiS2o3TMFdJ0hhxLibNK5uVpKXDGoQkqZU1CEljzQ7r/liDkCS1MkFIklrZxKQ5s2NaWppMEJIWDfsjFpZNTJKkViYISVIrm5g0K/Y7SEufCUIjMylonNgf0T2bmCRJrUwQkqRWNjHp/2O1XYuR/267YQ1CktTKGoT2yE5pLUbWJuaPCULSkmWymBsThKwpSGplglhGTATSj7KWsWdjlyCSnABcCKwAPl5V5/UckqQlxh9Lo0lV9R3D05KsAP4OeAOwHfgKcEpV3dO2/+TkZG3dunUBIxxfe/oV5BdBmp1RvkeLtcaR5Naqmpxuv3GrQawHtlXVNwGSXAFsAFoTxHLkH3xpYfhdG78EsRq4f2h9O3BsFx+00O2Oo/wCma9agP+wpYU3178poxy/0H+3xq2J6ReBE6rq15r1twPHVtWZQ/tsBDY2qy8Hvr4AoR0M/MMCfE7XvI7xshSuYylcAyy/6/jJqlo53U7jVoPYAawdWl/TlD2tqjYDmxcyqCRbR2mvG3dex3hZCtexFK4BvI49GbepNr4CHJbk0CTPBU4Gru05JklalsaqBlFVTyQ5E/grBsNcL6mqu3sOS5KWpbFKEABVdT1wfd9xPMuCNml1yOsYL0vhOpbCNYDX0WqsOqklSeNj3PogJEljwgQxA0nek+Rvk9yd5Pf7jmcukpyVpJIc3HcsM5XkfzT/H+5IcnWSA/uOaSaSnJDk60m2JdnUdzyzkWRtkhuT3NN8H97bd0xzkWRFkq8m+WzfscxWkgOTXNV8N+5N8jNzPacJYkRJXs/gru4jquqVwPk9hzRrSdYCPwf8fd+xzNIW4FVV9dMMpmY5u+d4RtZMJ/O/gDcChwOnJDm836hm5QngrKo6HHg1cMYivY4p7wXu7TuIOboQ+MuqegVwBPNwPSaI0f0GcF5VPQZQVbt6jmcuLgB+G1iUHVBV9ddV9USzehOD+2UWi6enk6mqx4Gp6WQWlaraWVW3Ncs/YPDHaHW/Uc1OkjXAm4CP9x3LbCV5EfBvgYsBqurxqnpwruc1QYzuZcBrk9yc5ItJjuk7oNlIsgHYUVVf6zuWefKrwOf6DmIG2qaTWZR/WKckmQCOAm7uN5JZ+0MGP5ie6juQOTgU2A38cdNU9vEkz5/rScdumGufktwA/HjLpt9h8N/qIAbV6WOAK5O8tMZwGNg013EOg+alsba3a6iqa5p9fodBU8flCxmbnpHkBcCngPdV1cN9xzNTSd4M7KqqW5O8ru945mAf4GjgPVV1c5ILgU3Af5nrSdWoqn+/p21JfgP4dJMQbknyFIN5T3YvVHyj2tN1JPkpBr80vpYEBk0ztyVZX1XfXcAQp7W3/xcASd4JvBk4fhyT9F5MO53MYpFkXwbJ4fKq+nTf8czSa4C3JDkR2B/4sSR/UlW/0nNcM7Ud2F5VU7W4qxgkiDmxiWl0nwFeD5DkZcBzWWSTe1XVnVX1kqqaqKoJBv+ojh635DCd5qFSvw28paoe7TueGVoS08lk8AvjYuDeqvpQ3/HMVlWdXVVrmu/DycAXFmFyoPkO35/k5U3R8czDYxKsQYzuEuCSJHcBjwOnLrJfrkvJR4D9gC1NTeimqvr1fkMazRKaTuY1wNuBO5Pc3pSd08yEoH68B7i8+eHxTeC0uZ7QO6klSa1sYpIktTJBSJJamSAkSa1MEJKkViYISVIrE4QkqZUJQpLUygQhSWr1/wAe1kOWlLrC1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test['f'] - df_test['predictions']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensorflow LinearRegressor Estimator\n",
    "Now we'll reproduce this with the high-level estimator API. Surprisingly, the calculations here take much longer than in the basic approach above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(df_train, shuffle=True, num_epochs=100, y=df_train['f'], batch_size=NUM_RECORDS)\n",
    "feature_columns = [\n",
    "    fc.numeric_column('x', dtype=tf.float32),\n",
    "    fc.numeric_column('y', dtype=tf.float32)\n",
    "]\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpOVnKdr\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f051090a450>, '_model_dir': '/tmp/tmpOVnKdr', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 5, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, config=config )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Perform the training on the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpOVnKdr/model.ckpt.\n",
      "INFO:tensorflow:loss = 380305.88, step = 1\n",
      "INFO:tensorflow:global_step/sec: 19.4918\n",
      "INFO:tensorflow:loss = 183951.56, step = 6 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1728\n",
      "INFO:tensorflow:loss = 123133.97, step = 11 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5127\n",
      "INFO:tensorflow:loss = 88415.984, step = 16 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8077\n",
      "INFO:tensorflow:loss = 67429.445, step = 21 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1637\n",
      "INFO:tensorflow:loss = 53171.36, step = 26 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1324\n",
      "INFO:tensorflow:loss = 43470.01, step = 31 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9571\n",
      "INFO:tensorflow:loss = 36885.56, step = 36 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.316\n",
      "INFO:tensorflow:loss = 32092.445, step = 41 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0476\n",
      "INFO:tensorflow:loss = 28676.115, step = 46 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2015\n",
      "INFO:tensorflow:loss = 26278.07, step = 51 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3013\n",
      "INFO:tensorflow:loss = 24659.898, step = 56 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5939\n",
      "INFO:tensorflow:loss = 23299.465, step = 61 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2045\n",
      "INFO:tensorflow:loss = 22366.258, step = 66 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2225\n",
      "INFO:tensorflow:loss = 21715.818, step = 71 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3374\n",
      "INFO:tensorflow:loss = 21253.059, step = 76 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6537\n",
      "INFO:tensorflow:loss = 20688.117, step = 81 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6933\n",
      "INFO:tensorflow:loss = 20696.445, step = 86 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8924\n",
      "INFO:tensorflow:loss = 20430.379, step = 91 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.821\n",
      "INFO:tensorflow:loss = 20269.477, step = 96 (0.194 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpOVnKdr/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20171.654.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f0510b89510>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.train(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparing The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_test = tf.estimator.inputs.pandas_input_fn(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = regressor.predict(input_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpOVnKdr/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pred_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.302367</td>\n",
       "      <td>-7.437540</td>\n",
       "      <td>-4.550783</td>\n",
       "      <td>-4.328052</td>\n",
       "      <td>-7.432281</td>\n",
       "      <td>-7.175642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.568293</td>\n",
       "      <td>4.357425</td>\n",
       "      <td>3.248688</td>\n",
       "      <td>3.279901</td>\n",
       "      <td>4.381163</td>\n",
       "      <td>4.203145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.862282</td>\n",
       "      <td>-10.037311</td>\n",
       "      <td>-3.811622</td>\n",
       "      <td>3.828134</td>\n",
       "      <td>-9.998946</td>\n",
       "      <td>-9.790426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.625595</td>\n",
       "      <td>6.463635</td>\n",
       "      <td>4.061283</td>\n",
       "      <td>2.317860</td>\n",
       "      <td>6.481897</td>\n",
       "      <td>6.260230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.247317</td>\n",
       "      <td>-2.602588</td>\n",
       "      <td>-0.333457</td>\n",
       "      <td>2.871345</td>\n",
       "      <td>-2.574324</td>\n",
       "      <td>-2.555588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.381897</td>\n",
       "      <td>-1.736223</td>\n",
       "      <td>-0.174087</td>\n",
       "      <td>1.776098</td>\n",
       "      <td>-1.712857</td>\n",
       "      <td>-1.701836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.854462</td>\n",
       "      <td>-0.364786</td>\n",
       "      <td>-0.376819</td>\n",
       "      <td>-1.777705</td>\n",
       "      <td>-0.356053</td>\n",
       "      <td>-0.330608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.150018</td>\n",
       "      <td>8.095863</td>\n",
       "      <td>4.725606</td>\n",
       "      <td>1.710697</td>\n",
       "      <td>8.110406</td>\n",
       "      <td>7.852885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.006145</td>\n",
       "      <td>-1.552918</td>\n",
       "      <td>0.466763</td>\n",
       "      <td>3.972886</td>\n",
       "      <td>-1.521405</td>\n",
       "      <td>-1.547562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.429570</td>\n",
       "      <td>2.996367</td>\n",
       "      <td>1.335520</td>\n",
       "      <td>-1.650657</td>\n",
       "      <td>3.002650</td>\n",
       "      <td>2.934105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions  pred_estimator\n",
       "0  -7.302367  -7.437540 -4.550783 -4.328052    -7.432281       -7.175642\n",
       "1   5.568293   4.357425  3.248688  3.279901     4.381163        4.203145\n",
       "2 -10.862282 -10.037311 -3.811622  3.828134    -9.998946       -9.790426\n",
       "3   5.625595   6.463635  4.061283  2.317860     6.481897        6.260230\n",
       "4  -4.247317  -2.602588 -0.333457  2.871345    -2.574324       -2.555588\n",
       "5  -1.381897  -1.736223 -0.174087  1.776098    -1.712857       -1.701836\n",
       "6  -0.854462  -0.364786 -0.376819 -1.777705    -0.356053       -0.330608\n",
       "7   8.150018   8.095863  4.725606  1.710697     8.110406        7.852885\n",
       "8  -2.006145  -1.552918  0.466763  3.972886    -1.521405       -1.547562\n",
       "9   1.429570   2.996367  1.335520 -1.650657     3.002650        2.934105"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_estimator = [f['predictions'][0] for f in generator]\n",
    "df_test['pred_estimator'] = pred_estimator\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pre-canned estimator arrives at (almost) the same results as our hand-made linear regressor. Not that we had a doubt, though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning From Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that the ground truth is a totally unexpected function of the week day and time of day. That could happen e.g., if you measure the humidity and fail to realize that your sensor is near a dry-cleaner's. Let's assume the dry-cleaner's have peek hours on Mon, Tue, Wed from 18:00h to 21:00 and Fri, Sat from 14:00h to 16:00h. During those hours humidity is significantly higher due to the steam produced there. \n",
    "\n",
    "First, let's create a dataset that reflects that situation. Day of week and hour of day shall be represented by categorical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe with days of week and hour-of-day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a constant, if the hour of week \n",
    "conditions = np.array([\n",
    "    (0, 18), (0, 19), (0, 20), (0, 21), # Mondays\n",
    "    (1, 18), (1, 19), (1, 20), (1, 21), # Tuesdays\n",
    "    (2, 18), (2, 19), (2, 20), (2, 21), # Wednesdays\n",
    "    # closed on Thursdays\n",
    "    (4, 14), (4, 15), (4, 16),          # Fridays\n",
    "    (5, 14), (5, 15), (5, 16)           # Saturdays\n",
    "    # closed on Sundays\n",
    "    ])\n",
    "\n",
    "def make_noisy_amplitude_function(amplitude):\n",
    "    def _f(c1, c2):\n",
    "        zipped = zip(c1,c2)\n",
    "        res = array_in(zipped, conditions)        \n",
    "        return res * (np.random.normal( 0 * res, .2 ) + amplitude)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v2(size, amplitude=5.0):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    dow_data = np.random.randint(7, size=size)\n",
    "    hod_data = np.random.randint(24, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    \n",
    "    f_special = make_noisy_amplitude_function(amplitude)(dow_data, hod_data)\n",
    "\n",
    "    f_total = f_data + f_special\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'dow': dow_data, 'hod': hod_data, 'f_orig': f_data, 'p': f_perf, 'special': f_special, 'f': f_total})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>f</th>\n",
       "      <th>f_orig</th>\n",
       "      <th>hod</th>\n",
       "      <th>p</th>\n",
       "      <th>special</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-7.958270</td>\n",
       "      <td>-7.958270</td>\n",
       "      <td>11</td>\n",
       "      <td>-8.337446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.493883</td>\n",
       "      <td>1.699360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>9.300634</td>\n",
       "      <td>9.300634</td>\n",
       "      <td>1</td>\n",
       "      <td>8.523461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.882867</td>\n",
       "      <td>1.484547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.217568</td>\n",
       "      <td>9.217568</td>\n",
       "      <td>12</td>\n",
       "      <td>8.168122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.544076</td>\n",
       "      <td>-3.159939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-4.169130</td>\n",
       "      <td>-4.169130</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.680111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.475199</td>\n",
       "      <td>2.459426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.202436</td>\n",
       "      <td>-4.202436</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.135136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.042376</td>\n",
       "      <td>-0.899230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.632703</td>\n",
       "      <td>-1.632703</td>\n",
       "      <td>14</td>\n",
       "      <td>-2.071320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.312197</td>\n",
       "      <td>-2.106147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3.248708</td>\n",
       "      <td>3.248708</td>\n",
       "      <td>2</td>\n",
       "      <td>2.602063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461352</td>\n",
       "      <td>-4.358717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>-4.080928</td>\n",
       "      <td>-4.080928</td>\n",
       "      <td>13</td>\n",
       "      <td>-3.581295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.434472</td>\n",
       "      <td>4.424703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>7.173328</td>\n",
       "      <td>7.173328</td>\n",
       "      <td>11</td>\n",
       "      <td>5.385658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.687610</td>\n",
       "      <td>2.979123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>12.273234</td>\n",
       "      <td>12.273234</td>\n",
       "      <td>1</td>\n",
       "      <td>10.480589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.361816</td>\n",
       "      <td>-4.513914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>5.251922</td>\n",
       "      <td>5.251922</td>\n",
       "      <td>0</td>\n",
       "      <td>4.954049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.355974</td>\n",
       "      <td>-1.484204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>-7.818800</td>\n",
       "      <td>-7.818800</td>\n",
       "      <td>23</td>\n",
       "      <td>-8.173253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.804294</td>\n",
       "      <td>0.129330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>9.924164</td>\n",
       "      <td>9.924164</td>\n",
       "      <td>9</td>\n",
       "      <td>7.626664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.329025</td>\n",
       "      <td>-2.937227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>-10.190805</td>\n",
       "      <td>-10.190805</td>\n",
       "      <td>12</td>\n",
       "      <td>-9.549197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.432946</td>\n",
       "      <td>4.366611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.407560</td>\n",
       "      <td>-3.407560</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.097030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.215034</td>\n",
       "      <td>-1.666076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.442616</td>\n",
       "      <td>-3.442616</td>\n",
       "      <td>15</td>\n",
       "      <td>-4.371550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.229918</td>\n",
       "      <td>-1.176570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>-4.700423</td>\n",
       "      <td>-4.700423</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.209090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.253155</td>\n",
       "      <td>2.405561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.289565</td>\n",
       "      <td>-0.289565</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.764039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.240241</td>\n",
       "      <td>-2.432887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>16.046559</td>\n",
       "      <td>5.923357</td>\n",
       "      <td>20</td>\n",
       "      <td>4.157817</td>\n",
       "      <td>10.123201</td>\n",
       "      <td>3.436061</td>\n",
       "      <td>4.428611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>3.718582</td>\n",
       "      <td>3.718582</td>\n",
       "      <td>12</td>\n",
       "      <td>4.727956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.439787</td>\n",
       "      <td>-4.696765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dow          f     f_orig  hod          p    special         x         y\n",
       "0     2  -7.958270  -7.958270   11  -8.337446   0.000000 -3.493883  1.699360\n",
       "1     4   9.300634   9.300634    1   8.523461   0.000000  4.882867  1.484547\n",
       "2     2   9.217568   9.217568   12   8.168122   0.000000  3.544076 -3.159939\n",
       "3     2  -4.169130  -4.169130    1  -2.680111   0.000000 -0.475199  2.459426\n",
       "4     1  -4.202436  -4.202436   11  -4.135136   0.000000 -2.042376 -0.899230\n",
       "5     2  -1.632703  -1.632703   14  -2.071320   0.000000 -1.312197 -2.106147\n",
       "6     0   3.248708   3.248708    2   2.602063   0.000000  0.461352 -4.358717\n",
       "7     5  -4.080928  -4.080928   13  -3.581295   0.000000 -0.434472  4.424703\n",
       "8     3   7.173328   7.173328   11   5.385658   0.000000  3.687610  2.979123\n",
       "9     4  12.273234  12.273234    1  10.480589   0.000000  4.361816 -4.513914\n",
       "10    0   5.251922   5.251922    0   4.954049   0.000000  2.355974 -1.484204\n",
       "11    3  -7.818800  -7.818800   23  -8.173253   0.000000 -3.804294  0.129330\n",
       "12    4   9.924164   9.924164    9   7.626664   0.000000  3.329025 -2.937227\n",
       "13    4 -10.190805 -10.190805   12  -9.549197   0.000000 -3.432946  4.366611\n",
       "14    1  -3.407560  -3.407560    7  -2.097030   0.000000 -1.215034 -1.666076\n",
       "15    2  -3.442616  -3.442616   15  -4.371550   0.000000 -2.229918 -1.176570\n",
       "16    2  -4.700423  -4.700423    1  -4.209090   0.000000 -1.253155  2.405561\n",
       "17    3  -0.289565  -0.289565    6  -1.764039   0.000000 -1.240241 -2.432887\n",
       "18    1  16.046559   5.923357   20   4.157817  10.123201  3.436061  4.428611\n",
       "19    4   3.718582   3.718582   12   4.727956   0.000000  1.439787 -4.696765"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v2 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "df_train_v2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create a data set suitable for training\n",
    "In the following, our assumption that it is particular hours on particular days makes this problem a candidate for the categorical features 'hour of day' and 'day of week'. Hence, in a first step, let's take those two features into account. For that, we have to one-hot encode those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinals = list(df_train_v2['dow'])\n",
    "one_hot_dows = np.transpose(np.eye(7)[ordinals])\n",
    "one_hot_dows[:7,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = list(df_train_v2['hod'])\n",
    "one_hot_hods = np.transpose(np.eye(24)[ordinals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (2, 20000) + (7, 20000) + (24, 20000) = (33, 20000)\n"
     ]
    }
   ],
   "source": [
    "input_numerical = [list(df_train_v2['x']), list(df_train_v2['y'])]\n",
    "lbls_data = [list(df_train_v2['f'])]\n",
    "input_data = np.append(input_numerical, one_hot_dows, axis=0)\n",
    "input_data = np.append(input_data, one_hot_hods, axis=0)\n",
    "print(\"shapes: {} + {} + {} = {}\".format(np.shape(input_numerical), np.shape(one_hot_dows), np.shape(one_hot_hods), np.shape(input_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 33 columns, 31 of which only sparsely populated. That's ok for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.49388308,  4.88286723,  3.54407606, -0.4751991 ],\n",
       "       [ 1.69936039,  1.48454657, -3.15993944,  2.4594256 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  1.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hereafter, we'll use create_input_data from the tools file to achieve just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_input_data(df, select_feats=[], oh_feats={}, cross_feats=[]):    \n",
      "    \"\"\"\n",
      "    create a list of input columns from pandas raw data\n",
      "    df: a pandas dataframe containing raw input data\n",
      "    select_feats: an array containing the names of features to be selected without transformation\n",
      "    oh_feats: a dictionary containing the names and sizes of discrete numerical features that are to be one-hot encoded\n",
      "    cross_feats: a list of oh_feats consisting of two discrete features to cross\n",
      "    \"\"\"\n",
      "\n",
      "    def _safe_append(l, r):\n",
      "        if l == [] or l is None:\n",
      "            return r\n",
      "        else:\n",
      "            return np.append(l, r, axis=0)\n",
      "\n",
      "    res = [list(df[n]) for n in select_feats]\n",
      "    \n",
      "    for k in oh_feats:\n",
      "        res = _safe_append(res, one_hot(df[k], oh_feats[k]))\n",
      "\n",
      "    for c in cross_feats:\n",
      "        keys = list(c.keys())\n",
      "        keys.sort()\n",
      "        \n",
      "        lk, ls = keys[0], c[keys[0]]\n",
      "        rk, rs = keys[1], c[keys[1]]\n",
      "        lhs = one_hot(df[lk], ls)\n",
      "        rhs = one_hot(df[rk], rs)\n",
      "        cross = [(lhs[:,i].reshape(ls,1) * rhs[:,i].reshape(1,rs)).reshape(rs*ls) for i in range(len(df))]\n",
      "        cross = np.transpose(cross)\n",
      "        res = _safe_append(res, cross)\n",
      "\n",
      "    return res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(create_input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create the network and start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use once more our self-made linear regressor. Below is the code that we hade previously, only this time augmented by the 24 + 7 new input features from the categorical columns. Observe that we train a long time with a lot more data, and the training loss still doesn't improve much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_DIM = 2 # namely x and y\n",
    "WEEKDAY_DIM = 7 # obviously\n",
    "HOUR_OF_DAY_DIM = 24\n",
    "X_DIM = NUMERICAL_DIM + WEEKDAY_DIM + HOUR_OF_DAY_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 8.08877849579"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.0887785"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear2 = Linear(X_DIM, .01)\n",
    "linear2.train(sess, input_data, lbls_data, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That loss is significantly larger than the one that we experienced in the simple case. So either the signal/noise ratio is worse (we know it isn't) or there's some signal in the data that we don't recognize yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sometimes the distribution of the prediction errors reveals additional facts of the problems that our network has. Usually we'll need large enough samples to allow for sufficient statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predicted</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.732816</td>\n",
       "      <td>-9.389396</td>\n",
       "      <td>-6.201935</td>\n",
       "      <td>9.789550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.951864</td>\n",
       "      <td>-1.574774</td>\n",
       "      <td>-2.642581</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.322885</td>\n",
       "      <td>3.595617</td>\n",
       "      <td>2.540795</td>\n",
       "      <td>9.842742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.437547</td>\n",
       "      <td>-9.217440</td>\n",
       "      <td>-9.088882</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.254481</td>\n",
       "      <td>3.355527</td>\n",
       "      <td>6.556032</td>\n",
       "      <td>9.771451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.246087</td>\n",
       "      <td>-5.275737</td>\n",
       "      <td>-6.463847</td>\n",
       "      <td>9.694548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.903853</td>\n",
       "      <td>8.870785</td>\n",
       "      <td>11.927402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.880778</td>\n",
       "      <td>7.125457</td>\n",
       "      <td>10.445516</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.655371</td>\n",
       "      <td>8.532784</td>\n",
       "      <td>7.424173</td>\n",
       "      <td>9.854159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.429217</td>\n",
       "      <td>7.149600</td>\n",
       "      <td>6.048488</td>\n",
       "      <td>9.732364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f         p  predicted   special\n",
       "0  -0.732816 -9.389396  -6.201935  9.789550\n",
       "1  -0.951864 -1.574774  -2.642581  0.000000\n",
       "2  12.322885  3.595617   2.540795  9.842742\n",
       "3  -9.437547 -9.217440  -9.088882  0.000000\n",
       "4  13.254481  3.355527   6.556032  9.771451\n",
       "5   6.246087 -5.275737  -6.463847  9.694548\n",
       "6  10.903853  8.870785  11.927402  0.000000\n",
       "7   6.880778  7.125457  10.445516  0.000000\n",
       "8  17.655371  8.532784   7.424173  9.854159\n",
       "9  18.429217  7.149600   6.048488  9.732364"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_v2 = create_data_frame_v2(size = 20000, amplitude=10)\n",
    "test_data = create_input_data(df=df_test_v2, select_feats=['x','y'], oh_feats={'dow': 7, 'hod': 24})\n",
    "\n",
    "pred = linear2.predict(x_data=test_data, sess=sess)\n",
    "df_test_v2['predicted'] = pred[0]\n",
    "df_test_v2[['f', 'p', 'predicted', 'special']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test_v2['predicted'] - df_test_v2['f']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the error distribution that there's some really interesting stuff going on. This is almost certainly a hint that our data contains structure that we didn't discover yet. This distribution is telling: For the majority of the data - the large bump - we have a tendency to over-predict. For some minority though we significantly under-predict. This is a typical sign that the linear regression is finding a weak compromise between two distinct and somehow unrelated distributions that make up our total input data.\n",
    "\n",
    "Obviously, although or network actually had all the information it needed, simply adding the categorical features didn't allow it to learn the specific characteristic, namely the \"and\" relationship like in: \"The humidity is higher, when it's Wednesday *and* it's 18:00h\". \n",
    "\n",
    "Feature crossings and embeddings to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example: This is Wednesday, 08:00h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday = np.array([[0,0,1,0,0,0,0]])\n",
    "at_0800 = np.zeros((1,24))\n",
    "at_0800[0,8] = 1\n",
    "wednesday, at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossing categorical features $a$ and $b$ means: Put a 1 only where both $a$ and $b$ have a one. Put zeros anywhere else. Python broadcasting helps us achieve that with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday_at_0800 = wednesday.T * at_0800\n",
    "wednesday_at_0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = np.reshape(wednesday_at_0800, newshape=(1,-1))\n",
    "np.argmax(cross) == 2 * 24 + 8 # Wed * 24 + at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets a little more involved when dealing with a batch of feature pairs as you can see in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dows = np.array([[0,0,1,0,0,0,0],[0,0,0,0,0,1,0]])\n",
    "hods = np.zeros((2,24))\n",
    "hods[0,8] = 1\n",
    "hods[1,16] = 1\n",
    "dows, hods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(dows[i].reshape(7,1) * hods[i].reshape(1,24)).reshape(168) for i in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now, instead of feeding both features independently we feed the feature cross into our linear regression model. Note that we need a lot of data to have sufficient statistics for each hour of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 20000), 20000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_RECORDS = 20000\n",
    "\n",
    "df_train_v3 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "input_data_v3 = create_input_data(df=df_train_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "lbls_data_v3 = [list(df_train_v3['f'])]\n",
    "input_data_v3.shape, len(lbls_data_v3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.148239851"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1482399"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_v3 = Linear(lr=.05, x_dim=170)\n",
    "regressor_v3.train(sess=sess, num_steps=4000, x_data=input_data_v3, labels_data=lbls_data_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can see that the loss function has indeed gone down dramatically. Now let's examine the error statistics on some fresh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_v3 = create_data_frame_v2(size = 20000, amplitude=10.0)\n",
    "input_data_test_v3 = create_input_data(df=df_test_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "preds = regressor_v3.predict(sess=sess, x_data=input_data_test_v3)\n",
    "\n",
    "errors = preds[0] - df_test_v3['f']\n",
    "df_test_v3['preds'] = preds[0]\n",
    "df_test_v3['err'] = errors\n",
    "df_test_v3['err'].plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, there's some subtle asymmetry in the error distribution, depending on how long you trained, but we can see that the characteristic second bump has disappeared. When we look at the weights associated with the 168 different hours of a week, we spot a few larger positive values amongst otherwise smaller negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0369917 , -0.87412417, -1.0296807 , -0.97235805, -1.0329243 ,\n",
       "       -0.9532137 , -0.91377425, -0.98386765, -1.0562124 , -0.86025226,\n",
       "       -0.69029087, -1.0250785 , -0.7781546 , -1.1320786 , -1.1221006 ,\n",
       "       -1.0803114 , -1.2009299 , -0.97671384,  8.309745  ,  8.151927  ,\n",
       "        8.377813  ,  8.149989  , -0.9438939 , -1.001763  , -0.9291226 ,\n",
       "       -1.0483662 , -1.1076334 , -0.922452  , -0.90957844, -0.9743063 ,\n",
       "       -0.8514996 , -1.1564575 , -0.8192737 , -0.79114527, -0.84117365,\n",
       "       -0.9801803 , -1.0034357 , -0.88653576, -1.0113047 , -0.78241587,\n",
       "       -0.86058253, -1.1416622 ,  7.6796565 ,  7.9556813 ,  8.288358  ,\n",
       "        7.9356713 , -0.9926121 , -0.925594  , -1.2792623 , -1.0741765 ,\n",
       "       -1.1446462 , -0.8764447 , -1.1983684 , -0.8421461 , -0.86000204,\n",
       "       -1.0889896 , -0.8972002 , -0.87434095, -1.092003  , -0.86425066,\n",
       "       -0.97108185, -1.029114  , -0.7760898 , -0.9511725 , -0.79167336,\n",
       "       -0.8792357 ,  8.0938015 ,  8.142061  ,  8.317849  ,  8.128023  ,\n",
       "       -0.96613336, -1.0823691 , -1.0113717 , -0.9955054 , -0.8440024 ,\n",
       "       -0.9943015 , -0.9914204 , -1.0789958 , -1.0434185 , -0.9662177 ,\n",
       "       -0.83792347, -1.0084298 , -1.1019081 , -1.0220422 , -0.92119706,\n",
       "       -0.9336297 , -1.0992271 , -0.90679634, -0.94724077, -0.951922  ,\n",
       "       -0.97177094, -1.0285606 , -0.89774376, -0.8376547 , -1.0010047 ,\n",
       "       -0.98198014, -1.0573738 , -1.0896401 , -0.99723446, -0.8797382 ,\n",
       "       -0.8739217 , -0.9079028 , -0.9236876 , -0.9531545 , -1.0714475 ,\n",
       "       -1.2125487 , -1.1116221 , -0.9568557 , -1.1458844 , -0.9477899 ,\n",
       "        7.82344   ,  8.26544   ,  8.133787  , -0.8474999 , -0.81921774,\n",
       "       -1.0956199 , -1.00633   , -0.8825389 , -0.96253943, -0.97395056,\n",
       "       -0.7876651 , -1.0500046 , -0.96262676, -0.89926934, -1.0036862 ,\n",
       "       -0.8865834 , -0.72780275, -1.0514276 , -1.0472162 , -0.8395142 ,\n",
       "       -1.1626647 , -0.78107685, -0.9554914 , -1.1431177 ,  8.218568  ,\n",
       "        8.3071575 ,  7.8890066 , -1.0182426 , -1.0107603 , -1.0464214 ,\n",
       "       -1.0680373 , -0.976044  , -0.8848457 , -1.0227104 , -0.7172683 ,\n",
       "       -1.1469852 , -1.1697105 , -0.9388089 , -0.77959466, -1.0420538 ,\n",
       "       -0.86711365, -0.7763306 , -0.9341376 , -1.0063615 , -0.8854127 ,\n",
       "       -1.0349886 , -1.1065938 , -1.0219326 , -0.9993033 , -0.9183393 ,\n",
       "       -0.9184287 , -1.0256485 , -1.1694287 , -0.85875636, -0.9713599 ,\n",
       "       -0.9929686 , -0.8522634 , -0.9124759 ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = regressor_v3.M.eval()\n",
    "weights_t = weights.squeeze()[2:]\n",
    "weights_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes of the larger values allow us to discover exactly those hours of week during which the dry-cleaner anomalies are observed. The network truly learned when these anomalies are typically observed and adds some more humidity in its prediction during those times of the week. Ain't that cool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 3), array([ 0, 18])),\n",
       " ((0, 6), array([ 0, 19])),\n",
       " ((0, 16), array([ 0, 20])),\n",
       " ((1, 6), array([ 0, 21])),\n",
       " ((1, 19), array([ 1, 18])),\n",
       " ((2, 6), array([ 1, 19])),\n",
       " ((2, 19), array([ 1, 20])),\n",
       " ((3, 6), array([ 1, 21])),\n",
       " ((3, 9), array([ 2, 18])),\n",
       " ((3, 19), array([ 2, 19])),\n",
       " ((4, 2), array([ 2, 20])),\n",
       " ((4, 9), array([ 2, 21])),\n",
       " ((5, 2), array([ 4, 14])),\n",
       " ((5, 9), array([ 4, 15])),\n",
       " ((5, 15), array([ 4, 16])),\n",
       " ((6, 2), array([ 5, 14])),\n",
       " ((6, 9), array([ 5, 15])),\n",
       " ((6, 15), array([ 5, 16]))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [i for i in range(168) if weights_t[i] > 1]\n",
    "how_detected = [(i % 7, i / 7 ) for i in indexes]\n",
    "how_detected = sorted(how_detected, key=lambda d: d[0])\n",
    "zip(how_detected, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the left, the hours of the week as detected by the network, to the left the conditions that lead to the anomalies in the data. A perfect fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
