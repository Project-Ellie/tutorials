{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BUCKET = 'going-tfx'\n",
    "PROJECT = 'going-tfx'\n",
    "REGION = 'us-east-1'\n",
    "BQ_DATASET = 'examples'\n",
    "#os.environ['BUCKET'] = BUCKET\n",
    "#os.environ['PROJECT'] = PROJECT\n",
    "#os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_query(project, dataset):\n",
    "    return \"\"\"SELECT\n",
    "      ORIGIN,\n",
    "      FL_YEAR,\n",
    "      FL_MONTH,\n",
    "      FL_DOW,\n",
    "      UNIQUE_CARRIER,\n",
    "      DEST,\n",
    "      CRS_ARR_TIME,\n",
    "      DEP_DELAY,\n",
    "      ARR_DELAY\n",
    "    FROM `{}.{}.ATL_JUNE` \n",
    "    where\n",
    "      MOD(ABS(FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "          STRING(TIMESTAMP(FL_DATE)),\n",
    "          UNIQUE_CARRIER,\n",
    "          DEST\n",
    "        )\n",
    "      )) + CRS_ARR_TIME, 10000) >= {} and \n",
    "      MOD(ABS(FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "          STRING(TIMESTAMP(FL_DATE)),\n",
    "          UNIQUE_CARRIER,\n",
    "          DEST\n",
    "        )\n",
    "      )) + CRS_ARR_TIME, 10000) < {} \n",
    "    \"\"\".format(project, dataset, '{}', '{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_queries(training_percentage, eval_percentage):\n",
    "    \"\"\"\n",
    "        returns 3 queries that return distinct samples of the ATL_JUNE table.\n",
    "        Use these for your convenience to define train,eval,test splits\n",
    "    \"\"\"\n",
    "    cut1 = int(100 * training_percentage)\n",
    "    cut2 = cut1 + int(100 * eval_percentage)\n",
    "    query = sample_query(PROJECT, BQ_DATASET)\n",
    "    q1 = query.format(0, cut1)\n",
    "    q2 = query.format(cut1+1, cut2)\n",
    "    q3 = query.format(cut2+1, 9999)\n",
    "    return q1, q2, q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The below query retrieves only 1/10'000 of the 400k entries, that's about 40-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "      ORIGIN,\n",
      "      FL_YEAR,\n",
      "      FL_MONTH,\n",
      "      FL_DOW,\n",
      "      UNIQUE_CARRIER,\n",
      "      DEST,\n",
      "      CRS_ARR_TIME,\n",
      "      DEP_DELAY,\n",
      "      ARR_DELAY\n",
      "    FROM `going-tfx.examples.ATL_JUNE` \n",
      "    where\n",
      "      MOD(ABS(FARM_FINGERPRINT(\n",
      "        CONCAT(\n",
      "          STRING(TIMESTAMP(FL_DATE)),\n",
      "          UNIQUE_CARRIER,\n",
      "          DEST\n",
      "        )\n",
      "      )) + CRS_ARR_TIME, 10000) >= 0 and \n",
      "      MOD(ABS(FARM_FINGERPRINT(\n",
      "        CONCAT(\n",
      "          STRING(TIMESTAMP(FL_DATE)),\n",
      "          UNIQUE_CARRIER,\n",
      "          DEST\n",
      "        )\n",
      "      )) + CRS_ARR_TIME, 10000) < 1 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "query_0001, e, s = create_queries(0.01,0.02)\n",
    "print(query_0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative way of getting some data\n",
    "# sample = pd.read_csv(os.path.join(DATA_DIR, \"atl_june_46.csv\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>FL_YEAR</th>\n",
       "      <th>FL_MONTH</th>\n",
       "      <th>FL_DOW</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>AA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>DL</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>2307</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>DL</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1153</td>\n",
       "      <td>8</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>DL</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>1255</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN  FL_YEAR  FL_MONTH  FL_DOW UNIQUE_CARRIER DEST  CRS_ARR_TIME  \\\n",
       "0    ATL     2009         6       7             AA  MIA          1610   \n",
       "1    ATL     2006         6       1             DL  ABQ          2307   \n",
       "2    ATL     2007         6       3             DL  SFO          1153   \n",
       "3    ATL     2008         6       7             DL  ABQ          1255   \n",
       "\n",
       "   DEP_DELAY  ARR_DELAY  \n",
       "0          0         24  \n",
       "1         20          8  \n",
       "2          8         -7  \n",
       "3          3         12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "sample = bq.Query(query_0001).execute().result().to_dataframe()\n",
    "sample[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Metadata and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'ARR_DELAY': 24,\n",
       "  u'CRS_ARR_TIME': 1610,\n",
       "  u'DEP_DELAY': 0,\n",
       "  u'DEST': 'MIA',\n",
       "  u'FL_DOW': 7,\n",
       "  u'FL_MONTH': 6,\n",
       "  u'FL_YEAR': 2009,\n",
       "  u'ORIGIN': 'ATL',\n",
       "  u'UNIQUE_CARRIER': 'AA'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = sample.to_dict(orient='records')\n",
    "records[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tft_metadata(columns):\n",
    "    \"\"\"\n",
    "    columns: dict of column names and tf.types\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    from tensorflow_transform.tf_metadata import (dataset_metadata, dataset_schema)\n",
    "\n",
    "    raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "        dataset_schema.from_feature_spec( {\n",
    "        col: tf.FixedLenFeature([], _type) for col, _type in columns.items()\n",
    "    }))\n",
    "    return raw_data_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "raw_data_metadata = tft_metadata({\n",
    "    'ORIGIN': tf.string, \n",
    "    'FL_YEAR': tf.int64,\n",
    "    'FL_MONTH': tf.int64,\n",
    "    'FL_DOW': tf.int64,\n",
    "    'UNIQUE_CARRIER': tf.string,\n",
    "    'DEST': tf.string,\n",
    "    'CRS_ARR_TIME': tf.int64,\n",
    "    'DEP_DELAY': tf.float32,\n",
    "    'ARR_DELAY': tf.float32\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The pre-processing function scales the arrival delay and lets all other columns unchanged. Pay particular attention to the name of the returned ARR_DELAY tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(inputs):\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_transform as tft\n",
    "    # print(inputs)\n",
    "    arr_delay=tft.scale_to_0_1(inputs['ARR_DELAY'])\n",
    "    res = {'ARR_DELAY': arr_delay}\n",
    "    for col in ['ORIGIN', 'FL_YEAR', 'FL_MONTH', 'FL_DOW', 'UNIQUE_CARRIER', 'DEST', 'CRS_ARR_TIME', 'DEP_DELAY']:\n",
    "        res[col] = tf.identity(inputs[col])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARR_DELAY': <tf.Tensor 'scale_by_min_max/add:0' shape=() dtype=float32>,\n",
       " 'CRS_ARR_TIME': <tf.Tensor 'Identity_6:0' shape=() dtype=int32>,\n",
       " 'DEP_DELAY': <tf.Tensor 'Identity_7:0' shape=() dtype=int32>,\n",
       " 'DEST': <tf.Tensor 'Identity_5:0' shape=() dtype=string>,\n",
       " 'FL_DOW': <tf.Tensor 'Identity_3:0' shape=() dtype=int32>,\n",
       " 'FL_MONTH': <tf.Tensor 'Identity_2:0' shape=() dtype=int32>,\n",
       " 'FL_YEAR': <tf.Tensor 'Identity_1:0' shape=() dtype=int32>,\n",
       " 'ORIGIN': <tf.Tensor 'Identity:0' shape=() dtype=string>,\n",
       " 'UNIQUE_CARRIER': <tf.Tensor 'Identity_4:0' shape=() dtype=string>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_fn(records[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERED_COLS=['ORIGIN', 'FL_YEAR', 'FL_MONTH', 'FL_DOW', 'UNIQUE_CARRIER', 'DEST', 'CRS_ARR_TIME', 'DEP_DELAY', 'ARR_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_to_tfrecord(in_test_mode=True):\n",
    "    import tempfile\n",
    "    import datetime\n",
    "    import apache_beam as beam\n",
    "    import tensorflow_transform as tft\n",
    "    import tensorflow_transform.beam.impl as tft_beam\n",
    "\n",
    "    BASE_DIR='gs://going-tfx/tutorials/tft/'\n",
    "    PROJECT='going-tfx'\n",
    "    in_test_mode = True\n",
    "    job_name = 'tft-tutorial' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "\n",
    "    options = {\n",
    "        'staging_location': os.path.join(BASE_DIR, 'staging'),\n",
    "        'temp_location': os.path.join(BASE_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'max_num_workers': 24,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True,\n",
    "        'requirements_file': 'requirements.txt'\n",
    "    }\n",
    "\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    if in_test_mode:\n",
    "        RUNNER = 'DirectRunner'\n",
    "    else:\n",
    "        RUNNER = 'DataflowRunner'    \n",
    "    \n",
    "    filebase_tfr=\"gs://going-tfx/tutorials/tft/tfr/q0001\"\n",
    "    filebase_csv=\"gs://going-tfx/tutorials/tft/csv/q0001\"\n",
    "\n",
    "    with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "        with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "            raw_data = p | \"ReadFromBQ\"  >> beam.io.Read(beam.io.BigQuerySource(query=query_0001, use_standard_sql=True)) \n",
    "\n",
    "            tds, tfn = (\n",
    "                (raw_data, raw_data_metadata)    \n",
    "                | 'Transform' >> tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "\n",
    "            td, tmd = tds\n",
    "\n",
    "            encoder = tft.coders.ExampleProtoCoder(tmd.schema)\n",
    "\n",
    "            _ = (td\n",
    "                 | 'EncodeTFRecord' >> beam.Map(encoder.encode)\n",
    "                 | 'WriteTFRecord' >> beam.io.WriteToTFRecord(filebase_tfr))\n",
    "        \n",
    "    with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "        with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "            csv_encode = tft.coders.CsvCoder(ORDERED_COLS, raw_data_metadata.schema).encode    \n",
    "            tft_data = (p \n",
    "                        | \"ReadFromTFRecord\" >> beam.io.ReadFromTFRecord(coder=encoder, file_pattern=filebase_tfr+\"*\")\n",
    "                        | beam.Map(csv_encode)\n",
    "                        | beam.io.WriteToText(file_path_prefix=filebase_csv))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_c919b24c24f8484688f6877e726449e6 does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "extract_to_tfrecord(in_test_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://going-tfx/tutorials/tft/csv/q0001-00000-of-00001...\n",
      "/ [1 files][  2.0 KiB/  2.0 KiB]                                                \n",
      "Operation completed over 1 objects/2.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://going-tfx/tutorials/tft/csv/* /tmp/tfr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL,2009,6,7,AA,MIA,1610,0.0,0.181159421802\n",
      "ATL,2006,6,1,DL,ABQ,2307,20.0,0.123188406229\n",
      "ATL,2016,6,1,DL,MSN,1134,-3.0,0.0326086953282\n",
      "ATL,2008,6,2,DL,LAX,1240,7.0,0.137681156397\n",
      "ATL,2010,6,2,DL,ONT,2040,52.0,0.242753624916\n",
      "ATL,2010,6,3,DL,PHL,1206,-1.0,0.105072468519\n",
      "ATL,2016,6,3,DL,DAL,1744,267.0,1.0\n",
      "ATL,2017,6,3,DL,ORD,1231,-5.0,0.00724637694657\n",
      "ATL,2014,6,3,DL,LAX,2219,10.0,0.108695656061\n",
      "ATL,2007,6,3,DL,SFO,1153,8.0,0.0688405781984\n",
      "ATL,2016,6,4,DL,ROA,2317,-2.0,0.0326086953282\n",
      "ATL,2017,6,4,DL,DEN,1059,-5.0,0.0289855077863\n",
      "ATL,2016,6,5,DL,TPA,1100,-2.0,0.0760869607329\n",
      "ATL,2008,6,5,DL,DEN,1206,13.0,0.202898561954\n",
      "ATL,2011,6,6,DL,PWM,2311,-3.0,0.0978260859847\n",
      "ATL,2014,6,6,DL,JAN,1110,-4.0,0.0724637657404\n",
      "ATL,2014,6,6,DL,PIT,2337,30.0,0.155797109008\n",
      "ATL,2013,6,6,DL,BWI,1819,-6.0,0.0108695654199\n",
      "ATL,2015,6,7,DL,CLE,1541,26.0,0.0942028984427\n",
      "ATL,2008,6,7,DL,ABQ,1255,3.0,0.137681156397\n",
      "ATL,2009,6,1,EV,MLU,1213,-4.0,0.0615942031145\n",
      "ATL,2011,6,1,EV,AEX,2121,43.0,0.278985500336\n",
      "ATL,2009,6,2,EV,ALB,2235,4.0,0.0652173906565\n",
      "ATL,2014,6,2,EV,CHA,1340,-2.0,0.0543478280306\n",
      "ATL,2013,6,2,EV,TYS,1238,113.0,0.51811593771\n",
      "ATL,2006,6,4,EV,AVL,1546,19.0,0.112318843603\n",
      "ATL,2010,6,4,EV,HPN,1625,-2.0,0.0905797109008\n",
      "ATL,2012,6,4,EV,LFT,1703,-4.0,0.0181159414351\n",
      "ATL,2014,6,4,EV,CHA,2339,17.0,0.123188406229\n",
      "ATL,2008,6,6,EV,CSG,1059,59.0,0.315217405558\n",
      "ATL,2011,6,6,EV,ICT,1040,39.0,0.271739125252\n",
      "ATL,2013,6,7,EV,ILM,2202,-4.0,0.0362318828702\n",
      "ATL,2015,6,7,EV,ECP,1807,-4.0,0.0688405781984\n",
      "ATL,2008,6,7,F9,DEN,2050,-10.0,0.0326086953282\n",
      "ATL,2010,6,1,FL,MEM,2344,14.0,0.0688405781984\n",
      "ATL,2011,6,2,FL,IAD,1431,-1.0,0.0905797109008\n",
      "ATL,2006,6,3,FL,CAK,958,-1.0,0.0797101482749\n",
      "ATL,2010,6,6,FL,MCO,1530,-2.0,0.0869565233588\n",
      "ATL,2007,6,6,FL,LAX,1230,2.0,0.0\n",
      "ATL,2012,6,6,FL,CAK,1154,-1.0,0.0434782616794\n",
      "ATL,2013,6,7,US,PHX,1236,-5.0,0.108695656061\n",
      "ATL,2016,6,3,WN,IND,2330,32.0,0.184782609344\n",
      "ATL,2015,6,4,WN,PBI,1535,-4.0,0.0434782616794\n",
      "ATL,2013,6,7,WN,MDW,1220,1.0,0.0760869607329\n",
      "ATL,2011,6,2,YV,IAD,2114,6.0,0.0942028984427\n"
     ]
    }
   ],
   "source": [
    "!cat /tmp/tfr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
