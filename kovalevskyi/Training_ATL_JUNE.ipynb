{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.saved import input_fn_maker, saved_transform_io\n",
    "from tensorflow_transform.tf_metadata import metadata_io\n",
    "import google.datalab.bigquery as dlbq\n",
    "\n",
    "from configuration_2 import directories\n",
    "from configuration_2 import ORDERED_TRAINING_COLUMNS, ORDERED_TRAINING_DEFAULTS, SIGNATURE_INT_COLUMNS, SIGNATURE_FLOAT_COLUMNS, SIGNATURE_METADATA\n",
    "\n",
    "from signature_queries import sample_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR=os.path.join(os.environ['HOME'], \"data\", \"model\")\n",
    "!ls $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#  Uncomment if you want to start from scratch\n",
    "#\n",
    "!rm -rf $MODEL_DIR/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Data\n",
    "Training and evaluation data should be provided in files already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'data': 'gs://going-tfx/sample/data',\n",
       "  'metadata': 'gs://going-tfx/sample/metadata',\n",
       "  'tmp': 'gs://going-tfx/sample/tmp'},\n",
       " {'data': '/tmp/atl_june/sample/data',\n",
       "  'metadata': '/tmp/atl_june/sample/metadata',\n",
       "  'tmp': '/tmp/atl_june/sample/tmp'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage='sample'\n",
    "gsdirs = directories('gs', stage)\n",
    "localdirs = directories('local', stage)\n",
    "gsdirs, localdirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if train and eval files exist\n",
    "If not, please go back an run ```Processing_ATL_JUNE.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "localdatadir=localdirs['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atl_june_eval-00000-of-00003   atl_june_train-00011-of-00025\n",
      "atl_june_eval-00001-of-00003   atl_june_train-00012-of-00025\n",
      "atl_june_eval-00002-of-00003   atl_june_train-00013-of-00025\n",
      "atl_june_train-00000-of-00025  atl_june_train-00014-of-00025\n",
      "atl_june_train-00001-of-00025  atl_june_train-00015-of-00025\n",
      "atl_june_train-00002-of-00025  atl_june_train-00016-of-00025\n",
      "atl_june_train-00003-of-00025  atl_june_train-00017-of-00025\n",
      "atl_june_train-00004-of-00025  atl_june_train-00018-of-00025\n",
      "atl_june_train-00005-of-00025  atl_june_train-00019-of-00025\n",
      "atl_june_train-00006-of-00025  atl_june_train-00020-of-00025\n",
      "atl_june_train-00007-of-00025  atl_june_train-00021-of-00025\n",
      "atl_june_train-00008-of-00025  atl_june_train-00022-of-00025\n",
      "atl_june_train-00009-of-00025  atl_june_train-00023-of-00025\n",
      "atl_june_train-00010-of-00025  atl_june_train-00024-of-00025\n"
     ]
    }
   ],
   "source": [
    "!ls $localdatadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 /tmp/atl_june/sample/data/atl_june_train-00000-of-00025\n"
     ]
    }
   ],
   "source": [
    "a_training_file = !ls $localdatadir/atl_june_train-00000-of-*\n",
    "a_training_file = a_training_file[0]\n",
    "!wc -l $a_training_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976 /tmp/atl_june/sample/data/atl_june_eval-00000-of-00003\n"
     ]
    }
   ],
   "source": [
    "an_eval_file = !ls $localdatadir/atl_june_eval-00000-of-*\n",
    "an_eval_file = an_eval_file[0]\n",
    "!wc -l $an_eval_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Have a look into the training data file\n",
    "\n",
    "This data is at the **training data** stage. It's got all and only the columns we want. Is has been normalized and integerized. We'll use ```tf.feature_column``` to further process categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = pd.read_csv(a_training_file, names=ORDERED_TRAINING_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_HOD</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>132.0</td>\n",
       "      <td>41.33</td>\n",
       "      <td>-75.72</td>\n",
       "      <td>0.503632</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.543593</td>\n",
       "      <td>0.882732</td>\n",
       "      <td>0.143711</td>\n",
       "      <td>0.610507</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.204301</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.248062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>3.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>-87.18</td>\n",
       "      <td>0.157385</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.293766</td>\n",
       "      <td>0.759665</td>\n",
       "      <td>0.043596</td>\n",
       "      <td>0.581522</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.248062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ARR_DELAY  ARR_LAT  ARR_LON  DEP_DELAY  DEP_DOW  DEP_HOD  DEP_LAT  \\\n",
       "826      132.0    41.33   -75.72   0.503632        4       20    33.63   \n",
       "824        3.0    30.47   -87.18   0.157385        4       10    33.63   \n",
       "\n",
       "     DEP_LON  DIFF_LAT  DIFF_LON  DISTANCE  MEAN_TEMP_ARR  MEAN_TEMP_DEP  \\\n",
       "826   -84.42  0.543593  0.882732  0.143711       0.610507       0.831933   \n",
       "824   -84.42  0.293766  0.759665  0.043596       0.581522       0.831933   \n",
       "\n",
       "     MEAN_VIS_ARR  MEAN_VIS_DEP  WND_SPD_ARR  WND_SPD_DEP  \n",
       "826      0.204301      0.984375     0.005601     0.248062  \n",
       "824      0.489247      0.984375     0.004100     0.248062  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe.sample(frac=1.0)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_HOD</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.653000</td>\n",
       "      <td>35.649160</td>\n",
       "      <td>-87.960920</td>\n",
       "      <td>0.164726</td>\n",
       "      <td>4.744000</td>\n",
       "      <td>14.378000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.412909</td>\n",
       "      <td>0.751279</td>\n",
       "      <td>0.137534</td>\n",
       "      <td>0.541755</td>\n",
       "      <td>0.639660</td>\n",
       "      <td>0.434478</td>\n",
       "      <td>0.727578</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.349775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.990776</td>\n",
       "      <td>5.288832</td>\n",
       "      <td>13.495345</td>\n",
       "      <td>0.082028</td>\n",
       "      <td>2.015571</td>\n",
       "      <td>4.654114</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.121666</td>\n",
       "      <td>0.144924</td>\n",
       "      <td>0.121488</td>\n",
       "      <td>0.132366</td>\n",
       "      <td>0.195845</td>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.210591</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.225363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.000000</td>\n",
       "      <td>18.330000</td>\n",
       "      <td>-157.920000</td>\n",
       "      <td>0.094431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106884</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.124031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.000000</td>\n",
       "      <td>31.320000</td>\n",
       "      <td>-93.450000</td>\n",
       "      <td>0.123487</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.313320</td>\n",
       "      <td>0.692333</td>\n",
       "      <td>0.062985</td>\n",
       "      <td>0.474638</td>\n",
       "      <td>0.483193</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.209302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.870000</td>\n",
       "      <td>-83.350000</td>\n",
       "      <td>0.128329</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.800795</td>\n",
       "      <td>0.106730</td>\n",
       "      <td>0.564312</td>\n",
       "      <td>0.684874</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.248062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>-79.970000</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.510697</td>\n",
       "      <td>0.837092</td>\n",
       "      <td>0.150884</td>\n",
       "      <td>0.628623</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>61.170000</td>\n",
       "      <td>-64.970000</td>\n",
       "      <td>0.777240</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947464</td>\n",
       "      <td>0.869748</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>0.798450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ARR_DELAY      ARR_LAT      ARR_LON    DEP_DELAY      DEP_DOW  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     12.653000    35.649160   -87.960920     0.164726     4.744000   \n",
       "std      35.990776     5.288832    13.495345     0.082028     2.015571   \n",
       "min     -30.000000    18.330000  -157.920000     0.094431     1.000000   \n",
       "25%      -8.000000    31.320000   -93.450000     0.123487     4.000000   \n",
       "50%       1.000000    35.870000   -83.350000     0.128329     4.000000   \n",
       "75%      18.000000    39.900000   -79.970000     0.169492     7.000000   \n",
       "max     252.000000    61.170000   -64.970000     0.777240     7.000000   \n",
       "\n",
       "           DEP_HOD  DEP_LAT  DEP_LON     DIFF_LAT     DIFF_LON     DISTANCE  \\\n",
       "count  1000.000000  1000.00  1000.00  1000.000000  1000.000000  1000.000000   \n",
       "mean     14.378000    33.63   -84.42     0.412909     0.751279     0.137534   \n",
       "std       4.654114     0.00     0.00     0.121666     0.144924     0.121488   \n",
       "min       5.000000    33.63   -84.42     0.014493     0.000000     0.000000   \n",
       "25%      10.000000    33.63   -84.42     0.313320     0.692333     0.062985   \n",
       "50%      14.000000    33.63   -84.42     0.417989     0.800795     0.106730   \n",
       "75%      18.000000    33.63   -84.42     0.510697     0.837092     0.150884   \n",
       "max      23.000000    33.63   -84.42     1.000000     0.998174     1.000000   \n",
       "\n",
       "       MEAN_TEMP_ARR  MEAN_TEMP_DEP  MEAN_VIS_ARR  MEAN_VIS_DEP  WND_SPD_ARR  \\\n",
       "count    1000.000000    1000.000000   1000.000000   1000.000000  1000.000000   \n",
       "mean        0.541755       0.639660      0.434478      0.727578     0.006493   \n",
       "std         0.132366       0.195845      0.074008      0.210591     0.002687   \n",
       "min         0.106884       0.214286      0.086022      0.375000     0.000700   \n",
       "25%         0.474638       0.483193      0.408602      0.515625     0.004700   \n",
       "50%         0.564312       0.684874      0.467742      0.671875     0.006201   \n",
       "75%         0.628623       0.816176      0.489247      0.984375     0.007901   \n",
       "max         0.947464       0.869748      0.489247      1.000000     0.024102   \n",
       "\n",
       "       WND_SPD_DEP  \n",
       "count  1000.000000  \n",
       "mean      0.349775  \n",
       "std       0.225363  \n",
       "min       0.124031  \n",
       "25%       0.209302  \n",
       "50%       0.248062  \n",
       "75%       0.604651  \n",
       "max       0.798450  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ```tf.data``` input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This reads from a CSV of pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(filename, mode, batch_size):\n",
    "\n",
    "    def _input_fn():\n",
    "        dataset = tf.data.TextLineDataset(filename)\n",
    "\n",
    "        def decode_csv(row):\n",
    "            cols = tf.decode_csv(row, record_defaults=ORDERED_TRAINING_DEFAULTS)\n",
    "            features = dict(zip(ORDERED_TRAINING_COLUMNS, cols))\n",
    "            return features\n",
    "\n",
    "        def pop_target(features):\n",
    "            target = features.pop('ARR_DELAY')\n",
    "            return features, target\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.shuffle(buffer_size=80000)\n",
    "                \n",
    "        dataset = (dataset.repeat()\n",
    "                   .map(decode_csv)\n",
    "                   .map(pop_target)\n",
    "                   .batch(batch_size))\n",
    "\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Verify the input_function's behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ARR_LAT': array([38.94, 26.68], dtype=float32),\n",
       "  'ARR_LON': array([-77.46, -80.09], dtype=float32),\n",
       "  'DEP_DELAY': array([0.12348669, 0.1283293 ], dtype=float32),\n",
       "  'DEP_DOW': array([7, 7], dtype=int32),\n",
       "  'DEP_HOD': array([21, 12], dtype=int32),\n",
       "  'DEP_LAT': array([33.63, 33.63], dtype=float32),\n",
       "  'DEP_LON': array([-84.42, -84.42], dtype=float32),\n",
       "  'DIFF_LAT': array([0.4886128 , 0.20657925], dtype=float32),\n",
       "  'DIFF_LON': array([0.8640464 , 0.83580333], dtype=float32),\n",
       "  'DISTANCE': array([0.10286955, 0.10555956], dtype=float32),\n",
       "  'MEAN_TEMP_ARR': array([0.58695644, 0.588768  ], dtype=float32),\n",
       "  'MEAN_TEMP_DEP': array([0.41176477, 0.41176477], dtype=float32),\n",
       "  'MEAN_VIS_ARR': array([0.4892473 , 0.37634405], dtype=float32),\n",
       "  'MEAN_VIS_DEP': array([0.59375, 0.59375], dtype=float32),\n",
       "  'WND_SPD_ARR': array([0.0070007 , 0.01350135], dtype=float32),\n",
       "  'WND_SPD_DEP': array([0.79844964, 0.79844964], dtype=float32)},\n",
       " array([-3., -5.], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_input_fn = make_input_fn(\n",
    "        a_training_file, mode=tf.estimator.ModeKeys.TRAIN, batch_size=2)\n",
    "    input = train_input_fn()\n",
    "    _, res = sess.run([tf.global_variables_initializer(), input])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Bucketize latitude and longitude \n",
    "We can easily understand the range of values with the help of ```pandas.describe()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>344.000000</td>\n",
       "      <td>344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.491570</td>\n",
       "      <td>-98.531599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.547964</td>\n",
       "      <td>21.746974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.480000</td>\n",
       "      <td>-176.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.450000</td>\n",
       "      <td>-111.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.715000</td>\n",
       "      <td>-93.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.907500</td>\n",
       "      <td>-82.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.280000</td>\n",
       "      <td>-64.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lat         lon\n",
       "count  344.000000  344.000000\n",
       "mean    38.491570  -98.531599\n",
       "std      8.547964   21.746974\n",
       "min     13.480000 -176.640000\n",
       "25%     33.450000 -111.675000\n",
       "50%     38.715000  -93.300000\n",
       "75%     42.907500  -82.497500\n",
       "max     71.280000  -64.800000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "select \n",
    "    distinct arrival_airport as airport, arrival_lat as lat, arrival_lon as lon \n",
    "from \n",
    "    `bigquery-samples.airline_ontime_data.flights`\n",
    "\"\"\"\n",
    "locations = dlbq.Query(query).execute().result().to_dataframe()\n",
    "locations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_boundaries = np.arange(10,80,5).tolist()\n",
    "lat_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, -95, -90, -85, -80, -75, -70, -65, -60]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_boundaries = np.arange(-100, -55, 5).tolist()\n",
    "lon_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use those boundaries in the function below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Using tf feature_column api for bucketizing, crossing and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_columns():\n",
    "    \n",
    "    ################################################################\n",
    "    #  Numerical columns for the pre-processed features\n",
    "    ################################################################\n",
    "    dep_delay = tf.feature_column.numeric_column('DEP_DELAY')\n",
    "    mean_temp_dep = tf.feature_column.numeric_column('MEAN_TEMP_DEP')\n",
    "    mean_vis_dep = tf.feature_column.numeric_column('MEAN_VIS_DEP')\n",
    "    wnd_spd_dep = tf.feature_column.numeric_column('WND_SPD_DEP')\n",
    "    mean_temp_arr = tf.feature_column.numeric_column('MEAN_TEMP_ARR')\n",
    "    mean_vis_arr = tf.feature_column.numeric_column('MEAN_VIS_ARR')\n",
    "    wnd_spd_arr = tf.feature_column.numeric_column('WND_SPD_ARR')\n",
    "    diff_lat = tf.feature_column.numeric_column('DIFF_LAT')\n",
    "    diff_lon = tf.feature_column.numeric_column('DIFF_LON')\n",
    "    distance = tf.feature_column.numeric_column('DISTANCE')\n",
    "    \n",
    "    ################################################################\n",
    "    #  Crossed and embedded\n",
    "    ################################################################\n",
    "    lat_boundaries = np.arange(10,80,5).tolist()\n",
    "    lon_boundaries = np.arange(-100, -55, 5).tolist()\n",
    "    \n",
    "    cross_size = len(lat_boundaries) * len(lon_boundaries)\n",
    "\n",
    "    arr_lat = tf.feature_column.numeric_column('ARR_LAT')\n",
    "    arr_lat_b = tf.feature_column.bucketized_column(arr_lat, lat_boundaries)\n",
    "    arr_lon = tf.feature_column.numeric_column('ARR_LON')\n",
    "    arr_lon_b = tf.feature_column.bucketized_column(arr_lon, lon_boundaries)\n",
    "    arr_geo_cross = tf.feature_column.crossed_column(['ARR_LAT', 'ARR_LON'], cross_size)\n",
    "    arr_geo_emb = tf.feature_column.embedding_column(arr_geo_cross, 10)\n",
    "\n",
    "    dep_lat = tf.feature_column.numeric_column(\"DEP_LAT\")\n",
    "    dep_lat_b = tf.feature_column.bucketized_column(dep_lat, lat_boundaries)\n",
    "    dep_lon = tf.feature_column.numeric_column(\"DEP_LON\")\n",
    "    dep_lon_b = tf.feature_column.bucketized_column(dep_lon, lon_boundaries)\n",
    "    dep_geo_cross = tf.feature_column.crossed_column(['DEP_LAT', 'DEP_LON'], cross_size)\n",
    "    dep_geo_emb = tf.feature_column.embedding_column(dep_geo_cross, 10)\n",
    "\n",
    "    dep_dow = tf.feature_column.categorical_column_with_identity(\"DEP_DOW\", num_buckets=7)\n",
    "    dep_hod = tf.feature_column.categorical_column_with_identity(\"DEP_HOD\", num_buckets=24)\n",
    "    dep_how = tf.feature_column.crossed_column([\"DEP_HOD\", \"DEP_DOW\"], 7*24)\n",
    "\n",
    "    dep_how_emb = tf.feature_column.embedding_column(dep_how, 10)\n",
    "    \n",
    "    ################################################################\n",
    "    #  Crossed and embedded\n",
    "    ################################################################\n",
    "    feature_columns = [\n",
    "        dep_how_emb, arr_geo_emb, dep_geo_emb,\n",
    "        dep_delay,\n",
    "        mean_temp_dep, mean_temp_arr, mean_vis_dep, mean_vis_arr, wnd_spd_dep, wnd_spd_arr,\n",
    "        diff_lat, diff_lon, distance\n",
    "    ]\n",
    "    \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â These feature columns will feed straight into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = create_feature_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model function and custom estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_fn(feature_columns):\n",
    "    \n",
    "    def _model_fn(features, labels, mode, params):\n",
    "\n",
    "        input_layer = tf.feature_column.input_layer( \n",
    "            features, feature_columns=feature_columns)\n",
    "\n",
    "        #############################################################\n",
    "        # This single line is the actual model\n",
    "        #############################################################\n",
    "        out = tf.layers.dense(input_layer, 1, activation=None)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=out)\n",
    "\n",
    "\n",
    "        labels = tf.expand_dims(labels, -1)\n",
    "        loss = tf.losses.mean_squared_error(labels, out)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:    \n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss = loss,\n",
    "                #eval_metric_ops={'my_metric': }\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(params['learning_rate'])\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(  \n",
    "                mode,\n",
    "                loss = loss,\n",
    "                train_op = train_op)\n",
    "        \n",
    "    return _model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5de4315e90>, '_model_dir': '/home/jupyter/data/model', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5de4315e90>, '_model_dir': '/home/jupyter/data/model', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "config = tf.estimator.RunConfig(model_dir=MODEL_DIR)\n",
    "\n",
    "model_fn = make_model_fn(FEATURE_COLUMNS)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "        config=config,\n",
    "        model_fn=model_fn,\n",
    "        params={\n",
    "            'learning_rate': 1e-3\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### The tft serving input function\n",
    "The saved ```transform_fn``` of the preprocessing step is recovered and applied to the signature input, which is represented by placeholders.\n",
    "This function will be exported together with the ```tf.feature_columns``` transforms after training, to support exactly the same preprocessing steps will can also be executed.\n",
    "The estimator will first apply this function (actually, attach this graph) to the signature data coming at prediction time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tft_serving_input_fn(metadata_dir):\n",
    "\n",
    "    def _input_fn():\n",
    "        # placeholders for all the raw inputs\n",
    "        placeholders = {\n",
    "            key: tf.placeholder(name = key, shape=[None], dtype=tf.int64)\n",
    "            for key in SIGNATURE_INT_COLUMNS\n",
    "        }\n",
    "        placeholders.update({\n",
    "            key: tf.placeholder(name = key, shape=[None], dtype=tf.float32)\n",
    "            for key in SIGNATURE_FLOAT_COLUMNS\n",
    "        })\n",
    "\n",
    "        # transform using the saved model in transform_fn        \n",
    "        transform_output = tft.TFTransformOutput(transform_output_dir=metadata_dir)\n",
    "        features = transform_output.transform_raw_features(placeholders)\n",
    "            \n",
    "        return tf.estimator.export.ServingInputReceiver(features, placeholders)\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training and Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At last, start the training!\n",
    "First, we use the smaller sample data to verify the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage='sample'\n",
    "gsdirs = directories('gs', stage)\n",
    "localdirs = directories('local', stage)\n",
    "localdatadir = localdirs['data']\n",
    "METADATA_DIR=gsdirs['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to start from scratch, execute this before the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/data/model'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(MODEL_DIR, ignore_errors=True)\n",
    "!mkdir -p $MODEL_DIR\n",
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_DIR=gsdirs['metadata']\n",
    "exporter = tf.estimator.LatestExporter('exporter', make_tft_serving_input_fn(METADATA_DIR))\n",
    "\n",
    "train_input_fn = make_input_fn(\n",
    "    a_training_file, mode=tf.estimator.ModeKeys.TRAIN, batch_size=128)\n",
    "\n",
    "eval_input_fn = make_input_fn(\n",
    "    an_eval_file, mode=tf.estimator.ModeKeys.EVAL, batch_size=128)  \n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=1000)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps = 50, exporters=exporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1303.9348, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1303.9348, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 54.1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 54.1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1393.6555, step = 501 (9.238 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1393.6555, step = 501 (9.238 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-11-11-12:13:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-11-11-12:13:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [35/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [35/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [45/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [45/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-11-11-12:13:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-11-11-12:13:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1681.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1681.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /home/jupyter/data/model/export/exporter/temp-1541938383/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /home/jupyter/data/model/export/exporter/temp-1541938383/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 711.58887.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 711.58887.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'global_step': 1000, 'loss': 1681.958},\n",
       " ['/home/jupyter/data/model/export/exporter/1541938383'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(estimator, train_spec=train_spec, eval_spec=eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Train with the full training set of ~300k records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage='full'\n",
    "gsdirs = directories('gs', stage)\n",
    "localdirs = directories('local', stage)\n",
    "localdatadir = localdirs['data']\n",
    "METADATA_DIR=gsdirs['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying first 6 of gs://going-tfx/full/data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gs://going-tfx/full/data/atl_june_eval-00000-of-00001',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00000-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00001-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00002-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00003-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00004-of-00005']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdatadir = gsdirs['data']\n",
    "res = !gsutil ls $gsdatadir\n",
    "print(\"Displaying first 6 of {}.\".format(gsdatadir))\n",
    "res[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Copy the files to local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/atl_june/full/data'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localdatadir = localdirs['data']\n",
    "!mkdir -p $localdatadir\n",
    "localdatadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = !gsutil -m cp $gsdatadir/*eval* $localdatadir\n",
    "_ = !gsutil -m cp $gsdatadir/*train* $localdatadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_files=!ls $localdatadir/atl_june_train-*-of-00005\n",
    "all_eval_files=!ls $localdatadir/atl_june_eval-*-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/tmp/atl_june/full/data/atl_june_train-00000-of-00005',\n",
       "  '/tmp/atl_june/full/data/atl_june_train-00001-of-00005',\n",
       "  '/tmp/atl_june/full/data/atl_june_train-00002-of-00005',\n",
       "  '/tmp/atl_june/full/data/atl_june_train-00003-of-00005',\n",
       "  '/tmp/atl_june/full/data/atl_june_train-00004-of-00005'],\n",
       " ['/tmp/atl_june/full/data/atl_june_eval-00000-of-00001'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_files, all_eval_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Create the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(train_files, eval_files, model_fn, config, options):\n",
    "    \n",
    "    former_verbosity=tf.logging.get_verbosity()\n",
    "    \n",
    "    metadata_dir = options['metadata_dir']\n",
    "    max_train_steps = options['max_train_steps']\n",
    "    eval_steps = options['eval_steps']\n",
    "    train_batch_size=options['train_batch_size']\n",
    "    eval_batch_size=options['eval_batch_size']\n",
    "   \n",
    "    #################################################################################################\n",
    "    #  Make the input functions from the file names passed herein\n",
    "    #################################################################################################\n",
    "    train_input_fn = make_input_fn(\n",
    "        train_files, mode=tf.estimator.ModeKeys.TRAIN, batch_size=train_batch_size)\n",
    "\n",
    "    eval_input_fn = make_input_fn(\n",
    "        eval_files, mode=tf.estimator.ModeKeys.EVAL, batch_size=eval_batch_size)  \n",
    "\n",
    "    #################################################################################################\n",
    "    #  Make the serving input function and hand it to an exporter\n",
    "    #################################################################################################\n",
    "    exporter = tf.estimator.LatestExporter('exporter', make_tft_serving_input_fn(metadata_dir))\n",
    "\n",
    "    #################################################################################################\n",
    "    #  Create train and eval specification \n",
    "    #################################################################################################\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=max_train_steps)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps = eval_steps, exporters=exporter)    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  And finally, the estimator\n",
    "    #################################################################################################\n",
    "    tf.logging.set_verbosity(tf.logging.WARN)\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        config=config,\n",
    "        model_fn=model_fn,\n",
    "        params={\n",
    "            'feature_columns': FEATURE_COLUMNS,\n",
    "            'learning_rate': 1e-3\n",
    "        })\n",
    "    tf.logging.set_verbosity(former_verbosity)\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_steps=1000,\n",
    "    save_summary_steps=100,\n",
    "    log_step_count_steps=500,\n",
    "    model_dir=MODEL_DIR\n",
    ")\n",
    "\n",
    "options={\n",
    "    'metadata_dir': METADATA_DIR,\n",
    "    'max_train_steps': 10000,\n",
    "    'eval_steps': 5,\n",
    "    'train_batch_size': 128,\n",
    "    'eval_batch_size': 1024\n",
    "}\n",
    "    \n",
    "estimator = create_estimator(\n",
    "    train_files=all_train_files,\n",
    "    eval_files=all_eval_files, \n",
    "    model_fn=make_model_fn(feature_columns=FEATURE_COLUMNS),\n",
    "    config = config,\n",
    "    options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $MODEL_DIR/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2202.5923, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2202.5923, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 54.2877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 54.2877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1146.7485, step = 501 (9.219 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1146.7485, step = 501 (9.219 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /home/jupyter/data/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-11-11-12:00:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-11-11-12:00:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [35/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [35/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [45/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [45/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-11-11-12:00:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-11-11-12:00:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1693.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1693.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:partially_apply_saved_transform is deprecated.  Use the transform_raw_features method of the TFTrandformOutput class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:partially_apply_saved_transform is deprecated.  Use the transform_raw_features method of the TFTrandformOutput class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jupyter/data/model/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /home/jupyter/data/model/export/exporter/temp-1541937613/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /home/jupyter/data/model/export/exporter/temp-1541937613/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1282.4895.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1282.4895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "#tf.logging.set_verbosity(tf.logging.WARN)\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Prediction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signature data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get some test data. Now we need signature data, and that's what we have in Bigquery. Remember? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT\n",
      "        DEP_LAT, DEP_LON, DEP_DELAY, MEAN_TEMP_DEP, MEAN_VIS_DEP, WND_SPD_DEP, ARR_LAT, ARR_LON, ARR_DELAY, MEAN_TEMP_ARR, MEAN_VIS_ARR, WND_SPD_ARR, DEP_DOW, DEP_T\n",
      "    FROM \n",
      "        `going-tfx.examples.ATL_JUNE_SIGNATURE` \n",
      "    where\n",
      "        MOD(ABS(FARM_FINGERPRINT(\n",
      "            CONCAT(DATE,AIRLINE,ARR)\n",
      "        )) + DEP_T, 10000) >= 0 \n",
      "    and\n",
      "        MOD(ABS(FARM_FINGERPRINT(\n",
      "            CONCAT( DATE, AIRLINE, ARR)\n",
      "        )) + DEP_T, 10000) < 1 \n",
      "    \n",
      "Only 40 examples. Showing first three:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>35.87</td>\n",
       "      <td>-78.78</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>-87.18</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>79.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>35.81</td>\n",
       "      <td>-83.99</td>\n",
       "      <td>14.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEP_LAT  DEP_LON  DEP_DELAY  MEAN_TEMP_DEP  MEAN_VIS_DEP  WND_SPD_DEP  \\\n",
       "0    33.63   -84.42       -1.0           74.5           6.9          9.8   \n",
       "1    33.63   -84.42       -3.0           74.0           7.6          5.0   \n",
       "2    33.63   -84.42       16.0           76.7           9.5          7.7   \n",
       "\n",
       "   ARR_LAT  ARR_LON  ARR_DELAY  MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  \\\n",
       "0    35.87   -78.78        7.0           78.6           9.0          4.6   \n",
       "1    30.47   -87.18       -9.0           79.7          10.0          4.8   \n",
       "2    35.81   -83.99       14.0           74.2           9.9          9.8   \n",
       "\n",
       "   DEP_DOW  DEP_T  \n",
       "0        1   1030  \n",
       "1        1   1025  \n",
       "2        1   1608  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIGNATURE_COLUMNS = SIGNATURE_FLOAT_COLUMNS+SIGNATURE_INT_COLUMNS\n",
    "signature_query=sample_query(SIGNATURE_COLUMNS, total=10000)\n",
    "print(signature_query)\n",
    "sample = dlbq.Query(signature_query).execute().result().to_dataframe()\n",
    "print('Only {} examples. Showing first three:'.format(len(sample)))\n",
    "sample[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"WND_SPD_DEP\": 9.8, \"DEP_DELAY\": -1.0, \"ARR_LAT\": 35.87, \"WND_SPD_ARR\": 4.6, \"MEAN_VIS_DEP\": 6.9, \"DEP_T\": 1030.0, \"MEAN_TEMP_ARR\": 78.6, \"DEP_LON\": -84.42, \"DEP_DOW\": 1.0, \"MEAN_VIS_ARR\": 9.0, \"MEAN_TEMP_DEP\": 74.5, \"DEP_LAT\": 33.63, \"ARR_LON\": -78.78}"
     ]
    }
   ],
   "source": [
    "samplefile='/tmp/test.json'\n",
    "a_record = sample.to_dict(orient='records')[0]\n",
    "a_record.pop('ARR_DELAY')\n",
    "with open(samplefile, 'w') as f:\n",
    "    f.write(json.dumps(a_record))\n",
    "!cat $samplefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Local prediction with gcloud ml-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest model: 1541926921\n",
      "OUTPUT\n",
      "[14.867263793945312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 2018-11-11 09:12:35.829041: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-11-11 09:12:35.836020: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "latest=$(ls -tr /home/jupyter/data/model/export/exporter | tail -1)\n",
    "echo Latest model: $latest\n",
    "gcloud ml-engine local predict \\\n",
    "  --model-dir=/home/jupyter/data/model/export/exporter/$latest \\\n",
    "  --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
