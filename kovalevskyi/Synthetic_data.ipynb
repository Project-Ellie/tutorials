{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Models With Synthetic Data\n",
    "The advantage of synthetic data is that we know the prior or ground truth and we know exactly how concealed it is. That helps us to determine with certainty that an algorithm is per se capable of discovering the ground truth. If an algorithm fails on the easy task of learning from synthetic data, then it won't be good in real life. The opposite, unfortunately, is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "from tools import print_progress, array_in, create_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Noisy Samples From A Well-Known Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a*x+b\n",
    "def make_lin(a, b, rnd):\n",
    "    def _f_a(x):\n",
    "        mu = a*x + b\n",
    "        return rnd(mu)\n",
    "    return _f_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Two linear but noisy signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = make_lin(2, 1, lambda mu: np.random.normal(loc=mu, scale=1.0))\n",
    "f_b = make_lin(-.5, -1.5, lambda mu: np.random.normal(loc=mu, scale=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A look at one of the signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE7lJREFUeJzt3X+w3XV95/HnS4iNWGqUpJTJTXpDYeyirZW9sO2wdV1ZKxIbaKfrYG1LEZvdWbS4dkYD21ncmXUmzrairlunWUINLSVS1IYtlDVSWusfEBNE+REoGYhyUzARSxEVA/G9f5xv5G74hpx77zn3e+7N8zFz557v53zP+b6GIXnl+/n+SlUhSdKhXtR1AEnSaLIgJEmtLAhJUisLQpLUyoKQJLWyICRJrSwISVIrC0KS1MqCkCS1OrbrALOxdOnSGh8f7zqGJM0rO3bs+GZVLTvSevO6IMbHx9m+fXvXMSRpXknytX7Wc4pJktTKgpAktRpaQSS5OsneJPe0vPd7SSrJ0mY5ST6WZFeSryY5fVi5JEn9GeYxiE8CHweumTqYZAXwS8DXpwy/GTi1+flXwCea35I0kp555hkmJyd5+umnu45yWIsXL2ZsbIxFixbN6PNDK4iq+kKS8Za3rgTeB2yZMnYecE31Hk5xe5IlSU6qqkeHlU+SZmNycpLjjz+e8fFxknQd53mqiscff5zJyUlWrVo1o++Y02MQSc4D9lTVVw55aznwyJTlyWZMkkbS008/zQknnDCS5QCQhBNOOGFWezhzdpprkuOAy+lNL83me9YCawFWrlw5gGSSNDOjWg4HzTbfXO5B/BSwCvhKkt3AGHBnkp8A9gArpqw71ow9T1VtqKqJqppYtuyI13lIkmZozvYgqupu4McPLjclMVFV30xyI/CuJJvpHZz+Z48/SJpPxtfdNNDv271+9RHXueWWW7j00ks5cOAA73znO1m3bt1AMwytIJJcB7weWJpkEriiqjYeZvWbgXOBXcB3gYuGlUtHl9n8oe3nD6jUlQMHDnDJJZewdetWxsbGOOOMM1izZg2nnXbawLYxzLOY3naE98envC7gkmFlkaSFZtu2bZxyyimcfPLJAFxwwQVs2bJloAXhldSSNA/t2bOHFSueO3Q7NjbGnj2th25nzIKQJLWyICRpHlq+fDmPPPLc5WOTk5MsXz7Yy8csCEmah8444wwefPBBHn74Yfbv38/mzZtZs2bNQLcxr58HIUmjYq7Pejv22GP5+Mc/zpve9CYOHDjAO97xDl71qlcNdhsD/TZJ0pw599xzOffcc4f2/U4xSZJaWRCSpFYWhCTNUO8a39E123wWhCTNwOLFi3n88cdHtiQOPg9i8eLFM/4OD1JL0gyMjY0xOTnJvn37uo5yWAefKDdTFoQkzcCiRYtm/KS2+cIpJklSKwtCktTKgpAktbIgJEmtLAhJUisLQpLUyoKQJLXyOgjpMMbX3TSrz8/17Z+lQXMPQpLUamgFkeTqJHuT3DNl7H8kuT/JV5N8NsmSKe9dlmRXkgeSvGlYuSRJ/RnmHsQngXMOGdsKvLqqfhb4B+AygCSnARcAr2o+80dJjhliNknSEQytIKrqC8C3Dhn7XFU92yzeDhy8i9R5wOaq+n5VPQzsAs4cVjZJ0pF1eQziHcBfN6+XA49MeW+yGZMkdaSTs5iS/BfgWeDaGXx2LbAWYOXKlQNOplE027OJJM3MnO9BJPlt4C3A2+u5J23sAVZMWW2sGXueqtpQVRNVNbFs2bKhZpWko9mcFkSSc4D3AWuq6rtT3roRuCDJjyRZBZwKbJvLbJKk/9/QppiSXAe8HliaZBK4gt5ZSz8CbE0CcHtV/cequjfJ9cB99KaeLqmqA8PKJkk6sqEVRFW9rWV44wus/0Hgg8PKI0maHq+kliS1siAkSa0sCElSKwtCktTKgpAktbIgJEmtLAhJUisLQpLUyoKQJLWyICRJrSwISVIrC0KS1MqCkCS1siAkSa06eeSodDSYzaNSd69fPcAk0sy4ByFJamVBSJJaWRCSpFYWhCSplQUhSWplQUiSWg2tIJJcnWRvknumjL0iydYkDza/X96MJ8nHkuxK8tUkpw8rlySpP8Pcg/gkcM4hY+uAW6vqVODWZhngzcCpzc9a4BNDzCVJ6sPQCqKqvgB865Dh84BNzetNwPlTxq+pntuBJUlOGlY2SdKRzfUxiBOr6tHm9WPAic3r5cAjU9abbMYkSR3p7FYbVVVJarqfS7KW3jQUK1euHHguaRR4mw6Ngrneg/jGwamj5vfeZnwPsGLKemPN2PNU1YaqmqiqiWXLlg01rCQdzea6IG4ELmxeXwhsmTL+W83ZTD8P/POUqShJUgeGNsWU5Drg9cDSJJPAFcB64PokFwNfA97arH4zcC6wC/gucNGwckmS+jO0gqiqtx3mrbNb1i3gkmFlkSRNn1dSS5JaWRCSpFYWhCSplQUhSWplQUiSWlkQkqRWFoQkqZUFIUlqZUFIklpZEJKkVhaEJKmVBSFJatVXQST5mWEHkSSNln73IP4oybYk/ynJy4aaSJI0EvoqiKr6ReDt9J76tiPJnyd541CTSZI61fcxiKp6EPh94P3AvwE+luT+JL86rHCSpO70ewziZ5NcCewE3gD8clX9i+b1lUPMJ0nqSL9PlPufwFXA5VX1vYODVfWPSX5/KMm0oIyvu6nrCJKmqd+CWA18r6oOACR5EbC4qr5bVX86tHSSpM70ewzi88BLpiwf14xJkhaofgticVU9dXCheX3ccCJJkkZBvwXxnSSnH1xI8i+B773A+i8oyX9Ocm+Se5Jcl2RxklVJ7kiyK8mnkrx4pt8vSZq9fgviPcBfJPn7JF8EPgW8ayYbTLIc+F1goqpeDRwDXAB8CLiyqk4B/gm4eCbfL0kajL4OUlfVl5L8NPDKZuiBqnpmltt9SZJn6E1VPUrvlNlfb97fBHwA+MQstiFJmoV+z2ICOAMYbz5zehKq6prpbrCq9iT5A+Dr9KapPgfsAJ6oqmeb1SaB5dP9bknS4PRVEEn+FPgp4C7gQDNcwLQLIsnLgfOAVcATwF8A50zj82uBtQArV66c7uYlSX3qdw9iAjitqmoA2/x3wMNVtQ8gyWeAs4AlSY5t9iLGgD1tH66qDcAGgImJiUHkkSS16Pcg9T3ATwxom18Hfj7JcUkCnA3cB9wG/FqzzoXAlgFtT5I0A/3uQSwF7kuyDfj+wcGqWjPdDVbVHUluAO4EngW+TG+P4CZgc5L/3oxtnO53S5IGp9+C+MAgN1pVVwBXHDL8EHDmILcjSZq5fk9z/bskPwmcWlWfT3IcvesXJEkLVL+3+/4d4Abgj5uh5cBfDiuUJKl7/R6kvoTemUZPwg8fHvTjwwolSepevwXx/araf3AhybH0roOQJC1Q/RbE3yW5nN7tMd5I7+K2/zO8WJKkrvVbEOuAfcDdwH8Abqb3fGpJ0gLV71lMPwD+d/MjSToK9HsvpodpOeZQVScPPJEkaSRM515MBy0G/j3wisHHkSSNir6OQVTV41N+9lTVR4DVQ84mSepQv1NMp09ZfBG9PYrpPEtCkjTP9PuX/B9Oef0ssBt468DTSJJGRr9nMf3bYQeRJI2WfqeY3vtC71fVhwcTR6NsfN1NXUeQNIemcxbTGcCNzfIvA9uAB4cRSpLUvX4LYgw4vaq+DZDkA8BNVfUbwwomSepWv7faOBHYP2V5fzMmSVqg+t2DuAbYluSzzfL5wKbhRJIkjYJ+z2L6YJK/Bn6xGbqoqr48vFiSpK71O8UEcBzwZFV9FJhMsmpImSRJI6DfR45eAbwfuKwZWgT82bBCSZK61+8exK8Aa4DvAFTVPwLHz3SjSZYkuSHJ/Ul2JvmFJK9IsjXJg83vl8/0+yVJs9dvQeyvqqK55XeSl85yux8FbqmqnwZeA+yk91CiW6vqVODWZlmS1JF+C+L6JH8MLEnyO8DnmeHDg5K8DHgdsBGgqvZX1RPAeTx3ZtQmemdKSZI60u9ZTH/QPIv6SeCVwH+tqq0z3OYqeo8v/ZMkrwF2AJcCJ1bVo806j+F1FpLUqSMWRJJjgM83N+ybaSkcus3TgXdX1R1JPsoh00lVVUme9wS7Js9aYC3AypUrBxBHktTmiFNMVXUA+EEzNTQIk8BkVd3RLN9ArzC+keQkgOb33sPk2VBVE1U1sWzZsgFFkiQdqt8rqZ8C7k6yleZMJoCq+t3pbrCqHkvySJJXVtUDwNnAfc3PhcD65veW6X63JGlw+i2IzzQ/g/Ju4NokLwYeAi6itzdzfZKLga/hA4kkqVMvWBBJVlbV16tqoPddqqq76N1C/FBnD3I7kqSZO9IxiL88+CLJp4ecRZI0Qo5UEJny+uRhBpEkjZYjFUQd5rUkaYE70kHq1yR5kt6exEua1zTLVVU/NtR0kqTOvGBBVNUxcxVE0mCMr7tpxp/dvX71AJNovpvO8yAkSUcRC0KS1MqCkCS1siAkSa0sCElSKwtCktTKgpAktbIgJEmtLAhJUisLQpLUyoKQJLXq94lyWgBmc48eSUcf9yAkSa0sCElSKwtCktTKgpAkteqsIJIck+TLSf6qWV6V5I4ku5J8KsmLu8omSep2D+JSYOeU5Q8BV1bVKcA/ARd3kkqSBHRUEEnGgNXAVc1ygDcANzSrbALO7yKbJKmnqz2IjwDvA37QLJ8APFFVzzbLk8DyLoJJknrmvCCSvAXYW1U7Zvj5tUm2J9m+b9++AaeTJB3UxR7EWcCaJLuBzfSmlj4KLEly8MruMWBP24erakNVTVTVxLJly+YiryQdlea8IKrqsqoaq6px4ALgb6rq7cBtwK81q10IbJnrbJKk54zSdRDvB96bZBe9YxIbO84jSUe1Tm/WV1V/C/xt8/oh4Mwu80iSnjNKexCSpBFiQUiSWvk8CEk/NJtnhuxev3qASTQK3IOQJLVyD0LSQMz2iYXugYwe9yAkSa0sCElSKwtCktTKgpAktbIgJEmtLAhJUisLQpLUyoKQJLWyICRJrSwISVIrC0KS1MqCkCS1siAkSa0sCElSK2/3Pc/M9pbKktQv9yAkSa3mvCCSrEhyW5L7ktyb5NJm/BVJtiZ5sPn98rnOJkl6ThdTTM8Cv1dVdyY5HtiRZCvw28CtVbU+yTpgHfD+DvINndNEkuaDOd+DqKpHq+rO5vW3gZ3AcuA8YFOz2ibg/LnOJkl6TqfHIJKMA68F7gBOrKpHm7ceA07sKJYkiQ4LIsmPAp8G3lNVT059r6oKqMN8bm2S7Um279u3bw6SStLRqZPTXJMsolcO11bVZ5rhbyQ5qaoeTXISsLfts1W1AdgAMDEx0Voikuaf2Ryb271+9QCT6KAuzmIKsBHYWVUfnvLWjcCFzesLgS1znU2S9Jwu9iDOAn4TuDvJXc3Y5cB64PokFwNfA97aQTZJUmPOC6KqvgjkMG+fPZdZJEmH55XUkqRWFoQkqZUFIUlqZUFIklpZEJKkVhaEJKmVBSFJamVBSJJaWRCSpFYWhCSplQUhSWplQUiSWlkQkqRWnTwwaCGYzcNNJGk+sCAkzXs+jW44nGKSJLWyICRJrSwISVIrC0KS1OqoPUjtWUiS9MLcg5AktRq5gkhyTpIHkuxKsq7rPJJ0tBqpKaYkxwD/C3gjMAl8KcmNVXVft8kkLVRdXkMx6tdvjFRBAGcCu6rqIYAkm4HzAAtC0shZ6McyR22KaTnwyJTlyWZMkjTHRm0P4oiSrAXWNotPJXmgz48uBb45nFRDZ/ZumL0bZu9DPjSrj/9kPyuNWkHsAVZMWR5rxn6oqjYAG6b7xUm2V9XE7OJ1w+zdMHs3zD46Rm2K6UvAqUlWJXkxcAFwY8eZJOmoNFJ7EFX1bJJ3Af8XOAa4uqru7TiWJB2VRqogAKrqZuDmIXz1tKelRojZu2H2bph9RKSqus4gSRpBo3YMQpI0IhZ8QcznW3ckuTrJ3iT3dJ1lOpKsSHJbkvuS3Jvk0q4z9SvJ4iTbknylyf7fus40XUmOSfLlJH/VdZbpSLI7yd1J7kqyves805FkSZIbktyfZGeSX+g60yAs6Cmm5tYd/8CUW3cAb5svt+5I8jrgKeCaqnp113n6leQk4KSqujPJ8cAO4Pz58N89SYCXVtVTSRYBXwQurarbO47WtyTvBSaAH6uqt3Sdp19JdgMTVTXvroFIsgn4+6q6qjkD87iqeqLrXLO10PcgfnjrjqraDxy8dce8UFVfAL7VdY7pqqpHq+rO5vW3gZ3Mkyviq+epZnFR8zNv/hWVZAxYDVzVdZajRZKXAa8DNgJU1f6FUA6w8AvCW3d0LMk48Frgjm6T9K+ZorkL2Atsrap5kx34CPA+4AddB5mBAj6XZEdzx4T5YhWwD/iTZmrvqiQv7TrUICz0glCHkvwo8GngPVX1ZNd5+lVVB6rq5+hdyX9mknkxvZfkLcDeqtrRdZYZ+tdVdTrwZuCSZop1PjgWOB34RFW9FvgOMK+Odx7OQi+II966Q8PRzN9/Gri2qj7TdZ6ZaKYJbgPO6TpLn84C1jRz+ZuBNyT5s24j9a+q9jS/9wKfpTdFPB9MApNT9jRvoFcY895CLwhv3dGB5kDvRmBnVX246zzTkWRZkiXN65fQO8Hh/m5T9aeqLquqsaoap/f/+t9U1W90HKsvSV7anNBAMz3zS8C8OHuvqh4DHknyymbobBbIIwpG7krqQZrvt+5Ich3wemBpkkngiqra2G2qvpwF/CZwdzOXD3B5c5X8qDsJ2NScAfci4Pqqmleni85TJwKf7f3bgmOBP6+qW7qNNC3vBq5t/iH6EHBRx3kGYkGf5ipJmrmFPsUkSZohC0KS1MqCkCS1siAkSa0sCElSKwtCktTKgpAktbIgJEmt/h8nWk81vs7S5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([f_a(1) for i in range(1000)])\n",
    "df.plot.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we create a data set/frame representing $f_a(x)+f_b(y)$ as a random variable that depends on random variables $x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v1(size):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'f': f_data, 'p': f_perf})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, this is equivalent to saying that the ground truth is:\n",
    "\n",
    "$$ f(x, y) = 2x - \\frac{1}{2} y - \\frac{1}{2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.704385</td>\n",
       "      <td>1.201487</td>\n",
       "      <td>0.233845</td>\n",
       "      <td>-2.467594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.979604</td>\n",
       "      <td>10.749027</td>\n",
       "      <td>4.783246</td>\n",
       "      <td>-3.365071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.129560</td>\n",
       "      <td>-10.380209</td>\n",
       "      <td>-4.193968</td>\n",
       "      <td>2.984546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.928761</td>\n",
       "      <td>-8.116644</td>\n",
       "      <td>-3.310922</td>\n",
       "      <td>1.989600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.377157</td>\n",
       "      <td>-6.458897</td>\n",
       "      <td>-2.440631</td>\n",
       "      <td>2.155271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y\n",
       "0   2.704385   1.201487  0.233845 -2.467594\n",
       "1  11.979604  10.749027  4.783246 -3.365071\n",
       "2 -11.129560 -10.380209 -4.193968  2.984546\n",
       "3  -4.928761  -8.116644 -3.310922  1.989600\n",
       "4  -6.377157  -6.458897 -2.440631  2.155271"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_data_frame_v1(NUM_RECORDS)\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Linear Regressor From Scratch With Tensorflow\n",
    "Let's train a self-made tensorflow linear regressor with the synthetic data to see whether it finds the coefficients above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Was already closed or didn't exist. That's fine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    print(\"OK. Was already closed or didn't exist. That's fine.\")\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating The Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, x_dim, lr):\n",
    "\n",
    "        # Variables for the parameters: weights M and bias b\n",
    "        self.M = tf.Variable(tf.zeros(shape=(1, x_dim)))\n",
    "        self.b = tf.Variable(0.)\n",
    "\n",
    "        # Placeholders for x and labels\n",
    "        self.x = tf.placeholder(shape=(x_dim,None), dtype=tf.float32)\n",
    "        self.lbls = tf.placeholder(shape=(1,None), dtype=tf.float32)\n",
    "\n",
    "        # The prediction and the distance (loss)\n",
    "        self.f = tf.matmul(self.M, self.x) + self.b\n",
    "        self.d = tf.losses.mean_squared_error(self.lbls, self.f)\n",
    "\n",
    "        # The gradients\n",
    "        self.nM = tf.gradients(self.d, self.M)\n",
    "        self.nb = tf.gradients(self.d, self.b)\n",
    "\n",
    "        # The optimizers\n",
    "        self.aM = tf.assign_add( self.M, tf.multiply(self.nM[0],-lr))\n",
    "        self.ab = tf.assign_add( self.b, tf.multiply(self.nb[0], -lr))\n",
    "\n",
    "        # The initializer\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def train(self, sess, x_data, labels_data, num_steps):        \n",
    "        sess.run(self.init)\n",
    "        for i in range(num_steps):\n",
    "            _, dist, _, _, _, _ = sess.run([self.f, self.d, self.nM, self.nb, self.aM, self.ab], \n",
    "                                           feed_dict = {self.x: x_data, self.lbls: labels_data})\n",
    "            print_progress(\"- Loss: {}\", dist)\n",
    "        return dist\n",
    "    \n",
    "    def predict(self, sess, x_data):\n",
    "        pred = sess.run(self.f, feed_dict={self.x: x_data})\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Perform The Training And Examine The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [list(df_train['x']), list(df_train['y'])]\n",
    "lbls_data = [list(df_train['f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 1.94614493847"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9461449"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = Linear(x_dim=2, lr=0.01)\n",
    "linear1.train(sess, input_data, lbls_data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the parameters to be close to $2, -0.5, -0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.0056808, -0.493813 ]], dtype=float32), -0.4829545]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([linear1.M, linear1.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now the tensor f represents the hypothesis. Let's evaluate it with some fresh test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = create_data_frame_v1(size=10000)\n",
    "test_data = [list(df_test['x']), list(df_test['y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear1.predict(sess=sess, x_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.301999</td>\n",
       "      <td>2.639552</td>\n",
       "      <td>2.563829</td>\n",
       "      <td>3.976211</td>\n",
       "      <td>2.695763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.079516</td>\n",
       "      <td>9.446649</td>\n",
       "      <td>4.482346</td>\n",
       "      <td>-1.963914</td>\n",
       "      <td>9.477007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.028062</td>\n",
       "      <td>4.956093</td>\n",
       "      <td>3.696011</td>\n",
       "      <td>3.871858</td>\n",
       "      <td>5.018090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.598048</td>\n",
       "      <td>7.535333</td>\n",
       "      <td>3.710391</td>\n",
       "      <td>-1.229102</td>\n",
       "      <td>7.565852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.261907</td>\n",
       "      <td>-7.177090</td>\n",
       "      <td>-2.913286</td>\n",
       "      <td>1.701035</td>\n",
       "      <td>-7.166070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.630704</td>\n",
       "      <td>-5.022695</td>\n",
       "      <td>-2.060982</td>\n",
       "      <td>0.801461</td>\n",
       "      <td>-5.012399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.184291</td>\n",
       "      <td>0.110887</td>\n",
       "      <td>-0.892570</td>\n",
       "      <td>-4.792055</td>\n",
       "      <td>0.093213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.135552</td>\n",
       "      <td>10.428042</td>\n",
       "      <td>4.846239</td>\n",
       "      <td>-2.471127</td>\n",
       "      <td>10.457331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.929766</td>\n",
       "      <td>-1.075982</td>\n",
       "      <td>-0.919770</td>\n",
       "      <td>-2.527114</td>\n",
       "      <td>-1.079797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.958737</td>\n",
       "      <td>5.163309</td>\n",
       "      <td>1.886791</td>\n",
       "      <td>-3.779453</td>\n",
       "      <td>5.167690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions\n",
       "0   4.301999   2.639552  2.563829  3.976211     2.695763\n",
       "1  11.079516   9.446649  4.482346 -1.963914     9.477007\n",
       "2   5.028062   4.956093  3.696011  3.871858     5.018090\n",
       "3   8.598048   7.535333  3.710391 -1.229102     7.565852\n",
       "4  -8.261907  -7.177090 -2.913286  1.701035    -7.166070\n",
       "5  -4.630704  -5.022695 -2.060982  0.801461    -5.012399\n",
       "6   1.184291   0.110887 -0.892570 -4.792055     0.093213\n",
       "7  11.135552  10.428042  4.846239 -2.471127    10.457331\n",
       "8  -0.929766  -1.075982 -0.919770 -2.527114    -1.079797\n",
       "9   4.958737   5.163309  1.886791 -3.779453     5.167690"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'] = predictions[0]\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see without surprise that the predictions are typically closer to the ground truth than to the noisy signal. This means we have enough data to average out the noise and reveal the ground truth. A look at the distribution of the errors reveals pure noise around 0. That's typically a good sign that our network has understood the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test['f'] - df_test['predictions']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensorflow LinearRegressor Estimator\n",
    "Now we'll reproduce this with the high-level estimator API. Surprisingly, the calculations here take much longer than in the basic approach above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(df_train, shuffle=True, num_epochs=100, y=df_train['f'], batch_size=NUM_RECORDS)\n",
    "feature_columns = [\n",
    "    fc.numeric_column('x', dtype=tf.float32),\n",
    "    fc.numeric_column('y', dtype=tf.float32)\n",
    "]\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp5A1Ad4\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4cd9914710>, '_model_dir': '/tmp/tmp5A1Ad4', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 5, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, config=config )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Perform the training on the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp5A1Ad4/model.ckpt.\n",
      "INFO:tensorflow:loss = 381016.44, step = 0\n",
      "INFO:tensorflow:global_step/sec: 18.5163\n",
      "INFO:tensorflow:loss = 183304.94, step = 5 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5751\n",
      "INFO:tensorflow:loss = 123007.03, step = 10 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0215\n",
      "INFO:tensorflow:loss = 89475.11, step = 15 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9046\n",
      "INFO:tensorflow:loss = 67188.66, step = 20 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3127\n",
      "INFO:tensorflow:loss = 53281.12, step = 25 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3585\n",
      "INFO:tensorflow:loss = 43669.164, step = 30 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0606\n",
      "INFO:tensorflow:loss = 36629.156, step = 35 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6665\n",
      "INFO:tensorflow:loss = 31856.191, step = 40 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8702\n",
      "INFO:tensorflow:loss = 28524.484, step = 45 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9475\n",
      "INFO:tensorflow:loss = 25849.191, step = 50 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9609\n",
      "INFO:tensorflow:loss = 24151.91, step = 55 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0782\n",
      "INFO:tensorflow:loss = 22853.918, step = 60 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3982\n",
      "INFO:tensorflow:loss = 21922.105, step = 65 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6852\n",
      "INFO:tensorflow:loss = 21237.736, step = 70 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1483\n",
      "INFO:tensorflow:loss = 20782.129, step = 75 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7673\n",
      "INFO:tensorflow:loss = 20522.535, step = 80 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7143\n",
      "INFO:tensorflow:loss = 20041.492, step = 85 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5438\n",
      "INFO:tensorflow:loss = 19967.986, step = 90 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2597\n",
      "INFO:tensorflow:loss = 19805.36, step = 95 (0.198 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmp5A1Ad4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 19750.79.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f4cd9914750>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.train(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparing The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_test = tf.estimator.inputs.pandas_input_fn(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = regressor.predict(input_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5A1Ad4/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pred_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.301999</td>\n",
       "      <td>2.639552</td>\n",
       "      <td>2.563829</td>\n",
       "      <td>3.976211</td>\n",
       "      <td>2.695763</td>\n",
       "      <td>2.545951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.079516</td>\n",
       "      <td>9.446649</td>\n",
       "      <td>4.482346</td>\n",
       "      <td>-1.963914</td>\n",
       "      <td>9.477007</td>\n",
       "      <td>9.225703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.028062</td>\n",
       "      <td>4.956093</td>\n",
       "      <td>3.696011</td>\n",
       "      <td>3.871858</td>\n",
       "      <td>5.018090</td>\n",
       "      <td>4.804597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.598048</td>\n",
       "      <td>7.535333</td>\n",
       "      <td>3.710391</td>\n",
       "      <td>-1.229102</td>\n",
       "      <td>7.565852</td>\n",
       "      <td>7.357228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.261907</td>\n",
       "      <td>-7.177090</td>\n",
       "      <td>-2.913286</td>\n",
       "      <td>1.701035</td>\n",
       "      <td>-7.166070</td>\n",
       "      <td>-7.004720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.630704</td>\n",
       "      <td>-5.022695</td>\n",
       "      <td>-2.060982</td>\n",
       "      <td>0.801461</td>\n",
       "      <td>-5.012399</td>\n",
       "      <td>-4.898073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.184291</td>\n",
       "      <td>0.110887</td>\n",
       "      <td>-0.892570</td>\n",
       "      <td>-4.792055</td>\n",
       "      <td>0.093213</td>\n",
       "      <td>0.147929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.135552</td>\n",
       "      <td>10.428042</td>\n",
       "      <td>4.846239</td>\n",
       "      <td>-2.471127</td>\n",
       "      <td>10.457331</td>\n",
       "      <td>10.186086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.929766</td>\n",
       "      <td>-1.075982</td>\n",
       "      <td>-0.919770</td>\n",
       "      <td>-2.527114</td>\n",
       "      <td>-1.079797</td>\n",
       "      <td>-1.026070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.958737</td>\n",
       "      <td>5.163309</td>\n",
       "      <td>1.886791</td>\n",
       "      <td>-3.779453</td>\n",
       "      <td>5.167690</td>\n",
       "      <td>5.064664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions  pred_estimator\n",
       "0   4.301999   2.639552  2.563829  3.976211     2.695763        2.545951\n",
       "1  11.079516   9.446649  4.482346 -1.963914     9.477007        9.225703\n",
       "2   5.028062   4.956093  3.696011  3.871858     5.018090        4.804597\n",
       "3   8.598048   7.535333  3.710391 -1.229102     7.565852        7.357228\n",
       "4  -8.261907  -7.177090 -2.913286  1.701035    -7.166070       -7.004720\n",
       "5  -4.630704  -5.022695 -2.060982  0.801461    -5.012399       -4.898073\n",
       "6   1.184291   0.110887 -0.892570 -4.792055     0.093213        0.147929\n",
       "7  11.135552  10.428042  4.846239 -2.471127    10.457331       10.186086\n",
       "8  -0.929766  -1.075982 -0.919770 -2.527114    -1.079797       -1.026070\n",
       "9   4.958737   5.163309  1.886791 -3.779453     5.167690        5.064664"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_estimator = [f['predictions'][0] for f in generator]\n",
    "df_test['pred_estimator'] = pred_estimator\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pre-canned estimator arrives at (almost) the same results as our hand-made linear regressor. Not that we had a doubt, though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning From Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that the ground truth is a totally unexpected function of the week day and time of day. That could happen e.g., if you measure the humidity and fail to realize that your sensor is near a dry-cleaner's. Let's assume the dry-cleaner's have peek hours on Mon, Tue, Wed from 18:00h to 21:00 and Fri, Sat from 14:00h to 16:00h. During those hours humidity is significantly higher due to the steam produced there. \n",
    "\n",
    "First, let's create a dataset that reflects that situation. Day of week and hour of day shall be represented by categorical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe with days of week and hour-of-day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a constant, if the hour of week \n",
    "conditions = np.array([\n",
    "    (0, 18), (0, 19), (0, 20), (0, 21), # Mondays\n",
    "    (1, 18), (1, 19), (1, 20), (1, 21), # Tuesdays\n",
    "    (2, 18), (2, 19), (2, 20), (2, 21), # Wednesdays\n",
    "    # closed on Thursdays\n",
    "    (4, 14), (4, 15), (4, 16),          # Fridays\n",
    "    (5, 14), (5, 15), (5, 16)           # Saturdays\n",
    "    # closed on Sundays\n",
    "    ])\n",
    "\n",
    "def make_noisy_amplitude_function(amplitude):\n",
    "    def _f(c1, c2):\n",
    "        zipped = zip(c1,c2)\n",
    "        res = array_in(zipped, conditions)        \n",
    "        return res * (np.random.normal( 0 * res, .2 ) + amplitude)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v2(size, amplitude=5.0):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    dow_data = np.random.randint(7, size=size)\n",
    "    hod_data = np.random.randint(24, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    \n",
    "    f_special = make_noisy_amplitude_function(amplitude)(dow_data, hod_data)\n",
    "\n",
    "    f_total = f_data + f_special\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'dow': dow_data, 'hod': hod_data, 'f_orig': f_data, 'p': f_perf, 'special': f_special, 'f': f_total})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>f</th>\n",
       "      <th>f_orig</th>\n",
       "      <th>hod</th>\n",
       "      <th>p</th>\n",
       "      <th>special</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-5.438986</td>\n",
       "      <td>-5.438986</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.072517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.183182</td>\n",
       "      <td>-1.587695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-8.573155</td>\n",
       "      <td>-8.573155</td>\n",
       "      <td>18</td>\n",
       "      <td>-6.669537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.662500</td>\n",
       "      <td>-2.310926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.354436</td>\n",
       "      <td>3.354436</td>\n",
       "      <td>22</td>\n",
       "      <td>1.334109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587232</td>\n",
       "      <td>-1.319291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.819795</td>\n",
       "      <td>0.819795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.561460</td>\n",
       "      <td>4.827699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-12.394006</td>\n",
       "      <td>-12.394006</td>\n",
       "      <td>19</td>\n",
       "      <td>-10.756785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.947351</td>\n",
       "      <td>0.724163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-2.194510</td>\n",
       "      <td>-2.194510</td>\n",
       "      <td>16</td>\n",
       "      <td>-2.826211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>4.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>-10.157694</td>\n",
       "      <td>-10.157694</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.732057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.107665</td>\n",
       "      <td>4.033455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>-5.765204</td>\n",
       "      <td>-5.765204</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.202595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.625521</td>\n",
       "      <td>4.903107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.357639</td>\n",
       "      <td>-1.357639</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.584667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.091044</td>\n",
       "      <td>1.805158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>-6.865816</td>\n",
       "      <td>-6.865816</td>\n",
       "      <td>23</td>\n",
       "      <td>-6.783451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.167957</td>\n",
       "      <td>-4.104927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>6.931493</td>\n",
       "      <td>6.931493</td>\n",
       "      <td>19</td>\n",
       "      <td>6.523072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.859760</td>\n",
       "      <td>1.392896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.100439</td>\n",
       "      <td>-1.100439</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.439633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.792625</td>\n",
       "      <td>-3.291232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.903022</td>\n",
       "      <td>-0.903022</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.707494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932799</td>\n",
       "      <td>4.146185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>-7.313240</td>\n",
       "      <td>-7.313240</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.904042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.491990</td>\n",
       "      <td>0.840123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>5.995719</td>\n",
       "      <td>5.995719</td>\n",
       "      <td>4</td>\n",
       "      <td>4.983093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.921991</td>\n",
       "      <td>4.721778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>10.812940</td>\n",
       "      <td>10.812940</td>\n",
       "      <td>7</td>\n",
       "      <td>10.275746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.546798</td>\n",
       "      <td>-3.364302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.602179</td>\n",
       "      <td>-1.602179</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.554103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.461442</td>\n",
       "      <td>-1.737560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>7.950026</td>\n",
       "      <td>7.950026</td>\n",
       "      <td>10</td>\n",
       "      <td>6.803403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.202276</td>\n",
       "      <td>-1.797702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>-3.102325</td>\n",
       "      <td>-3.102325</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.510480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.602043</td>\n",
       "      <td>-2.387214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.063682</td>\n",
       "      <td>0.063682</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.078016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.020412</td>\n",
       "      <td>1.074382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dow          f     f_orig  hod          p  special         x         y\n",
       "0     3  -5.438986  -5.438986   10  -6.072517      0.0 -3.183182 -1.587695\n",
       "1     3  -8.573155  -8.573155   18  -6.669537      0.0 -3.662500 -2.310926\n",
       "2     2   3.354436   3.354436   22   1.334109      0.0  0.587232 -1.319291\n",
       "3     1   0.819795   0.819795    0   0.209070      0.0  1.561460  4.827699\n",
       "4     4 -12.394006 -12.394006   19 -10.756785      0.0 -4.947351  0.724163\n",
       "5     6  -2.194510  -2.194510   16  -2.826211      0.0  0.059894  4.892000\n",
       "6     3 -10.157694 -10.157694    1  -8.732057      0.0 -3.107665  4.033455\n",
       "7     6  -5.765204  -5.765204    3  -6.202595      0.0 -1.625521  4.903107\n",
       "8     0  -1.357639  -1.357639    3  -1.584667      0.0 -0.091044  1.805158\n",
       "9     3  -6.865816  -6.865816   23  -6.783451      0.0 -4.167957 -4.104927\n",
       "10    4   6.931493   6.931493   19   6.523072      0.0  3.859760  1.392896\n",
       "11    0  -1.100439  -1.100439    5  -0.439633      0.0 -0.792625 -3.291232\n",
       "12    1  -0.903022  -0.903022    3  -0.707494      0.0  0.932799  4.146185\n",
       "13    2  -7.313240  -7.313240    9  -5.904042      0.0 -2.491990  0.840123\n",
       "14    0   5.995719   5.995719    4   4.983093      0.0  3.921991  4.721778\n",
       "15    1  10.812940  10.812940    7  10.275746      0.0  4.546798 -3.364302\n",
       "16    2  -1.602179  -1.602179   11  -0.554103      0.0 -0.461442 -1.737560\n",
       "17    4   7.950026   7.950026   10   6.803403      0.0  3.202276 -1.797702\n",
       "18    4  -3.102325  -3.102325    4  -2.510480      0.0 -1.602043 -2.387214\n",
       "19    1   0.063682   0.063682    2  -3.078016      0.0 -1.020412  1.074382"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v2 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "df_train_v2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create a data set suitable for training\n",
    "In the following, our assumption that it is particular hours on particular days makes this problem a candidate for the categorical features 'hour of day' and 'day of week'. Hence, in a first step, let's take those two features into account. For that, we have to one-hot encode those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinals = list(df_train_v2['dow'])\n",
    "one_hot_dows = np.transpose(np.eye(7)[ordinals])\n",
    "one_hot_dows[:7,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = list(df_train_v2['hod'])\n",
    "one_hot_hods = np.transpose(np.eye(24)[ordinals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (2, 20000) + (7, 20000) + (24, 20000) = (33, 20000)\n"
     ]
    }
   ],
   "source": [
    "input_numerical = [list(df_train_v2['x']), list(df_train_v2['y'])]\n",
    "lbls_data = [list(df_train_v2['f'])]\n",
    "input_data = np.append(input_numerical, one_hot_dows, axis=0)\n",
    "input_data = np.append(input_data, one_hot_hods, axis=0)\n",
    "print(\"shapes: {} + {} + {} = {}\".format(np.shape(input_numerical), np.shape(one_hot_dows), np.shape(one_hot_hods), np.shape(input_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 33 columns, 31 of which only sparsely populated. That's ok for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.18318233, -3.66249989,  0.58723175,  1.56146003],\n",
       "       [-1.58769466, -2.31092587, -1.31929101,  4.82769942],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 1.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hereafter, we'll use create_input_data from the tools file to achieve just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_input_data(df, select_feats=[], oh_feats={}, cross_feats=[]):    \n",
      "    \"\"\"\n",
      "    create a list of input columns from pandas raw data\n",
      "    df: a pandas dataframe containing raw input data\n",
      "    select_feats: an array containing the names of features to be selected without transformation\n",
      "    oh_feats: a dictionary containing the names and sizes of discrete numerical features that are to be one-hot encoded\n",
      "    cross_feats: a list of oh_feats consisting of two discrete features to cross\n",
      "    \"\"\"\n",
      "\n",
      "    def _safe_append(l, r):\n",
      "        if l == [] or l is None:\n",
      "            return r\n",
      "        else:\n",
      "            return np.append(l, r, axis=0)\n",
      "\n",
      "    res = [list(df[n]) for n in select_feats]\n",
      "    \n",
      "    for k in oh_feats:\n",
      "        res = _safe_append(res, one_hot(df[k], oh_feats[k]))\n",
      "\n",
      "    for c in cross_feats:\n",
      "        keys = list(c.keys())\n",
      "        keys.sort()\n",
      "        \n",
      "        lk, ls = keys[0], c[keys[0]]\n",
      "        rk, rs = keys[1], c[keys[1]]\n",
      "        lhs = one_hot(df[lk], ls)\n",
      "        rhs = one_hot(df[rk], rs)\n",
      "        cross = [(lhs[:,i].reshape(ls,1) * rhs[:,i].reshape(1,rs)).reshape(rs*ls) for i in range(len(df))]\n",
      "        cross = np.transpose(cross)\n",
      "        res = _safe_append(res, cross)\n",
      "\n",
      "    return res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(create_input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create the network and start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use once more our self-made linear regressor. Below is the code that we hade previously, only this time augmented by the 24 + 7 new input features from the categorical columns. Observe that we train a long time with a lot more data, and the training loss still doesn't improve much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_DIM = 2 # namely x and y\n",
    "WEEKDAY_DIM = 7 # obviously\n",
    "HOUR_OF_DAY_DIM = 24\n",
    "X_DIM = NUMERICAL_DIM + WEEKDAY_DIM + HOUR_OF_DAY_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 8.20839881897"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.208399"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear2 = Linear(X_DIM, .01)\n",
    "linear2.train(sess, input_data, lbls_data, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That loss is significantly larger than the one that we experienced in the simple case. So either the signal/noise ratio is worse (we know it isn't) or there's some signal in the data that we don't recognize yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sometimes the distribution of the prediction errors reveals additional facts of the problems that our network has. Usually we'll need large enough samples to allow for sufficient statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predicted</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.284052</td>\n",
       "      <td>7.248983</td>\n",
       "      <td>6.244270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022941</td>\n",
       "      <td>1.014816</td>\n",
       "      <td>2.960186</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.772774</td>\n",
       "      <td>-7.641151</td>\n",
       "      <td>-8.711981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063213</td>\n",
       "      <td>-0.878304</td>\n",
       "      <td>-1.845098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.228664</td>\n",
       "      <td>1.077320</td>\n",
       "      <td>1.270840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.367347</td>\n",
       "      <td>-1.458664</td>\n",
       "      <td>-2.466586</td>\n",
       "      <td>10.080529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-9.274298</td>\n",
       "      <td>-7.929399</td>\n",
       "      <td>-8.986940</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.766864</td>\n",
       "      <td>0.518837</td>\n",
       "      <td>3.732916</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.533575</td>\n",
       "      <td>8.647478</td>\n",
       "      <td>11.873520</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.337770</td>\n",
       "      <td>-6.444223</td>\n",
       "      <td>-7.483815</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f         p  predicted    special\n",
       "0  6.284052  7.248983   6.244270   0.000000\n",
       "1  1.022941  1.014816   2.960186   0.000000\n",
       "2 -9.772774 -7.641151  -8.711981   0.000000\n",
       "3  0.063213 -0.878304  -1.845098   0.000000\n",
       "4  1.228664  1.077320   1.270840   0.000000\n",
       "5  7.367347 -1.458664  -2.466586  10.080529\n",
       "6 -9.274298 -7.929399  -8.986940   0.000000\n",
       "7 -0.766864  0.518837   3.732916   0.000000\n",
       "8  6.533575  8.647478  11.873520   0.000000\n",
       "9 -5.337770 -6.444223  -7.483815   0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_v2 = create_data_frame_v2(size = 20000, amplitude=10)\n",
    "test_data = create_input_data(df=df_test_v2, select_feats=['x','y'], oh_feats={'dow': 7, 'hod': 24})\n",
    "\n",
    "pred = linear2.predict(x_data=test_data, sess=sess)\n",
    "df_test_v2['predicted'] = pred[0]\n",
    "df_test_v2[['f', 'p', 'predicted', 'special']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test_v2['predicted'] - df_test_v2['f']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the error distribution that there's some really interesting stuff going on. This is almost certainly a hint that our data contains structure that we didn't discover yet. This distribution is telling: For the majority of the data - the large bump - we have a tendency to over-predict. For some minority though we significantly under-predict. This is a typical sign that the linear regression is finding a weak compromise between two distinct and somehow unrelated distributions that make up our total input data.\n",
    "\n",
    "Obviously, although or network actually had all the information it needed, simply adding the categorical features didn't allow it to learn the specific characteristic, namely the \"and\" relationship like in: \"The humidity is higher, when it's Wednesday *and* it's 18:00h\". \n",
    "\n",
    "Feature crossings and embeddings to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example: This is Wednesday, 08:00h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday = np.array([[0,0,1,0,0,0,0]])\n",
    "at_0800 = np.zeros((1,24))\n",
    "at_0800[0,8] = 1\n",
    "wednesday, at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossing categorical features $a$ and $b$ means: Put a 1 only where both $a$ and $b$ have a one. Put zeros anywhere else. Python broadcasting helps us achieve that with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday_at_0800 = wednesday.T * at_0800\n",
    "wednesday_at_0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = np.reshape(wednesday_at_0800, newshape=(1,-1))\n",
    "np.argmax(cross) == 2 * 24 + 8 # Wed * 24 + at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets a little more involved when dealing with a batch of feature pairs as you can see in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dows = np.array([[0,0,1,0,0,0,0],[0,0,0,0,0,1,0]])\n",
    "hods = np.zeros((2,24))\n",
    "hods[0,8] = 1\n",
    "hods[1,16] = 1\n",
    "dows, hods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(dows[i].reshape(7,1) * hods[i].reshape(1,24)).reshape(168) for i in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now, instead of feeding both features independently we feed the feature cross into our linear regression model. Note that we need a lot of data to have sufficient statistics for each hour of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 20000), 20000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_RECORDS = 20000\n",
    "\n",
    "df_train_v3 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "input_data_v3 = create_input_data(df=df_train_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "lbls_data_v3 = [list(df_train_v3['f'])]\n",
    "input_data_v3.shape, len(lbls_data_v3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.09489989281"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0949"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_v3 = Linear(lr=.05, x_dim=170)\n",
    "regressor_v3.train(sess=sess, num_steps=4000, x_data=input_data_v3, labels_data=lbls_data_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can see that the loss function has indeed gone down dramatically. Now let's examine the error statistics on some fresh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_v3 = create_data_frame_v2(size = 20000, amplitude=10.0)\n",
    "input_data_test_v3 = create_input_data(df=df_test_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "preds = regressor_v3.predict(sess=sess, x_data=input_data_test_v3)\n",
    "\n",
    "errors = preds[0] - df_test_v3['f']\n",
    "df_test_v3['preds'] = preds[0]\n",
    "df_test_v3['err'] = errors\n",
    "df_test_v3['err'].plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, there's some subtle asymmetry in the error distribution, depending on how long you trained, but we can see that the characteristic second bump has disappeared. When we look at the weights associated with the 168 different hours of a week, we spot a few larger positive values amongst otherwise smaller negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.78268397, -0.97158486, -1.059289  , -1.0374155 , -0.9097017 ,\n",
       "       -1.1046445 , -0.80199677, -1.1526093 , -0.8890181 , -0.7986392 ,\n",
       "       -1.1270332 , -1.0862069 , -1.0329483 , -0.9682627 , -0.99010205,\n",
       "       -1.0400494 , -0.84793365, -0.8335291 ,  8.303333  ,  8.314928  ,\n",
       "        7.972943  ,  7.967135  , -0.98674995, -0.92116404, -0.6516055 ,\n",
       "       -0.8902612 , -1.018739  , -1.07226   , -0.97972333, -0.98706883,\n",
       "       -0.9965006 , -1.0691361 , -1.076108  , -1.1086419 , -0.7654904 ,\n",
       "       -1.0164598 , -0.7948248 , -0.8060174 , -0.97434205, -0.7883136 ,\n",
       "       -0.8836284 , -1.0609919 ,  8.445197  ,  8.205121  ,  8.245153  ,\n",
       "        7.9685793 , -1.1414807 , -0.92419404, -0.7838536 , -1.1716707 ,\n",
       "       -1.0317333 , -0.84845936, -0.9545352 , -1.1193985 , -0.8947975 ,\n",
       "       -0.734755  , -0.6783842 , -0.84594554, -0.9542126 , -1.0235251 ,\n",
       "       -1.0044669 , -1.0384227 , -0.9062452 , -1.0035944 , -1.1596124 ,\n",
       "       -0.96748614,  8.34185   ,  8.18994   ,  8.125217  ,  8.212111  ,\n",
       "       -0.871314  , -0.9715076 , -0.83602947, -0.90378726, -0.8234728 ,\n",
       "       -1.0293902 , -0.85955507, -1.1530949 , -0.98839056, -0.926914  ,\n",
       "       -0.93960685, -0.69379574, -0.67014426, -0.89102215, -1.0881262 ,\n",
       "       -1.1520505 , -0.9547343 , -0.9895657 , -1.0266176 , -1.0488424 ,\n",
       "       -1.0905898 , -0.78963697, -0.9537744 , -0.9370164 , -1.0678507 ,\n",
       "       -1.005112  , -0.96027136, -0.91990775, -1.0953034 , -1.0142189 ,\n",
       "       -1.012086  , -0.90190554, -1.0436845 , -0.83888006, -0.9171898 ,\n",
       "       -0.9025331 , -1.0758044 , -1.2254602 , -0.9353612 , -1.0708194 ,\n",
       "        8.225329  ,  8.384919  ,  7.840224  , -0.78198874, -0.8646602 ,\n",
       "       -1.1532037 , -0.84240335, -1.0687871 , -1.0350966 , -0.92408484,\n",
       "       -0.9271751 , -1.0180261 , -0.97209054, -0.9795788 , -1.0275042 ,\n",
       "       -0.81331515, -1.0354354 , -1.0882461 , -1.035299  , -1.0285038 ,\n",
       "       -1.0420035 , -1.0874752 , -0.77414733, -0.90069395,  7.995283  ,\n",
       "        7.70957   ,  7.7597866 , -1.0358491 , -0.9573706 , -0.929968  ,\n",
       "       -1.027679  , -1.1485753 , -0.8164797 , -1.0581357 , -0.9843266 ,\n",
       "       -0.88079804, -1.1506574 , -1.1170285 , -1.0922223 , -0.9879111 ,\n",
       "       -0.91707957, -1.2270048 , -1.1132035 , -1.0771002 , -0.8861448 ,\n",
       "       -0.8599957 , -1.0344722 , -0.93436885, -1.1130667 , -0.99291646,\n",
       "       -1.1560624 , -1.1359739 , -0.8619624 , -0.9879277 , -1.106349  ,\n",
       "       -0.82167435, -1.0795149 , -0.7044634 ], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = regressor_v3.M.eval()\n",
    "weights_t = weights.squeeze()[2:]\n",
    "weights_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes of the larger values allow us to discover exactly those hours of week during which the dry-cleaner anomalies are observed. The network truly learned when these anomalies are typically observed and adds some more humidity in its prediction during those times of the week. Ain't that cool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 18), array([ 0, 18])),\n",
       " ((0, 19), array([ 0, 19])),\n",
       " ((0, 20), array([ 0, 20])),\n",
       " ((0, 21), array([ 0, 21])),\n",
       " ((1, 18), array([ 1, 18])),\n",
       " ((1, 19), array([ 1, 19])),\n",
       " ((1, 20), array([ 1, 20])),\n",
       " ((1, 21), array([ 1, 21])),\n",
       " ((2, 18), array([ 2, 18])),\n",
       " ((2, 19), array([ 2, 19])),\n",
       " ((2, 20), array([ 2, 20])),\n",
       " ((2, 21), array([ 2, 21])),\n",
       " ((4, 14), array([ 4, 14])),\n",
       " ((4, 15), array([ 4, 15])),\n",
       " ((4, 16), array([ 4, 16])),\n",
       " ((5, 14), array([ 5, 14])),\n",
       " ((5, 15), array([ 5, 15])),\n",
       " ((5, 16), array([ 5, 16]))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [i for i in range(168) if weights_t[i] > 1]\n",
    "how_detected = [(i // 24, i % 24 ) for i in indexes]\n",
    "how_detected = sorted(how_detected, key=lambda d: d[0])\n",
    "list(zip(how_detected, conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the left, the hours of the week as detected by the network, to the left the conditions that lead to the anomalies in the data. A perfect fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with an embedded feature\n",
    "\n",
    "The dimensions: 2 linear, 168 categories - embedded into $R^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIN_DIM = 2\n",
    "CAT_DIM = 168\n",
    "EMB_DIM = 3\n",
    "lr = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights, including the embedding weights - and the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_emb = tf.Variable(tf.random_normal(shape=(EMB_DIM, CAT_DIM)))\n",
    "M = tf.Variable(tf.zeros(shape=(1, LIN_DIM + EMB_DIM)))\n",
    "b = tf.Variable(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The place holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = tf.placeholder(shape=(LIN_DIM, None), dtype=tf.float32)\n",
    "x_cat = tf.placeholder(shape=(CAT_DIM, None), dtype=tf.float32)\n",
    "lbls = tf.placeholder(shape=(1,None), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data: embed categorical sparse data and concatenate with linear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb = tf.matmul(M_emb, x_cat)\n",
    "x = tf.concat([x_lin, x_emb], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypothesis and the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tf.matmul(M, x) + b\n",
    "d = tf.losses.mean_squared_error(lbls, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients and the optimizers, now including the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "nM = tf.gradients(d, M)\n",
    "nb = tf.gradients(d, b)\n",
    "nMe = tf.gradients(d, M_emb)\n",
    "aM = tf.assign_add( M, tf.multiply(nM[0], -lr))\n",
    "ab = tf.assign_add( b, tf.multiply(nb[0], -lr))\n",
    "aMe = tf.assign_add( M_emb, tf.multiply(nMe[0], -lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_v3 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "input_data_v3 = create_input_data(df=df_train_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "lbls_data_v3 = [list(df_train_v3['f'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, please observe how fast the loss converges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.01035094261"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    dist, _, _, _ = sess.run([d, aM, ab, aMe], \n",
    "                                   feed_dict = {\n",
    "                                       x_lin: input_data_v3[:2], \n",
    "                                       x_cat: input_data_v3[2:], \n",
    "                                       lbls: lbls_data_v3})\n",
    "    print_progress(\"- Loss: {}\", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now let's examine the error distribution on some test data once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v3 = create_data_frame_v2(size = 20000, amplitude=10.0)\n",
    "input_data_test_v3 = create_input_data(df=df_test_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sess.run(f, feed_dict={\n",
    "    x_lin: input_data_test_v3[:2], \n",
    "    x_cat: input_data_test_v3[2:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFThJREFUeJzt3X+w5XV93/HnS1BRo6zIumF22SzWDdY2outFcYypujUjaFzaJgQn0ZUy2TQhFqd2ZCVpk3bSGWytCGlKuxXtYkwoQQnbSGxW/NHpTAB3EUFBy4ZCdldgV6OgYiTou3+cz+Jh/e695+7e7z3nnn0+Zs6c7/dzPt/vfX9hz33fz4/v55uqQpKkgz1p3AFIkiaTCUKS1MkEIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSJxOEJKnTseMO4EiceOKJtWbNmnGHIUlLys6dO79WVcvnqrekE8SaNWvYsWPHuMOQpCUlyX2j1LOLSZLUyQQhSepkgpAkdTJBSJI6mSAkSZ16SxBJTk1y29Dr4STvSHJCku1J7m7vz271k+TyJLuS3J5kXV+xSZLm1luCqKqvVNWLq+rFwEuBR4DrgM3AjVW1Frix7QOcCaxtr03AFX3FJkma22J1Ma0H/rKq7gM2AFtb+Vbg7La9AbiqBm4CliU5aZHikyQdZLESxLnAH7XtFVV1f9t+AFjRtlcCu4eO2dPKniDJpiQ7kuzYv39/X/FK0lGv9zupkzwFeBPw7oM/q6pKUvM5X1VtAbYAzMzMzOtYadKs2fzxx7fvveQNY4xE+lGL0YI4E7i1qh5s+w8e6Dpq7/ta+V7g5KHjVrUySdIYLEaCeDM/7F4C2AZsbNsbgeuHyt/aZjOdATw01BUlSVpkvXYxJXkG8DrgV4eKLwGuSXI+cB9wTiu/ATgL2MVgxtN5fcYmSZpdrwmiqr4DPOegsq8zmNV0cN0CLugzHknS6LyTWpLUaUk/D0JaKpytpKXIFoQkqZMJQpLUyQQhSepkgpAkdXKQWlpkwwPW863vALcWkwlCWiD+Ite0sYtJktTJBCFJ6mQXkzSB5jtOIfXBBCFNCJOCJo0JQuqBv+w1DRyDkCR1sgUhLSFOpdViMkFIS5TJQn2zi0mS1MkEIUnqZIKQJHUyQUiSOvWaIJIsS3Jtki8nuSvJK5KckGR7krvb+7Nb3SS5PMmuJLcnWddnbJKk2fXdgrgM+ERVvQA4DbgL2AzcWFVrgRvbPsCZwNr22gRc0XNskqRZ9DbNNcnxwM8AbwOoqkeBR5NsAF7dqm0FPgNcBGwArqqqAm5qrY+Tqur+vmKUjpR3TGua9XkfxCnAfuBDSU4DdgIXAiuGfuk/AKxo2yuB3UPH72llJghpHrw/Qgulzy6mY4F1wBVV9RLgO/ywOwmA1lqo+Zw0yaYkO5Ls2L9//4IFK0l6oj4TxB5gT1Xd3PavZZAwHkxyEkB739c+3wucPHT8qlb2BFW1papmqmpm+fLlvQUvSUe73hJEVT0A7E5yaitaD9wJbAM2trKNwPVtexvw1jab6QzgIccfJGl8+l6L6e3AR5I8BbgHOI9BUromyfnAfcA5re4NwFnALuCRVleSNCa9Joiqug2Y6fhofUfdAi7oMx5J0ui8k1qS1MkEIUnq5PMgpCngDXvqgy0ISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ28D0KaYj4bQkfCFoQkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUqdcEkeTeJHckuS3JjlZ2QpLtSe5u789u5UlyeZJdSW5Psq7P2CRJs1uMtZheU1VfG9rfDNxYVZck2dz2LwLOBNa218uBK9q7NHbT8Mxn12XSfI2ji2kDsLVtbwXOHiq/qgZuApYlOWkM8UmS6D9BFPDnSXYm2dTKVlTV/W37AWBF214J7B46dk8rkySNQd9dTD9dVXuTPBfYnuTLwx9WVSWp+ZywJZpNAKtXr164SCVJT9BrC6Kq9rb3fcB1wMuABw90HbX3fa36XuDkocNXtbKDz7mlqmaqamb58uV9hi9JR7XeWhBJngE8qaq+1bZ/Fvi3wDZgI3BJe7++HbIN+I0kVzMYnH5oqCtKWnTTMDAtHYk+u5hWANclOfBz/rCqPpHkc8A1Sc4H7gPOafVvAM4CdgGPAOf1GJskaQ69JYiqugc4raP868D6jvICLugrHknS/HgntSSpkwlCktTJBCFJ6mSCkCR1MkFIkjqZICRJnUwQkqROi7Hct6QJc6i7xF0GXMNsQUiSOtmCkIa4/pL0QyMliCQ/VVV39B2MNA4mBanbqF1M/znJLUl+PcnxvUYkSZoIIyWIqnoV8EsMntewM8kfJnldr5FJksZq5EHqqrob+C3gIuAfAJcn+XKSf9xXcJKk8RkpQSR5UZJLgbuA1wI/V1V/t21f2mN8kqQxGXUW0+8BHwAurqrvHiisqq8m+a1eIpMW2PBgtPP9pbmNmiDeAHy3qr4PkORJwHFV9UhVfbi36CRJYzPqGMQngacN7T+9lUmSptSoCeK4qvr2gZ22/fR+QpIkTYJRE8R3kqw7sJPkpcB3Z6kvSVriRh2DeAfwx0m+CgT4ceAXe4tK0li4iJ+GjZQgqupzSV4AnNqKvlJVfzvKsUmOAXYAe6vqjUlOAa4GngPsBN5SVY8meSpwFfBS4OvAL1bVvfO6GmlELq8hzW0+q7meDrwIWAe8OclbRzzuQgb3TxzwHuDSqno+8A3g/FZ+PvCNVn5pqydJGpNRb5T7MPBe4KcZJIrTgZkRjlvFYIrsB9p+GNxcd22rshU4u21vaPu0z9e3+pKkMRh1DGIGeGFV1TzP/37gXcAz2/5zgG9W1WNtfw+wsm2vBHYDVNVjSR5q9b82fMIkm4BNAKtXr55nOJKkUY3axfRFBgPTI0vyRmBfVe2cd1SzqKotVTVTVTPLly9fyFNLkoaM2oI4EbgzyS3A9w4UVtWbZjnmlcCbkpwFHAc8C7gMWJbk2NaKWAXsbfX3Mlgtdk+SY4HjGQxWS5LGYNQE8TvzPXFVvRt4N0CSVwP/sqp+KckfAz/PYCbTRuD6dsi2tv8X7fNPHUaXliRpgYw6zfWzSX4CWFtVn0zydOCYw/yZFwFXJ/ld4PPAla38SuDDSXYBfw2ce5jnlyQtgFEfOforDAaGTwD+DoMB5f8CrB/l+Kr6DPCZtn0P8LKOOn8D/MIo55Mk9W/UQeoLGIwpPAyPPzzouX0FJUkav1ETxPeq6tEDO20Q2fEBSZpiow5SfzbJxcDT2rOofx34n/2FJS0Ml9SQDt+oLYjNwH7gDuBXgRsYPJ9akjSlRp3F9APgv7WXJOkoMOospv9Hx5hDVT1vwSOSJE2E+azFdMBxDKajnrDw4UiSJsVIYxBV9fWh196qej+DVVolSVNq1C6mdUO7T2LQohi19SFJWoJG/SX/H4e2HwPuBc5Z8GgkSRNj1FlMr+k7EEnSZBm1i+lfzPZ5Vb1vYcKRJE2K+cxiOp3BktwAPwfcAtzdR1CSpPEbNUGsAtZV1bcAkvwO8PGq+uW+ApMkjdeoS22sAB4d2n+0lUmSptSoLYirgFuSXNf2zwa29hOSJGkSjDqL6d8l+TPgVa3ovKr6fH9hSYfPFVylhTFqFxPA04GHq+oyYE+SU3qKSZI0AUad5vrbDGYynQp8CHgy8AcMnjInacoNt8ruvcRVdo4Wo45B/CPgJcCtAFX11STP7C0qSRPLZHH0GLWL6dGqKtqS30meMdcBSY5LckuSLyT5UpJ/08pPSXJzkl1J/keSp7Typ7b9Xe3zNYd3SZKkhTBqgrgmyX8FliX5FeCTzP3woO8Br62q04AXA69PcgbwHuDSqno+8A3g/Fb/fOAbrfzSVk+SNCajLvf9XuBa4KMMxiH+dVX93hzHVFV9u+0+ub0KeG07Fwymyp7dtjfww6mz1wLrk2TE65AkLbA5xyCSHAN8si3Yt30+J2/H7gSeD/w+8JfAN6vqsVZlD7Cyba8EdgNU1WNJHgKeA3xtPj9TkrQw5kwQVfX9JD9IcnxVPTSfk1fV94EXJ1kGXAe84DDjfFySTcAmgNWrVx/p6TQlvPdBWnijzmL6NnBHku3Adw4UVtU/H+Xgqvpmkk8Dr2AwjnFsa0WsAva2anuBkxncY3EscDzw9Y5zbQG2AMzMzPzIc7IlSQtj1ATxsfYaWZLlwN+25PA04HUMBp4/Dfw8cDWwEbi+HbKt7f9F+/xTbeaUJGkMZk0QSVZX1V9V1eGsu3QSsLWNQzwJuKaq/jTJncDVSX4X+DxwZat/JfDhJLuAvwbOPYyfKUlaIHO1IP4EWAeQ5KNV9U9GPXFV3c7g5rqDy+8BXtZR/jfAL4x6fklSv+aa5jo8zfR5fQYiSZoscyWIOsS2JGnKzdXFdFqShxm0JJ7Wtmn7VVXP6jU6aRZObZX6NWuCqKpjFisQSdJkmc/zICRJRxEThCSp06g3yknSj/DZENPNFoQkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTt4HIWlBeE/E9LEFIUnqZAtC0oKzNTEdbEFIkjqZICRJnUwQkqROjkFoSfEpctLi6a0FkeTkJJ9OcmeSLyW5sJWfkGR7krvb+7NbeZJcnmRXktuTrOsrNknS3PpsQTwGvLOqbk3yTGBnku3A24Abq+qSJJuBzcBFwJnA2vZ6OXBFe5e0hDmjaenqrQVRVfdX1a1t+1vAXcBKYAOwtVXbCpzdtjcAV9XATcCyJCf1FZ8kaXaLMkidZA3wEuBmYEVV3d8+egBY0bZXAruHDtvTyiRJY9B7gkjyY8BHgXdU1cPDn1VVATXP821KsiPJjv379y9gpJKkYb3OYkryZAbJ4SNV9bFW/GCSk6rq/taFtK+V7wVOHjp8VSt7gqraAmwBmJmZmVdy0dLkzCVpPPqcxRTgSuCuqnrf0EfbgI1teyNw/VD5W9tspjOAh4a6oiRJi6zPFsQrgbcAdyS5rZVdDFwCXJPkfOA+4Jz22Q3AWcAu4BHgvB5jkyTNobcEUVX/B8ghPl7fUb+AC/qKR5I0Py61IUnqZIKQJHUyQUiSOpkgJEmdXM1V0qI5+J4W12aabCYITQwXdZMmi11MkqROJghJUicThCSpk2MQksbGcafJZgtCktTJFoSkiWBrYvKYIDSRfAaENH4mCC06f/lLS4NjEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdXKaq6SJ401zk6G3FkSSDybZl+SLQ2UnJNme5O72/uxWniSXJ9mV5PYk6/qKS5I0mj67mP478PqDyjYDN1bVWuDGtg9wJrC2vTYBV/QYl6QlZM3mjz/+0uLqrYupqv53kjUHFW8AXt22twKfAS5q5VdVVQE3JVmW5KSqur+v+LS4/HJLS89iD1KvGPql/wCwom2vBHYP1dvTyn5Ekk1JdiTZsX///v4ilaSj3NhmMbXWQh3GcVuqaqaqZpYvX95DZJIkWPxZTA8e6DpKchKwr5XvBU4eqreqlUnS45zdtLgWuwWxDdjYtjcC1w+Vv7XNZjoDeMjxB0kar95aEEn+iMGA9IlJ9gC/DVwCXJPkfOA+4JxW/QbgLGAX8AhwXl9xafE4MC0tbX3OYnrzIT5a31G3gAv6ikWSNH/eSa0FZatBmh6uxSRJ6mQLQtKS5Iym/tmCkCR1sgWhI+KYgzS9bEFIkjqZICRJnexikrTkOWDdD1sQkqROJghJUie7mHRIh2q2O3NJOjqYICRNFccjFo5dTJKkTrYgNBK7laSjjwlCT2Ai0DSxu+nImCAkHRVMFvNngpB01DFZjMYEcZTyCyJpLiYISUe1Q427+YeTCeKocqgvggPTkrpMVIJI8nrgMuAY4ANVdcmYQ5J0lLIbdoISRJJjgN8HXgfsAT6XZFtV3TneyJYe/2FLC2uUbqhp/N5NTIIAXgbsqqp7AJJcDWwApjpBzPcf1Xz7S+0+kvoz7d+vSUoQK4HdQ/t7gJePKZZejTIWMN/F8ab9H6q0lIzyfZztOz4pLZNJShAjSbIJ2NR2v53kKz3/yBOBr/X8M35E3tPbqcdyPT2ZpmuB6bqeaboW6OF6ZvuOH+qzBfq9cCLwE6NUnKQEsRc4eWh/VSt7gqraAmxZrKCS7KiqmcX6eX2bpuuZpmuB6bqeaboWmK7radeyZpS6k7Sa6+eAtUlOSfIU4Fxg25hjkqSj1sS0IKrqsSS/AfwvBtNcP1hVXxpzWJJ01JqYBAFQVTcAN4w7joMsWnfWIpmm65mma4Hpup5puhaYrusZ+VpSVX0GIklaoiZpDEKSNEFMECNK8vYkX07ypST/ftzxHKkk70xSSU4cdyxHIsl/aP9fbk9yXZJl445pvpK8PslXkuxKsnnc8RyJJCcn+XSSO9t35cJxx3SkkhyT5PNJ/nTcsRypJMuSXNu+M3clecVs9U0QI0jyGgZ3dZ9WVX8PeO+YQzoiSU4Gfhb4q3HHsgC2A3+/ql4E/F/g3WOOZ16Glpg5E3gh8OYkLxxvVEfkMeCdVfVC4AzggiV+PQAXAneNO4gFchnwiap6AXAac1yXCWI0vwZcUlXfA6iqfWOO50hdCrwLWPIDUFX151X1WNu9icH9M0vJ40vMVNWjwIElZpakqrq/qm5t299i8Ato5XijOnxJVgFvAD4w7liOVJLjgZ8BrgSoqker6puzHWOCGM1PAq9KcnOSzyY5fdwBHa4kG4C9VfWFccfSg38K/Nm4g5inriVmluwv1GFJ1gAvAW4ebyRH5P0M/pj6wbgDWQCnAPuBD7Uusw8kecZsB0zUNNdxSvJJ4Mc7PvpNBv+dTmDQZD4duCbJ82pCp4DNcS0XM+heWjJmu56qur7V+U0G3RsfWczY1C3JjwEfBd5RVQ+PO57DkeSNwL6q2pnk1eOOZwEcC6wD3l5VNye5DNgM/KvZDhBQVf/wUJ8l+TXgYy0h3JLkBwzWM9m/WPHNx6GuJclPMfgr4gtJYNAdc2uSl1XVA4sY4rzM9v8GIMnbgDcC6yc1ac9ipCVmlpIkT2aQHD5SVR8bdzxH4JXAm5KcBRwHPCvJH1TVL485rsO1B9hTVQdadNcySBCHZBfTaP4EeA1Akp8EnsISXIisqu6oqudW1Zq2FsseYN0kJ4e5tIdMvQt4U1U9Mu54DsNULTGTwV8eVwJ3VdX7xh3Pkaiqd1fVqvZdORf41BJODrTv+e4kp7ai9czxOAVbEKP5IPDBJF8EHgU2LsG/VKfVfwKeCmxvraKbquqfjTek0U3hEjOvBN4C3JHktlZ2cVslQeP3duAj7Y+Re4DzZqvsndSSpE52MUmSOpkgJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHX6/54BNNd9sCuvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = preds[0] - df_test_v3['f']\n",
    "df_test_v3['preds'] = preds[0]\n",
    "df_test_v3['err'] = errors\n",
    "df_test_v3['err'].plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now let's look at the embedded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = sess.run([x_emb], feed_dict={x_cat: input_data_test_v3[2:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_pd = pd.DataFrame(np.transpose(embs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs_pd[0].plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the values form two distinct clusters in the embedding space. We suspect that the smaller cluster to the left is made of those dry-cleaner's peek hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 18], [0, 19], [0, 20], [0, 21], [1, 18], [1, 19], [1, 20], [1, 21], [2, 18], [2, 19], [2, 20], [2, 21], [4, 14], [4, 15], [4, 16], [5, 14], [5, 15], [5, 16]]\n"
     ]
    }
   ],
   "source": [
    "print(conditions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
