{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = ['1','3','4','6','8','5','2','7']\n",
    "arr2 = [1,3,4,6,8,5,2,7]\n",
    "arr = zip(arr1,arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "arr.sort(key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 1),\n",
       " ('2', 2),\n",
       " ('3', 3),\n",
       " ('4', 4),\n",
       " ('5', 5),\n",
       " ('6', 6),\n",
       " ('7', 7),\n",
       " ('8', 8)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'compare_to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f553b393bf9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"A\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'compare_to'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a': 1}\n",
    "d.update({'b': 2})\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_random_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_summary_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_checkpoints_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mobject\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f24debf3130\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_checkpoints_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mobject\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f24debf3130\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_checkpoint_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_step_count_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_distribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_distribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_distribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      This class specifies the configurations for an `Estimator` run.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Constructs a RunConfig.\n",
       "\n",
       "All distributed training related properties `cluster_spec`, `is_chief`,\n",
       "`master` , `num_worker_replicas`, `num_ps_replicas`, `task_id`, and\n",
       "`task_type` are set based on the `TF_CONFIG` environment variable, if the\n",
       "pertinent information is present. The `TF_CONFIG` environment variable is a\n",
       "JSON object with attributes: `cluster` and `task`.\n",
       "\n",
       "`cluster` is a JSON serialized version of `ClusterSpec`'s Python dict from\n",
       "`server_lib.py`, mapping task types (usually one of the `TaskType` enums) to\n",
       "a list of task addresses.\n",
       "\n",
       "`task` has two attributes: `type` and `index`, where `type` can be any of\n",
       "the task types in `cluster`. When `TF_CONFIG` contains said information,\n",
       "the following properties are set on this class:\n",
       "\n",
       "* `cluster_spec` is parsed from `TF_CONFIG['cluster']`. Defaults to {}. If\n",
       "  present, must have one and only one node in the `chief` attribute of\n",
       "  `cluster_spec`.\n",
       "* `task_type` is set to `TF_CONFIG['task']['type']`. Must set if\n",
       "  `cluster_spec` is present; must be `worker` (the default value) if\n",
       "  `cluster_spec` is not set.\n",
       "* `task_id` is set to `TF_CONFIG['task']['index']`. Must set if\n",
       "  `cluster_spec` is present; must be 0 (the default value) if\n",
       "  `cluster_spec` is not set.\n",
       "* `master` is determined by looking up `task_type` and `task_id` in the\n",
       "  `cluster_spec`. Defaults to ''.\n",
       "* `num_ps_replicas` is set by counting the number of nodes listed\n",
       "  in the `ps` attribute of `cluster_spec`. Defaults to 0.\n",
       "* `num_worker_replicas` is set by counting the number of nodes listed\n",
       "  in the `worker` and `chief` attributes of `cluster_spec`. Defaults to 1.\n",
       "* `is_chief` is determined based on `task_type` and `cluster`.\n",
       "\n",
       "There is a special node with `task_type` as `evaluator`, which is not part\n",
       "of the (training) `cluster_spec`. It handles the distributed evaluation job.\n",
       "\n",
       "Example of non-chief node:\n",
       "```\n",
       "  cluster = {'chief': ['host0:2222'],\n",
       "             'ps': ['host1:2222', 'host2:2222'],\n",
       "             'worker': ['host3:2222', 'host4:2222', 'host5:2222']}\n",
       "  os.environ['TF_CONFIG'] = json.dumps(\n",
       "      {'cluster': cluster,\n",
       "       'task': {'type': 'worker', 'index': 1}})\n",
       "  config = RunConfig()\n",
       "  assert config.master == 'host4:2222'\n",
       "  assert config.task_id == 1\n",
       "  assert config.num_ps_replicas == 2\n",
       "  assert config.num_worker_replicas == 4\n",
       "  assert config.cluster_spec == server_lib.ClusterSpec(cluster)\n",
       "  assert config.task_type == 'worker'\n",
       "  assert not config.is_chief\n",
       "```\n",
       "\n",
       "Example of chief node:\n",
       "```\n",
       "  cluster = {'chief': ['host0:2222'],\n",
       "             'ps': ['host1:2222', 'host2:2222'],\n",
       "             'worker': ['host3:2222', 'host4:2222', 'host5:2222']}\n",
       "  os.environ['TF_CONFIG'] = json.dumps(\n",
       "      {'cluster': cluster,\n",
       "       'task': {'type': 'chief', 'index': 0}})\n",
       "  config = RunConfig()\n",
       "  assert config.master == 'host0:2222'\n",
       "  assert config.task_id == 0\n",
       "  assert config.num_ps_replicas == 2\n",
       "  assert config.num_worker_replicas == 4\n",
       "  assert config.cluster_spec == server_lib.ClusterSpec(cluster)\n",
       "  assert config.task_type == 'chief'\n",
       "  assert config.is_chief\n",
       "```\n",
       "\n",
       "Example of evaluator node (evaluator is not part of training cluster):\n",
       "```\n",
       "  cluster = {'chief': ['host0:2222'],\n",
       "             'ps': ['host1:2222', 'host2:2222'],\n",
       "             'worker': ['host3:2222', 'host4:2222', 'host5:2222']}\n",
       "  os.environ['TF_CONFIG'] = json.dumps(\n",
       "      {'cluster': cluster,\n",
       "       'task': {'type': 'evaluator', 'index': 0}})\n",
       "  config = RunConfig()\n",
       "  assert config.master == ''\n",
       "  assert config.evaluator_master == ''\n",
       "  assert config.task_id == 0\n",
       "  assert config.num_ps_replicas == 0\n",
       "  assert config.num_worker_replicas == 0\n",
       "  assert config.cluster_spec == {}\n",
       "  assert config.task_type == 'evaluator'\n",
       "  assert not config.is_chief\n",
       "```\n",
       "\n",
       "N.B.: If `save_checkpoints_steps` or `save_checkpoints_secs` is set,\n",
       "`keep_checkpoint_max` might need to be adjusted accordingly, especially in\n",
       "distributed training. For example, setting `save_checkpoints_secs` as 60\n",
       "without adjusting `keep_checkpoint_max` (defaults to 5) leads to situation\n",
       "that checkpoint would be garbage collected after 5 minutes. In distributed\n",
       "training, the evaluation job starts asynchronously and might fail to load or\n",
       "find the checkpoint due to race condition.\n",
       "\n",
       "Args:\n",
       "  model_dir: directory where model parameters, graph, etc are saved. If\n",
       "    `PathLike` object, the path will be resolved. If `None`, will use a\n",
       "    default value set by the Estimator.\n",
       "  tf_random_seed: Random seed for TensorFlow initializers.\n",
       "    Setting this value allows consistency between reruns.\n",
       "  save_summary_steps: Save summaries every this many steps.\n",
       "  save_checkpoints_steps: Save checkpoints every this many steps. Can not be\n",
       "      specified with `save_checkpoints_secs`.\n",
       "  save_checkpoints_secs: Save checkpoints every this many seconds. Can not\n",
       "      be specified with `save_checkpoints_steps`. Defaults to 600 seconds if\n",
       "      both `save_checkpoints_steps` and `save_checkpoints_secs` are not set\n",
       "      in constructor.  If both `save_checkpoints_steps` and\n",
       "      `save_checkpoints_secs` are None, then checkpoints are disabled.\n",
       "  session_config: a ConfigProto used to set session parameters, or None.\n",
       "  keep_checkpoint_max: The maximum number of recent checkpoint files to\n",
       "    keep. As new files are created, older files are deleted. If None or 0,\n",
       "    all checkpoint files are kept. Defaults to 5 (that is, the 5 most recent\n",
       "    checkpoint files are kept.)\n",
       "  keep_checkpoint_every_n_hours: Number of hours between each checkpoint\n",
       "    to be saved. The default value of 10,000 hours effectively disables\n",
       "    the feature.\n",
       "  log_step_count_steps: The frequency, in number of global steps, that the\n",
       "    global step/sec and the loss will be logged during training.\n",
       "  train_distribute: An optional instance of\n",
       "    `tf.contrib.distribute.DistributionStrategy`. If specified,\n",
       "    then Estimator will distribute the user's model during training,\n",
       "    according to the policy specified by that strategy. Setting\n",
       "    `experimental_distribute.train_distribute` is preferred.\n",
       "  device_fn: A callable invoked for every `Operation` that takes the\n",
       "    `Operation` and returns the device string. If `None`, defaults to\n",
       "    the device function returned by `tf.train.replica_device_setter`\n",
       "    with round-robin strategy.\n",
       "  protocol: An optional argument which specifies the protocol used when\n",
       "    starting server. None means default to grpc.\n",
       "  eval_distribute: An optional instance of\n",
       "    `tf.contrib.distribute.DistributionStrategy`. If specified,\n",
       "    then Estimator will distribute the user's model during evaluation,\n",
       "    according to the policy specified by that strategy. Setting\n",
       "    `experimental_distribute.eval_distribute` is preferred.\n",
       "  experimental_distribute: an optional\n",
       "    `tf.contrib.distribute.DistributeConfig` object specifying\n",
       "    DistributionStrategy-related configuration. The `train_distribute` and\n",
       "    `eval_distribute` can be passed as parameters to `RunConfig` or set in\n",
       "    `experimental_distribute` but not both.\n",
       "\n",
       "Raises:\n",
       "  ValueError: If both `save_checkpoints_steps` and `save_checkpoints_secs`\n",
       "  are set.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/py2/local/lib/python2.7/site-packages/tensorflow/python/estimator/run_config.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.estimator.RunConfig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexporters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_delay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrottle_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Configuration for the \"eval\" part for the `train_and_evaluate` call.\n",
       "\n",
       "`EvalSpec` combines details of evaluation of the trained model as well as its\n",
       "export. Evaluation consists of computing metrics to judge the performance of\n",
       "the trained model.  Export writes out the trained model on to external\n",
       "storage.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/py2/local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.estimator.EvalSpec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_chief_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaffold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Ops and objects returned from a `model_fn` and passed to an `Estimator`.\n",
       "\n",
       "`EstimatorSpec` fully defines the model to be run by an `Estimator`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/py2/local/lib/python2.7/site-packages/tensorflow/python/estimator/model_fn.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.estimator.EstimatorSpec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a==None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
