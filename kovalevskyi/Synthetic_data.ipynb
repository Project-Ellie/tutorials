{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Models With Synthetic Data\n",
    "The advantage of synthetic data is that we know the prior or ground truth and we know exactly how concealed it is. That helps us to determine with certainty that an algorithm is per se capable of discovering the ground truth. If an algorithm fails on the easy task of learning from synthetic data, then it won't be good in real life. The opposite, unfortunately, is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "from tools import print_progress, array_in, create_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Noisy Samples From A Well-Known Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a*x+b\n",
    "def make_lin(a, b, rnd):\n",
    "    def _f_a(x):\n",
    "        mu = a*x + b\n",
    "        return rnd(mu)\n",
    "    return _f_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Two linear but noisy signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = make_lin(2, 1, lambda mu: np.random.normal(loc=mu, scale=1.0))\n",
    "f_b = make_lin(-.5, -1.5, lambda mu: np.random.normal(loc=mu, scale=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A look at one of the signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([f_a(1) for i in range(1000)])\n",
    "df.plot.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we create a data set/frame representing $f_a(x)+f_b(y)$ as a random variable that depends on random variables $x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v1(size):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'f': f_data, 'p': f_perf})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, this is equivalent to saying that the ground truth is:\n",
    "\n",
    "$$ f(x, y) = 2x - \\frac{1}{2} y - \\frac{1}{2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.058366</td>\n",
       "      <td>8.044171</td>\n",
       "      <td>4.515562</td>\n",
       "      <td>0.973908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.914317</td>\n",
       "      <td>-1.975468</td>\n",
       "      <td>-1.855730</td>\n",
       "      <td>-4.471983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.946856</td>\n",
       "      <td>-10.943174</td>\n",
       "      <td>-4.369122</td>\n",
       "      <td>3.409859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.875899</td>\n",
       "      <td>4.322476</td>\n",
       "      <td>2.837760</td>\n",
       "      <td>1.706086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.855388</td>\n",
       "      <td>3.238319</td>\n",
       "      <td>3.113317</td>\n",
       "      <td>4.976632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f          p         x         y\n",
       "0  8.058366   8.044171  4.515562  0.973908\n",
       "1 -1.914317  -1.975468 -1.855730 -4.471983\n",
       "2 -8.946856 -10.943174 -4.369122  3.409859\n",
       "3  2.875899   4.322476  2.837760  1.706086\n",
       "4  2.855388   3.238319  3.113317  4.976632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_data_frame_v1(NUM_RECORDS)\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Linear Regressor From Scratch With Tensorflow\n",
    "Let's train a self-made tensorflow linear regressor with the synthetic data to see whether it finds the coefficients above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Was already closed or didn't exist. That's fine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    print(\"OK. Was already closed or didn't exist. That's fine.\")\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating The Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, x_dim, lr):\n",
    "\n",
    "        # Variables for the parameters: weights M and bias b\n",
    "        self.M = tf.Variable(tf.zeros(shape=(1, x_dim)))\n",
    "        self.b = tf.Variable(0.)\n",
    "\n",
    "        # Placeholders for x and labels\n",
    "        self.x = tf.placeholder(shape=(x_dim,None), dtype=tf.float32)\n",
    "        self.lbls = tf.placeholder(shape=(1,None), dtype=tf.float32)\n",
    "\n",
    "        # The prediction and the distance (loss)\n",
    "        self.f = tf.matmul(self.M, self.x) + self.b\n",
    "        self.d = tf.losses.mean_squared_error(self.lbls, self.f)\n",
    "\n",
    "        # The gradients\n",
    "        self.nM = tf.gradients(self.d, self.M)\n",
    "        self.nb = tf.gradients(self.d, self.b)\n",
    "\n",
    "        # The optimizers\n",
    "        self.aM = tf.assign_add( self.M, tf.multiply(self.nM[0],-lr))\n",
    "        self.ab = tf.assign_add( self.b, tf.multiply(self.nb[0], -lr))\n",
    "\n",
    "        # The initializer\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def train(self, sess, x_data, labels_data, num_steps):        \n",
    "        sess.run(self.init)\n",
    "        for i in range(num_steps):\n",
    "            _, dist, _, _, _, _ = sess.run([self.f, self.d, self.nM, self.nb, self.aM, self.ab], \n",
    "                                           feed_dict = {self.x: x_data, self.lbls: labels_data})\n",
    "            print_progress(\"- Loss: {}\", dist)\n",
    "        return dist\n",
    "    \n",
    "    def predict(self, sess, x_data):\n",
    "        pred = sess.run(self.f, feed_dict={self.x: x_data})\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Perform The Training And Examine The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [list(df_train['x']), list(df_train['y'])]\n",
    "lbls_data = [list(df_train['f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.02404260635"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0240426"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = Linear(x_dim=2, lr=0.01)\n",
    "linear1.train(sess, input_data, lbls_data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the parameters to be close to $2, -0.5, -0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.0038278 , -0.49731547]], dtype=float32), -0.48622087]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([linear1.M, linear1.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now the tensor f represents the hypothesis. Let's evaluate it with some fresh test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = create_data_frame_v1(size=10000)\n",
    "test_data = [list(df_test['x']), list(df_test['y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear1.predict(sess=sess, x_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.265676</td>\n",
       "      <td>6.090455</td>\n",
       "      <td>3.891011</td>\n",
       "      <td>2.383133</td>\n",
       "      <td>6.125526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.353870</td>\n",
       "      <td>2.247488</td>\n",
       "      <td>2.589349</td>\n",
       "      <td>4.862419</td>\n",
       "      <td>2.284232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.655408</td>\n",
       "      <td>10.444847</td>\n",
       "      <td>4.818306</td>\n",
       "      <td>-2.616473</td>\n",
       "      <td>10.470045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.217691</td>\n",
       "      <td>8.367587</td>\n",
       "      <td>4.372981</td>\n",
       "      <td>-0.243249</td>\n",
       "      <td>8.397451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.197377</td>\n",
       "      <td>-8.724205</td>\n",
       "      <td>-4.837105</td>\n",
       "      <td>-2.900008</td>\n",
       "      <td>-8.736728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.540921</td>\n",
       "      <td>8.284001</td>\n",
       "      <td>4.020541</td>\n",
       "      <td>-1.485837</td>\n",
       "      <td>8.309180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-8.942902</td>\n",
       "      <td>-10.520889</td>\n",
       "      <td>-4.962240</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>-10.525587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.870993</td>\n",
       "      <td>-4.503606</td>\n",
       "      <td>-3.205553</td>\n",
       "      <td>-4.815000</td>\n",
       "      <td>-4.515023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.067645</td>\n",
       "      <td>8.864354</td>\n",
       "      <td>4.168805</td>\n",
       "      <td>-2.053489</td>\n",
       "      <td>8.888577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.752304</td>\n",
       "      <td>3.754524</td>\n",
       "      <td>1.780378</td>\n",
       "      <td>-1.387537</td>\n",
       "      <td>3.771393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions\n",
       "0   6.265676   6.090455  3.891011  2.383133     6.125526\n",
       "1   4.353870   2.247488  2.589349  4.862419     2.284232\n",
       "2  12.655408  10.444847  4.818306 -2.616473    10.470045\n",
       "3   6.217691   8.367587  4.372981 -0.243249     8.397451\n",
       "4  -8.197377  -8.724205 -4.837105 -2.900008    -8.736728\n",
       "5  10.540921   8.284001  4.020541 -1.485837     8.309180\n",
       "6  -8.942902 -10.520889 -4.962240  0.192817   -10.525587\n",
       "7  -4.870993  -4.503606 -3.205553 -4.815000    -4.515023\n",
       "8   9.067645   8.864354  4.168805 -2.053489     8.888577\n",
       "9   3.752304   3.754524  1.780378 -1.387537     3.771393"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'] = predictions[0]\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see without surprise that the predictions are typically closer to the ground truth than to the noisy signal. This means we have enough data to average out the noise and reveal the ground truth. A look at the distribution of the errors reveals pure noise around 0. That's typically a good sign that our network has understood the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test['f'] - df_test['predictions']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensorflow LinearRegressor Estimator\n",
    "Now we'll reproduce this with the high-level estimator API. Surprisingly, the calculations here take much longer than in the basic approach above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(df_train, shuffle=True, num_epochs=100, y=df_train['f'], batch_size=NUM_RECORDS)\n",
    "feature_columns = [\n",
    "    fc.numeric_column('x', dtype=tf.float32),\n",
    "    fc.numeric_column('y', dtype=tf.float32)\n",
    "]\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpUBttKI\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f708930a4d0>, '_model_dir': '/tmp/tmpUBttKI', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 5, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, config=config )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Perform the training on the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpUBttKI/model.ckpt.\n",
      "INFO:tensorflow:loss = 374425.2, step = 1\n",
      "INFO:tensorflow:global_step/sec: 19.6661\n",
      "INFO:tensorflow:loss = 183131.44, step = 6 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9548\n",
      "INFO:tensorflow:loss = 122467.05, step = 11 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5012\n",
      "INFO:tensorflow:loss = 88845.11, step = 16 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.4962\n",
      "INFO:tensorflow:loss = 67912.734, step = 21 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8471\n",
      "INFO:tensorflow:loss = 53805.58, step = 26 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4528\n",
      "INFO:tensorflow:loss = 44052.67, step = 31 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4224\n",
      "INFO:tensorflow:loss = 37129.25, step = 36 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5358\n",
      "INFO:tensorflow:loss = 32270.59, step = 41 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2956\n",
      "INFO:tensorflow:loss = 28966.426, step = 46 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5512\n",
      "INFO:tensorflow:loss = 26496.32, step = 51 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5921\n",
      "INFO:tensorflow:loss = 24936.484, step = 56 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2892\n",
      "INFO:tensorflow:loss = 23557.545, step = 61 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9777\n",
      "INFO:tensorflow:loss = 22517.295, step = 66 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6625\n",
      "INFO:tensorflow:loss = 21944.473, step = 71 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3695\n",
      "INFO:tensorflow:loss = 21521.217, step = 76 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3777\n",
      "INFO:tensorflow:loss = 21093.834, step = 81 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3226\n",
      "INFO:tensorflow:loss = 20951.209, step = 86 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8035\n",
      "INFO:tensorflow:loss = 20644.166, step = 91 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.7539\n",
      "INFO:tensorflow:loss = 20565.465, step = 96 (0.187 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpUBttKI/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20618.984.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f7064a1ff50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.train(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparing The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_test = tf.estimator.inputs.pandas_input_fn(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = regressor.predict(input_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpUBttKI/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pred_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.265676</td>\n",
       "      <td>6.090455</td>\n",
       "      <td>3.891011</td>\n",
       "      <td>2.383133</td>\n",
       "      <td>6.125526</td>\n",
       "      <td>5.913188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.353870</td>\n",
       "      <td>2.247488</td>\n",
       "      <td>2.589349</td>\n",
       "      <td>4.862419</td>\n",
       "      <td>2.284232</td>\n",
       "      <td>2.145571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.655408</td>\n",
       "      <td>10.444847</td>\n",
       "      <td>4.818306</td>\n",
       "      <td>-2.616473</td>\n",
       "      <td>10.470045</td>\n",
       "      <td>10.202961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.217691</td>\n",
       "      <td>8.367587</td>\n",
       "      <td>4.372981</td>\n",
       "      <td>-0.243249</td>\n",
       "      <td>8.397451</td>\n",
       "      <td>8.156639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.197377</td>\n",
       "      <td>-8.724205</td>\n",
       "      <td>-4.837105</td>\n",
       "      <td>-2.900008</td>\n",
       "      <td>-8.736728</td>\n",
       "      <td>-8.470347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.540921</td>\n",
       "      <td>8.284001</td>\n",
       "      <td>4.020541</td>\n",
       "      <td>-1.485837</td>\n",
       "      <td>8.309180</td>\n",
       "      <td>8.086980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-8.942902</td>\n",
       "      <td>-10.520889</td>\n",
       "      <td>-4.962240</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>-10.525587</td>\n",
       "      <td>-10.250129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.870993</td>\n",
       "      <td>-4.503606</td>\n",
       "      <td>-3.205553</td>\n",
       "      <td>-4.815000</td>\n",
       "      <td>-4.515023</td>\n",
       "      <td>-4.340159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.067645</td>\n",
       "      <td>8.864354</td>\n",
       "      <td>4.168805</td>\n",
       "      <td>-2.053489</td>\n",
       "      <td>8.888577</td>\n",
       "      <td>8.657784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.752304</td>\n",
       "      <td>3.754524</td>\n",
       "      <td>1.780378</td>\n",
       "      <td>-1.387537</td>\n",
       "      <td>3.771393</td>\n",
       "      <td>3.673077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions  pred_estimator\n",
       "0   6.265676   6.090455  3.891011  2.383133     6.125526        5.913188\n",
       "1   4.353870   2.247488  2.589349  4.862419     2.284232        2.145571\n",
       "2  12.655408  10.444847  4.818306 -2.616473    10.470045       10.202961\n",
       "3   6.217691   8.367587  4.372981 -0.243249     8.397451        8.156639\n",
       "4  -8.197377  -8.724205 -4.837105 -2.900008    -8.736728       -8.470347\n",
       "5  10.540921   8.284001  4.020541 -1.485837     8.309180        8.086980\n",
       "6  -8.942902 -10.520889 -4.962240  0.192817   -10.525587      -10.250129\n",
       "7  -4.870993  -4.503606 -3.205553 -4.815000    -4.515023       -4.340159\n",
       "8   9.067645   8.864354  4.168805 -2.053489     8.888577        8.657784\n",
       "9   3.752304   3.754524  1.780378 -1.387537     3.771393        3.673077"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_estimator = [f['predictions'][0] for f in generator]\n",
    "df_test['pred_estimator'] = pred_estimator\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pre-canned estimator arrives at (almost) the same results as our hand-made linear regressor. Not that we had a doubt, though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning From Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that the ground truth is a totally unexpected function of the week day and time of day. That could happen e.g., if you measure the humidity and fail to realize that your sensor is near a dry-cleaner's. Let's assume the dry-cleaner's have peek hours on Mon, Tue, Wed from 18:00h to 21:00 and Fri, Sat from 14:00h to 16:00h. During those hours humidity is significantly higher due to the steam produced there. \n",
    "\n",
    "First, let's create a dataset that reflects that situation. Day of week and hour of day shall be represented by categorical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe with days of week and hour-of-day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a constant, if the hour of week \n",
    "conditions = np.array([\n",
    "    (0, 18), (0, 19), (0, 20), (0, 21), # Mondays\n",
    "    (1, 18), (1, 19), (1, 20), (1, 21), # Tuesdays\n",
    "    (2, 18), (2, 19), (2, 20), (2, 21), # Wednesdays\n",
    "    # closed on Thursdays\n",
    "    (4, 14), (4, 15), (4, 16),          # Fridays\n",
    "    (5, 14), (5, 15), (5, 16)           # Saturdays\n",
    "    # closed on Sundays\n",
    "    ])\n",
    "\n",
    "def make_noisy_amplitude_function(amplitude):\n",
    "    def _f(c1, c2):\n",
    "        zipped = zip(c1,c2)\n",
    "        res = array_in(zipped, conditions)        \n",
    "        return res * (np.random.normal( 0 * res, .2 ) + amplitude)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v2(size, amplitude=5.0):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    dow_data = np.random.randint(7, size=size)\n",
    "    hod_data = np.random.randint(24, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    \n",
    "    f_special = make_noisy_amplitude_function(amplitude)(dow_data, hod_data)\n",
    "\n",
    "    f_total = f_data + f_special\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'dow': dow_data, 'hod': hod_data, 'f_orig': f_data, 'p': f_perf, 'special': f_special, 'f': f_total})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>f</th>\n",
       "      <th>f_orig</th>\n",
       "      <th>hod</th>\n",
       "      <th>p</th>\n",
       "      <th>special</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.530336</td>\n",
       "      <td>-1.530336</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.810533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047477</td>\n",
       "      <td>2.810974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.878536</td>\n",
       "      <td>-2.878536</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.633218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.883840</td>\n",
       "      <td>-1.268925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-8.504981</td>\n",
       "      <td>-8.504981</td>\n",
       "      <td>6</td>\n",
       "      <td>-9.228641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.999361</td>\n",
       "      <td>-2.540162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.205178</td>\n",
       "      <td>-1.205178</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.847020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.033572</td>\n",
       "      <td>-3.440247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>-7.405804</td>\n",
       "      <td>-7.405804</td>\n",
       "      <td>16</td>\n",
       "      <td>-6.845109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.147791</td>\n",
       "      <td>0.099055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.957850</td>\n",
       "      <td>-2.957850</td>\n",
       "      <td>16</td>\n",
       "      <td>-3.843888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.459307</td>\n",
       "      <td>0.850547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.491196</td>\n",
       "      <td>-2.491196</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.881113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633875</td>\n",
       "      <td>3.297726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.496236</td>\n",
       "      <td>-10.496236</td>\n",
       "      <td>2</td>\n",
       "      <td>-11.001783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.798727</td>\n",
       "      <td>1.808657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>1.972425</td>\n",
       "      <td>1.972425</td>\n",
       "      <td>8</td>\n",
       "      <td>1.547327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.150290</td>\n",
       "      <td>4.506506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>-7.768493</td>\n",
       "      <td>-7.768493</td>\n",
       "      <td>14</td>\n",
       "      <td>-6.658851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.861290</td>\n",
       "      <td>0.872542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.324307</td>\n",
       "      <td>-5.324307</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.123550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.111872</td>\n",
       "      <td>4.799611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>9.156586</td>\n",
       "      <td>-0.646353</td>\n",
       "      <td>14</td>\n",
       "      <td>1.259112</td>\n",
       "      <td>9.802939</td>\n",
       "      <td>1.277223</td>\n",
       "      <td>1.590669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.520833</td>\n",
       "      <td>-0.520833</td>\n",
       "      <td>17</td>\n",
       "      <td>-2.360772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113217</td>\n",
       "      <td>4.174412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>6.172034</td>\n",
       "      <td>6.172034</td>\n",
       "      <td>10</td>\n",
       "      <td>4.998811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.707487</td>\n",
       "      <td>3.832325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4.172306</td>\n",
       "      <td>4.172306</td>\n",
       "      <td>21</td>\n",
       "      <td>4.923019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.577591</td>\n",
       "      <td>-0.535675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>-4.368206</td>\n",
       "      <td>-4.368206</td>\n",
       "      <td>22</td>\n",
       "      <td>-3.963320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.508357</td>\n",
       "      <td>0.893213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.935851</td>\n",
       "      <td>-3.935851</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.625911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.817898</td>\n",
       "      <td>2.980230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>8.868577</td>\n",
       "      <td>-1.273301</td>\n",
       "      <td>14</td>\n",
       "      <td>0.711637</td>\n",
       "      <td>10.141878</td>\n",
       "      <td>1.747679</td>\n",
       "      <td>4.567443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>16.556173</td>\n",
       "      <td>6.570668</td>\n",
       "      <td>21</td>\n",
       "      <td>7.658271</td>\n",
       "      <td>9.985505</td>\n",
       "      <td>3.763738</td>\n",
       "      <td>-1.261589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0.784986</td>\n",
       "      <td>0.784986</td>\n",
       "      <td>22</td>\n",
       "      <td>1.765830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736946</td>\n",
       "      <td>-1.583875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dow          f     f_orig  hod          p    special         x         y\n",
       "0     4  -1.530336  -1.530336    4  -1.810533   0.000000  0.047477  2.810974\n",
       "1     3  -2.878536  -2.878536    9  -5.633218   0.000000 -2.883840 -1.268925\n",
       "2     2  -8.504981  -8.504981    6  -9.228641   0.000000 -4.999361 -2.540162\n",
       "3     6  -1.205178  -1.205178    5  -0.847020   0.000000 -1.033572 -3.440247\n",
       "4     3  -7.405804  -7.405804   16  -6.845109   0.000000 -3.147791  0.099055\n",
       "5     2  -2.957850  -2.957850   16  -3.843888   0.000000 -1.459307  0.850547\n",
       "6     0  -2.491196  -2.491196   12  -0.881113   0.000000  0.633875  3.297726\n",
       "7     1 -10.496236 -10.496236    2 -11.001783   0.000000 -4.798727  1.808657\n",
       "8     6   1.972425   1.972425    8   1.547327   0.000000  2.150290  4.506506\n",
       "9     3  -7.768493  -7.768493   14  -6.658851   0.000000 -2.861290  0.872542\n",
       "10    0  -5.324307  -5.324307   11  -5.123550   0.000000 -1.111872  4.799611\n",
       "11    5   9.156586  -0.646353   14   1.259112   9.802939  1.277223  1.590669\n",
       "12    0  -0.520833  -0.520833   17  -2.360772   0.000000  0.113217  4.174412\n",
       "13    1   6.172034   6.172034   10   4.998811   0.000000  3.707487  3.832325\n",
       "14    3   4.172306   4.172306   21   4.923019   0.000000  2.577591 -0.535675\n",
       "15    3  -4.368206  -4.368206   22  -3.963320   0.000000 -1.508357  0.893213\n",
       "16    1  -3.935851  -3.935851    8  -3.625911   0.000000 -0.817898  2.980230\n",
       "17    5   8.868577  -1.273301   14   0.711637  10.141878  1.747679  4.567443\n",
       "18    2  16.556173   6.570668   21   7.658271   9.985505  3.763738 -1.261589\n",
       "19    3   0.784986   0.784986   22   1.765830   0.000000  0.736946 -1.583875"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v2 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "df_train_v2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create a data set suitable for training\n",
    "In the following, our assumption that it is particular hours on particular days makes this problem a candidate for the categorical features 'hour of day' and 'day of week'. Hence, in a first step, let's take those two features into account. For that, we have to one-hot encode those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinals = list(df_train_v2['dow'])\n",
    "one_hot_dows = np.transpose(np.eye(7)[ordinals])\n",
    "one_hot_dows[:7,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = list(df_train_v2['hod'])\n",
    "one_hot_hods = np.transpose(np.eye(24)[ordinals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (2, 20000) + (7, 20000) + (24, 20000) = (33, 20000)\n"
     ]
    }
   ],
   "source": [
    "input_numerical = [list(df_train_v2['x']), list(df_train_v2['y'])]\n",
    "lbls_data = [list(df_train_v2['f'])]\n",
    "input_data = np.append(input_numerical, one_hot_dows, axis=0)\n",
    "input_data = np.append(input_data, one_hot_hods, axis=0)\n",
    "print(\"shapes: {} + {} + {} = {}\".format(np.shape(input_numerical), np.shape(one_hot_dows), np.shape(one_hot_hods), np.shape(input_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 33 columns, 31 of which only sparsely populated. That's ok for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.25788725, -2.57390834,  2.13505662,  4.27987879],\n",
       "       [-3.03482066, -4.44846516, -3.73233705,  0.76097059],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hereafter, we'll use create_input_data from the tools file to achieve just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_input_data(df, select_feats=[], oh_feats={}, cross_feats=[]):    \n",
      "    \"\"\"\n",
      "    create a list of input columns from pandas raw data\n",
      "    df: a pandas dataframe containing raw input data\n",
      "    select_feats: an array containing the names of features to be selected without transformation\n",
      "    oh_feats: a dictionary containing the names and sizes of discrete numerical features that are to be one-hot encoded\n",
      "    cross_feats: a list of oh_feats consisting of two discrete features to cross\n",
      "    \"\"\"\n",
      "\n",
      "    def _safe_append(l, r):\n",
      "        if l == [] or l is None:\n",
      "            return r\n",
      "        else:\n",
      "            return np.append(l, r, axis=0)\n",
      "\n",
      "    res = [list(df[n]) for n in select_feats]\n",
      "    \n",
      "    for k in oh_feats:\n",
      "        res = _safe_append(res, one_hot(df[k], oh_feats[k]))\n",
      "\n",
      "    for c in cross_feats:\n",
      "        lk, ls = c.items()[0]\n",
      "        rk, rs = c.items()[1]\n",
      "        lhs = one_hot(df[lk], ls)\n",
      "        rhs = one_hot(df[rk], rs)\n",
      "        cross = [(lhs[:,i].reshape(ls,1) * rhs[:,i].reshape(1,rs)).reshape(rs*ls) for i in range(len(df))]\n",
      "        cross = np.transpose(cross)\n",
      "        res = _safe_append(res, cross)\n",
      "\n",
      "    return res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(create_input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create the network and start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use once more our self-made linear regressor. Below is the code that we hade previously, only this time augmented by the 24 + 7 new input features from the categorical columns. Observe that we train a long time with a lot more data, and the training loss still doesn't improve much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_DIM = 2 # namely x and y\n",
    "WEEKDAY_DIM = 7 # obviously\n",
    "HOUR_OF_DAY_DIM = 24\n",
    "X_DIM = NUMERICAL_DIM + WEEKDAY_DIM + HOUR_OF_DAY_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 8.42599868774"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.425999"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear2 = Linear(X_DIM, .01)\n",
    "linear2.train(sess, input_data, lbls_data, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That loss is significantly larger than the one that we experienced in the simple case. So either the signal/noise ratio is worse (we know it isn't) or there's some signal in the data that we don't recognize yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sometimes the distribution of the prediction errors reveals additional facts of the problems that our network has. Usually we'll need large enough samples to allow for sufficient statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predicted</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.111627</td>\n",
       "      <td>7.873753</td>\n",
       "      <td>6.672920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.396051</td>\n",
       "      <td>6.752109</td>\n",
       "      <td>11.254703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.177805</td>\n",
       "      <td>-1.466376</td>\n",
       "      <td>3.269683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.131866</td>\n",
       "      <td>-7.519740</td>\n",
       "      <td>-4.369236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.852942</td>\n",
       "      <td>4.012187</td>\n",
       "      <td>2.858963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-15.086180</td>\n",
       "      <td>-12.010042</td>\n",
       "      <td>-8.945951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-7.873636</td>\n",
       "      <td>-6.344114</td>\n",
       "      <td>-2.064191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-10.269167</td>\n",
       "      <td>-9.411917</td>\n",
       "      <td>-6.201080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.909115</td>\n",
       "      <td>1.348384</td>\n",
       "      <td>1.873280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.159789</td>\n",
       "      <td>0.268248</td>\n",
       "      <td>-0.813622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p  predicted  special\n",
       "0   5.111627   7.873753   6.672920      0.0\n",
       "1   7.396051   6.752109  11.254703      0.0\n",
       "2  -3.177805  -1.466376   3.269683      0.0\n",
       "3  -8.131866  -7.519740  -4.369236      0.0\n",
       "4   2.852942   4.012187   2.858963      0.0\n",
       "5 -15.086180 -12.010042  -8.945951      0.0\n",
       "6  -7.873636  -6.344114  -2.064191      0.0\n",
       "7 -10.269167  -9.411917  -6.201080      0.0\n",
       "8   1.909115   1.348384   1.873280      0.0\n",
       "9   1.159789   0.268248  -0.813622      0.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_v2 = create_data_frame_v2(size = 20000, amplitude=10)\n",
    "test_data = create_input_data(df=df_test_v2, select_feats=['x','y'], oh_feats={'dow': 7, 'hod': 24})\n",
    "\n",
    "pred = linear2.predict(x_data=test_data, sess=sess)\n",
    "df_test_v2['predicted'] = pred[0]\n",
    "df_test_v2[['f', 'p', 'predicted', 'special']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test_v2['predicted'] - df_test_v2['f']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the error distribution that there's some really interesting stuff going on. This is almost certainly a hint that our data contains structure that we didn't discover yet. This distribution is telling: For the majority of the data - the large bump - we have a tendency to over-predict. For some minority though we significantly under-predict. This is a typical sign that the linear regression is finding a weak compromise between two distinct and somehow unrelated distributions that make up our total input data.\n",
    "\n",
    "Obviously, although or network actually had all the information it needed, simply adding the categorical features didn't allow it to learn the specific characteristic, namely the \"and\" relationship like in: \"The humidity is higher, when it's Wednesday *and* it's 18:00h\". \n",
    "\n",
    "Feature crossings and embeddings to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example: This is Wednesday, 08:00h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday = np.array([[0,0,1,0,0,0,0]])\n",
    "at_0800 = np.zeros((1,24))\n",
    "at_0800[0,8] = 1\n",
    "wednesday, at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossing categorical features $a$ and $b$ means: Put a 1 only where both $a$ and $b$ have a one. Put zeros anywhere else. Python broadcasting helps us achieve that with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday_at_0800 = wednesday.T * at_0800\n",
    "wednesday_at_0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = np.reshape(wednesday_at_0800, newshape=(1,-1))\n",
    "np.argmax(cross) == 2 * 24 + 8 # Wed * 24 + at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets a little more involved when dealing with a batch of feature pairs as you can see in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dows = np.array([[0,0,1,0,0,0,0],[0,0,0,0,0,1,0]])\n",
    "hods = np.zeros((2,24))\n",
    "hods[0,8] = 1\n",
    "hods[1,16] = 1\n",
    "dows, hods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(dows[i].reshape(7,1) * hods[i].reshape(1,24)).reshape(168) for i in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now, instead of feeding both features independently we feed the feature cross into our linear regression model. Note that we need a lot of data to have sufficient statistics for each hour of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 20000), 20000)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_RECORDS = 20000\n",
    "\n",
    "df_train_v3 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "input_data_v3 = create_input_data(df=df_train_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "lbls_data_v3 = [list(df_train_v3['f'])]\n",
    "input_data_v3.shape, len(lbls_data_v3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.08507370949"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0850737"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_v3 = Linear(lr=.05, x_dim=170)\n",
    "regressor_v3.train(sess=sess, num_steps=4000, x_data=input_data_v3, labels_data=lbls_data_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can see that the loss function has indeed gone down dramatically. Now let's examine the error statistics on some fresh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_v3 = create_data_frame_v2(size = 20000, amplitude=10.0)\n",
    "input_data_test_v3 = create_input_data(df=df_test_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "preds = regressor_v3.predict(sess=sess, x_data=input_data_test_v3)\n",
    "\n",
    "errors = preds[0] - df_test_v3['f']\n",
    "df_test_v3['preds'] = preds[0]\n",
    "df_test_v3['err'] = errors\n",
    "df_test_v3['err'].plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, there's some subtle asymmetry in the error distribution, depending on how long you trained, but we can see that the characteristic second bump has disappeared. When we look at the weights associated with the 168 different hours of a week, we spot a few larger positive values amongst otherwise smaller negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.005149  , -0.8667414 , -0.967675  , -0.91787624, -0.803695  ,\n",
       "       -1.2356933 , -1.016509  , -0.92341936, -1.1314232 , -1.1117525 ,\n",
       "       -0.8752426 , -1.0067945 , -0.8578481 , -0.87095094, -1.1425475 ,\n",
       "       -0.9637266 , -1.0629308 , -0.9574459 , -0.82083046, -1.1197901 ,\n",
       "       -0.91110855, -0.9723683 , -0.8987742 , -1.1045686 , -1.0094982 ,\n",
       "       -1.0034063 , -0.92455786, -1.0734261 , -0.8558298 , -1.1054251 ,\n",
       "       -0.93289226, -0.9428423 , -1.0206796 , -0.9693226 , -1.0491971 ,\n",
       "       -0.70295584, -1.0074732 , -0.880943  , -0.75826097, -1.1733898 ,\n",
       "       -1.1646322 , -0.96469384, -0.8453277 , -1.2653475 , -0.84292185,\n",
       "       -0.84850174, -1.0921426 , -0.81932515, -1.0378444 , -0.9019344 ,\n",
       "       -0.7971329 , -0.97631526, -0.7903632 , -0.98868984, -0.856047  ,\n",
       "       -1.0594823 , -0.7900342 , -1.1091088 , -1.2077525 , -0.820299  ,\n",
       "       -0.8997701 , -0.8044826 , -1.0639642 , -0.8517061 , -0.7990329 ,\n",
       "       -0.9921987 , -1.030122  , -1.103021  , -0.9092001 , -0.982336  ,\n",
       "       -0.91505796, -0.9678397 , -1.0384432 , -0.85909003, -1.0410082 ,\n",
       "       -1.1028333 , -0.8253786 , -0.874672  , -0.9690489 , -1.0493939 ,\n",
       "       -1.0021615 , -0.99480486, -0.8830947 , -0.9286582 , -1.2012583 ,\n",
       "       -0.98477453, -0.9172957 , -0.9049747 , -0.856679  , -0.7427606 ,\n",
       "       -0.9977982 , -1.0595207 , -0.8364851 , -1.0104016 , -0.8324982 ,\n",
       "       -1.1655145 , -0.96880835, -1.0679511 , -0.7900927 , -0.7844564 ,\n",
       "       -1.0898551 , -0.8343936 ,  8.111396  ,  8.212222  , -1.0621122 ,\n",
       "       -1.0998579 , -1.0438757 , -0.93556   , -1.1244605 ,  7.9286776 ,\n",
       "        8.051692  , -0.92753184, -0.88559943, -0.88205487, -0.8538568 ,\n",
       "       -1.0371683 ,  8.091381  ,  7.910343  , -0.91610354, -0.7476006 ,\n",
       "       -1.0130546 , -0.7938346 , -0.9485361 , -0.84933645, -0.89856684,\n",
       "       -0.68855584,  7.7449822 ,  8.186176  ,  7.8996825 , -0.9210507 ,\n",
       "       -0.87068367, -1.0479943 , -0.8081561 ,  8.19172   ,  7.74588   ,\n",
       "        8.1049385 , -0.9406709 , -1.0687191 , -0.78257483, -1.1068622 ,\n",
       "        8.278643  ,  7.9149127 ,  7.9310994 , -1.0969384 , -0.8933162 ,\n",
       "       -0.9753076 , -1.0199649 ,  7.8698373 ,  7.5905704 ,  8.507965  ,\n",
       "       -1.0992881 , -0.96820414, -0.9487221 , -0.95719934, -0.910403  ,\n",
       "       -1.0179596 , -0.82326245, -0.9483878 , -1.0999379 , -0.91345906,\n",
       "       -0.9889649 , -1.0865685 , -0.8795486 , -0.7823414 , -1.1482999 ,\n",
       "       -0.9391342 , -0.82387036, -1.0798475 ], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = regressor_v3.M.eval()\n",
    "weights_t = weights.squeeze()[2:]\n",
    "weights_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes of the larger values allow us to discover exactly those hours of week during which the dry-cleaner anomalies are observed. The network truly learned when these anomalies are typically observed and adds some more humidity in its prediction during those times of the week. Ain't that cool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 18), array([ 0, 18])),\n",
       " ((0, 19), array([ 0, 19])),\n",
       " ((0, 20), array([ 0, 20])),\n",
       " ((0, 21), array([ 0, 21])),\n",
       " ((1, 18), array([ 1, 18])),\n",
       " ((1, 19), array([ 1, 19])),\n",
       " ((1, 20), array([ 1, 20])),\n",
       " ((1, 21), array([ 1, 21])),\n",
       " ((2, 18), array([ 2, 18])),\n",
       " ((2, 19), array([ 2, 19])),\n",
       " ((2, 20), array([ 2, 20])),\n",
       " ((2, 21), array([ 2, 21])),\n",
       " ((4, 14), array([ 4, 14])),\n",
       " ((4, 15), array([ 4, 15])),\n",
       " ((4, 16), array([ 4, 16])),\n",
       " ((5, 14), array([ 5, 14])),\n",
       " ((5, 15), array([ 5, 15])),\n",
       " ((5, 16), array([ 5, 16]))]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [i for i in range(168) if weights_t[i] > 1]\n",
    "how_detected = [(i % 7, i / 7 ) for i in indexes]\n",
    "how_detected = sorted(how_detected, key=lambda d: d[0])\n",
    "zip(how_detected, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the left, the hours of the week as detected by the network, to the left the conditions that lead to the anomalies in the data. A perfect fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
