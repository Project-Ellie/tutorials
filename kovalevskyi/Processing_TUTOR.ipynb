{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import tempfile\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import apache_beam as beam\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam.impl as beam_impl\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import google.datalab.bigquery as dlbq\n",
    "\n",
    "from tools import tf_haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The google.cloud.bigquery extension is already loaded. To reload it, use:\n",
      "  %reload_ext google.cloud.bigquery\n"
     ]
    }
   ],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT='going-tfx'\n",
    "BUCKET='going-tfx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from configuration_2 import PROJECT\n",
    "from configuration_2 import BUCKET\n",
    "from configuration_2 import DATASET\n",
    "\n",
    "from configuration_2 import SIGNATURE_METADATA\n",
    "from configuration_2 import SIGNATURE_SCHEMA\n",
    "from configuration_2 import SIGNATURE_COLUMNS\n",
    "from configuration_2 import TRAINING_COLUMNS\n",
    "from configuration_2 import ORDERED_TRAINING_COLUMNS\n",
    "\n",
    "from configuration_2 import directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We will distinguish different stages, such as 'sample' or 'full', to avoid mixing up things. That's what we're demonstrating here:\n",
    "As an example:\n",
    "\n",
    "- The first dictionary groups the directories containing *sample* stage data on Google cloud storage\n",
    "- The second dictionary groups the directories containing *full* stage data on some local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "directories('gs', 'sample'), directories('local', 'full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Signature data in Bigquery\n",
    "We collected the raw data that we use from various sources into a single denormalized table holding the data in so-called signature format. That table's schema is meant to reflect the structure of the data/requests that we expect to be served at prediction time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>...</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_T</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_W</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-06-01</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1927</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2113</td>\n",
       "      <td>26.0</td>\n",
       "      <td>RNO</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-119.76</td>\n",
       "      <td>RENO WBO</td>\n",
       "      <td>67.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-06-02</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1927</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2113</td>\n",
       "      <td>40.0</td>\n",
       "      <td>RNO</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-119.76</td>\n",
       "      <td>RENO WBO</td>\n",
       "      <td>62.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-06-03</td>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Delta Air Lines Inc.: DL</td>\n",
       "      <td>1927</td>\n",
       "      <td>ATL</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2113</td>\n",
       "      <td>13.0</td>\n",
       "      <td>RNO</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-119.76</td>\n",
       "      <td>RENO WBO</td>\n",
       "      <td>58.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  YEAR  MONTH  DAY  DEP_DOW                   AIRLINE  DEP_T  \\\n",
       "0  2005-06-01  2005      6    1        4  Delta Air Lines Inc.: DL   1927   \n",
       "1  2005-06-02  2005      6    2        5  Delta Air Lines Inc.: DL   1927   \n",
       "2  2005-06-03  2005      6    3        6  Delta Air Lines Inc.: DL   1927   \n",
       "\n",
       "   DEP  DEP_LAT  DEP_LON     ...       WND_SPD_DEP ARR_T  ARR_DELAY  ARR  \\\n",
       "0  ATL    33.63   -84.42     ...              14.4  2113       26.0  RNO   \n",
       "1  ATL    33.63   -84.42     ...               9.7  2113       40.0  RNO   \n",
       "2  ATL    33.63   -84.42     ...               7.4  2113       13.0  RNO   \n",
       "\n",
       "   ARR_LAT  ARR_LON     ARR_W MEAN_TEMP_ARR  MEAN_VIS_ARR  WND_SPD_ARR  \n",
       "0    39.49  -119.76  RENO WBO          67.2          10.0          9.8  \n",
       "1    39.49  -119.76  RENO WBO          62.1          10.0          7.2  \n",
       "2    39.49  -119.76  RENO WBO          58.9          10.0          4.3  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery aj_sample\n",
    "select * FROM `going-tfx.examples.ATL_JUNE_SIGNATURE` limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Signature** columns are those columns that we expect to be provided at prediction time. We have exactly those columns made available in ```ATL_JUNE_SIGNATURE``` table in Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEP_DOW', 'DEP_T', 'DEP_LAT', 'DEP_LON', 'DEP_DELAY', 'MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', 'ARR_LAT', 'ARR_LON', 'ARR_DELAY', 'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR']\n"
     ]
    }
   ],
   "source": [
    "from train.model_config import SIGNATURE_COLUMNS\n",
    "print(SIGNATURE_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "These are the feature-engineered columns that we'll create and save in ```TFRecord``` files for training. You see: Some columns will be dropped (e.g. ```DEP_T```) and others added (e.g. ```DISTANCE```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEP_DOW', 'DEP_HOD', 'DEP_LAT', 'DEP_LON', 'MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', 'DEP_DELAY', 'ARR_LAT', 'ARR_LON', 'ARR_DELAY', 'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR', 'DIFF_LAT', 'DIFF_LON', 'DISTANCE']\n"
     ]
    }
   ],
   "source": [
    "from train.model_config import TRAINING_COLUMNS\n",
    "print(TRAINING_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Repeatable random subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_query(columns, total, lower, upper):\n",
    "    col_string=\", \".join(columns)\n",
    "    return \"\"\"\n",
    "    SELECT\n",
    "        {0}\n",
    "    FROM \n",
    "        `going-tfx.examples.ATL_JUNE_SIGNATURE` \n",
    "    where\n",
    "        MOD(ABS(FARM_FINGERPRINT(\n",
    "            CONCAT(DATE,AIRLINE,ARR)\n",
    "        )) + DEP_T, {1}) >= {2} \n",
    "    and\n",
    "        MOD(ABS(FARM_FINGERPRINT(\n",
    "            CONCAT( DATE, AIRLINE, ARR)\n",
    "        )) + DEP_T, {1}) < {3} \n",
    "    \"\"\".format(col_string, total, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_queries(columns, fractions, rate=0.1):\n",
    "    start = 0\n",
    "    total = int(sum(fractions) / rate)\n",
    "    res = []\n",
    "    for f in fractions:\n",
    "        f_ = int(f) \n",
    "        q = sample_query(columns, total, start, start+f_)\n",
    "        start = start + f_\n",
    "        res.append(q)\n",
    "    return dict(zip(['train', 'eval', 'test'], res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = sample_queries(SIGNATURE_COLUMNS, [80,10,10], .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT\n",
      "        DEP_DOW, DEP_T, DEP_LAT, DEP_LON, DEP_DELAY, MEAN_TEMP_DEP, MEAN_VIS_DEP, WND_SPD_DEP, ARR_LAT, ARR_LON, ARR_DELAY, MEAN_TEMP_ARR, MEAN_VIS_ARR, WND_SPD_ARR\n",
      "    FROM \n",
      "        `going-tfx.examples.ATL_JUNE_SIGNATURE` \n",
      "    where\n",
      "        MOD(ABS(FARM_FINGERPRINT(\n",
      "            CONCAT(DATE,AIRLINE,ARR)\n",
      "        )) + DEP_T, 1000) >= 80 \n",
      "    and\n",
      "        MOD(ABS(FARM_FINGERPRINT(\n",
      "            CONCAT( DATE, AIRLINE, ARR)\n",
      "        )) + DEP_T, 1000) < 90 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(queries['eval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A super-small random subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 40 examples. Showing first three:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_T</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1025</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>-87.18</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>79.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1608</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>35.81</td>\n",
       "      <td>-83.99</td>\n",
       "      <td>14.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>27.97</td>\n",
       "      <td>-82.53</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEP_DOW  DEP_T  DEP_LAT  DEP_LON  DEP_DELAY  MEAN_TEMP_DEP  MEAN_VIS_DEP  \\\n",
       "0        1   1025    33.63   -84.42       -3.0           74.0           7.6   \n",
       "1        1   1608    33.63   -84.42       16.0           76.7           9.5   \n",
       "2        1   1405    33.63   -84.42        2.0           75.7           9.3   \n",
       "\n",
       "   WND_SPD_DEP  ARR_LAT  ARR_LON  ARR_DELAY  MEAN_TEMP_ARR  MEAN_VIS_ARR  \\\n",
       "0          5.0    30.47   -87.18       -9.0           79.7          10.0   \n",
       "1          7.7    35.81   -83.99       14.0           74.2           9.9   \n",
       "2          6.5    27.97   -82.53       -1.0           82.5          10.0   \n",
       "\n",
       "   WND_SPD_ARR  \n",
       "0          4.8  \n",
       "1          9.8  \n",
       "2          4.3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_query = sample_query(SIGNATURE_COLUMNS, 10000, 0, 1)\n",
    "sample = dlbq.Query(tiny_query).execute().result().to_dataframe()\n",
    "print('Only {} examples. Showing first three:'.format(len(sample)))\n",
    "sample[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Reading from Bigquery into a beam pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR=\"./out\"\n",
    "job_name = 'tft_tutorial' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "\n",
    "options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': job_name,\n",
    "    'project': PROJECT,\n",
    "    'max_num_workers': 24,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True,\n",
    "    'requirements_file': 'requirements.txt'\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "This simple pipeline reads, transforms and emits the result into a csv file. It returns a pair consisting of a pandas dataframe containing the data, and the transformed schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_TMPDIR='/tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be written to /tmp/\n"
     ]
    }
   ],
   "source": [
    "def exec_pipeline(query, preprocessing_fn, output_columns, out_name = 'atl_june_transformed', write_header=False, runner='DirectRunner'):\n",
    "    \n",
    "    header=\",\".join(output_columns) if write_header else None\n",
    "    \n",
    "    out_prefix = os.path.join(LOCAL_TMPDIR, out_name)\n",
    "    with beam.Pipeline(runner, options=opts) as p:\n",
    "        with beam_impl.Context(temp_dir=tempfile.mkdtemp()):\n",
    "            \n",
    "            \n",
    "            #   Read from Big Query\n",
    "            #\n",
    "            sig_data = p | \"ReadFromBigQuery\"  >> beam.io.Read(beam.io.BigQuerySource(query=query, use_standard_sql=True)) \n",
    "            sig_dataset = (sig_data, SIGNATURE_METADATA)\n",
    "\n",
    "            \n",
    "            #   Analyze and transform by calling a single function that has all the tft.transforms in it\n",
    "            #\n",
    "            t_dataset, t_fn = (sig_dataset | beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "            t_data, t_metadata = t_dataset\n",
    "            \n",
    "            \n",
    "            # Encode back to CSV file(s)\n",
    "            #\n",
    "            csv_encode = tft.coders.CsvCoder(output_columns, t_metadata.schema).encode    \n",
    "            res = (t_data \n",
    "                   | beam.Map(csv_encode)\n",
    "                   | beam.io.WriteToText(file_path_prefix=out_prefix, header=header))\n",
    "\n",
    "            \n",
    "    # Return a pandas dataframe containing the result\n",
    "    #\n",
    "    resfile = !ls $LOCAL_TMPDIR | grep $out_name\n",
    "    resfile = resfile[0]\n",
    "    resfile = os.path.join(LOCAL_TMPDIR, resfile)\n",
    "    return pd.read_csv(resfile), t_metadata.schema\n",
    "\n",
    "print(\"Output will be written to {}\".format(LOCAL_TMPDIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Developing the pre-processing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Do nothing\n",
    "Here, we simply verify that the pipeline setup is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing(inputs):\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiny_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e9a01a31ad88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexec_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiny_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_nothing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIGNATURE_COLUMNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DirectRunner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tiny_query' is not defined"
     ]
    }
   ],
   "source": [
    "res, _ = exec_pipeline(tiny_query, do_nothing, SIGNATURE_COLUMNS, write_header=True, runner='DirectRunner')\n",
    "res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Adding engineered features\n",
    "We use the well-known haversine function (defined in ```tools.py```) to calculate the distance between two lat/lon coordinate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf_haversine(lat1, lon1, lat2, lon2):\n",
      "    \n",
      "    def radians(a):\n",
      "        return a * math.pi / 180.0\n",
      "\n",
      "    radius = 6371.0\n",
      "    dlat = radians (lat2 - lat1) \n",
      "    dlon = radians (lon2 - lon1)\n",
      "    a = (tf.sin(dlat / 2.0) * tf.sin(dlat/2.0) +\n",
      "         tf.cos(radians(lat1)) * tf.cos(radians(lat2)) *\n",
      "         tf.sin(dlon / 2.0) * tf.sin(dlon / 2.0))\n",
      "    c = 2.0 * tf.atan2(tf.sqrt(a), tf.sqrt(1.0 - a))\n",
      "    return radius * c\n"
     ]
    }
   ],
   "source": [
    "!grep -A 13 tf_haversine tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engineered(row):\n",
    "    dep_lat = row['DEP_LAT']\n",
    "    dep_lon = row['DEP_LON']\n",
    "    arr_lat = row['ARR_LAT']\n",
    "    arr_lon = row['ARR_LON']\n",
    "\n",
    "    row['DEP_HOD'] = row['DEP_T'] // 100\n",
    "    row.pop('DEP_T')  # no longer needed\n",
    "\n",
    "    row['DIFF_LAT'] = arr_lat - dep_lat\n",
    "    row['DIFF_LON'] = arr_lon - dep_lon\n",
    "    row['DISTANCE'] = tf_haversine(arr_lat, arr_lon, dep_lat, dep_lon)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_59f2be10099641ec9b14a6926f24ecb8 does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_HOD</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>75.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.97</td>\n",
       "      <td>-82.53</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-5.660002</td>\n",
       "      <td>1.889999</td>\n",
       "      <td>654.69806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>30.47</td>\n",
       "      <td>-87.18</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>79.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-3.160002</td>\n",
       "      <td>-2.760002</td>\n",
       "      <td>437.13605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>74.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.87</td>\n",
       "      <td>-78.78</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.239998</td>\n",
       "      <td>5.639999</td>\n",
       "      <td>572.19543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEP_DOW  DEP_HOD  DEP_LAT  DEP_LON  MEAN_TEMP_DEP  MEAN_VIS_DEP  \\\n",
       "0        1       14    33.63   -84.42           75.7           9.3   \n",
       "1        1       10    33.63   -84.42           74.0           7.6   \n",
       "2        1       10    33.63   -84.42           74.5           6.9   \n",
       "\n",
       "   WND_SPD_DEP  DEP_DELAY  ARR_LAT  ARR_LON  ARR_DELAY  MEAN_TEMP_ARR  \\\n",
       "0          6.5        2.0    27.97   -82.53       -1.0           82.5   \n",
       "1          5.0       -3.0    30.47   -87.18       -9.0           79.7   \n",
       "2          9.8       -1.0    35.87   -78.78        7.0           78.6   \n",
       "\n",
       "   MEAN_VIS_ARR  WND_SPD_ARR  DIFF_LAT  DIFF_LON   DISTANCE  \n",
       "0          10.0          4.3 -5.660002  1.889999  654.69806  \n",
       "1          10.0          4.8 -3.160002 -2.760002  437.13605  \n",
       "2           9.0          4.6  2.239998  5.639999  572.19543  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_processor(row):\n",
    "    return add_engineered(row)\n",
    "\n",
    "res, _ = exec_pipeline(tiny_query, pre_processor, TRAINING_COLUMNS, write_header=True)\n",
    "res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Step 4: Scaling floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_floats(row):\n",
    "    for c in ['MEAN_TEMP_DEP', 'MEAN_VIS_DEP', 'WND_SPD_DEP', 'MEAN_TEMP_ARR', 'MEAN_VIS_ARR', 'WND_SPD_ARR', 'DEP_DELAY',\n",
    "             'DIFF_LAT', 'DIFF_LON', 'DISTANCE']:\n",
    "        row[c] = tft.scale_to_0_1(row[c])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processor(row):\n",
    "    row = row.copy()\n",
    "    row = add_engineered(row)\n",
    "    row = scale_floats(row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_fbf5cb6f2917407380383f7e407622cb does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_HOD</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>35.87</td>\n",
       "      <td>-78.78</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.490364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.823701</td>\n",
       "      <td>0.122422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>35.81</td>\n",
       "      <td>-83.99</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.396146</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.561345</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.010180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>27.97</td>\n",
       "      <td>-82.53</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.573876</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>0.122129</td>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.150773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEP_DOW  DEP_HOD  DEP_LAT  DEP_LON  MEAN_TEMP_DEP  MEAN_VIS_DEP  \\\n",
       "0        1       10    33.63   -84.42         0.2875         0.225   \n",
       "1        1       16    33.63   -84.42         0.4250         0.875   \n",
       "2        1       14    33.63   -84.42         0.3625         0.825   \n",
       "\n",
       "   WND_SPD_DEP  DEP_DELAY  ARR_LAT  ARR_LON  ARR_DELAY  MEAN_TEMP_ARR  \\\n",
       "0       0.7500   0.017937    35.87   -78.78        7.0       0.490364   \n",
       "1       0.4875   0.094170    35.81   -83.99       14.0       0.396146   \n",
       "2       0.3375   0.031390    27.97   -82.53       -1.0       0.573876   \n",
       "\n",
       "   MEAN_VIS_ARR  WND_SPD_ARR  DIFF_LAT  DIFF_LON  DISTANCE  \n",
       "0          0.80     0.148649  0.564706  0.823701  0.122422  \n",
       "1          0.98     0.500000  0.561345  0.715385  0.010180  \n",
       "2          1.00     0.128378  0.122129  0.745738  0.150773  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, _ = exec_pipeline(tiny_query, pre_processor, TRAINING_COLUMNS, write_header=True)\n",
    "res[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create the big files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tell dataflow what packages our pipeline requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-transform"
     ]
    }
   ],
   "source": [
    "!cat dataflow_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_pipeline_prod (environment, stage, \n",
    "                        preprocessing_fn, output_columns, \n",
    "                        fractions, sample_rate, prefix,\n",
    "                        runner='DirectRunner', write_header=False):\n",
    "    \n",
    "    header=\",\".join(output_columns) if write_header else None\n",
    "    \n",
    "    dirs = directories(environment, stage)    \n",
    "    tmpdir = dirs['tmp']\n",
    "    datadir = dirs['data']\n",
    "    metadir = dirs['metadata']\n",
    "\n",
    "    job_name = 'tft-tutorial' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "\n",
    "    options = {\n",
    "        'staging_location': tmpdir,\n",
    "        'temp_location': tmpdir,\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'max_num_workers': 24,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True,\n",
    "        'requirements_file': 'dataflow_requirements.txt'\n",
    "    }    \n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    \n",
    "    with beam.Pipeline(runner, options=opts) as p:\n",
    "        with beam_impl.Context(temp_dir=tmpdir):\n",
    "            \n",
    "            queries = sample_queries(SIGNATURE_COLUMNS, fractions, sample_rate)\n",
    "\n",
    "            #   Read training data from Big Query\n",
    "            #\n",
    "            signature_data = p | \"ReadFromBigQuery_train\"  >> beam.io.Read(beam.io.BigQuerySource(query=queries['train'], use_standard_sql=True)) \n",
    "            signature_dataset = (signature_data, SIGNATURE_METADATA)\n",
    "\n",
    "            \n",
    "            #   Analyze and transform by calling a single function that has all the tft.transforms in it\n",
    "            #\n",
    "            t_dataset, transform_fn = (signature_dataset \n",
    "                                       | \"AnalyzeAndTransform\" >> beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "            t_data, t_metadata = t_dataset\n",
    "            \n",
    "            \n",
    "            # Encode back to CSV file(s)\n",
    "            #\n",
    "            train_prefix = os.path.join(datadir, prefix + \"_train\")\n",
    "\n",
    "            csv_encode = tft.coders.CsvCoder(output_columns, t_metadata.schema).encode    \n",
    "            res = (t_data \n",
    "                   | \"EncodeTraining\" >> beam.Map(csv_encode)\n",
    "                   | \"WriteTraining\" >> beam.io.WriteToText(file_path_prefix=train_prefix, header=header))\n",
    "\n",
    "\n",
    "            #   Read eval data from Big Query\n",
    "            #\n",
    "            signature_data = p | \"ReadFromBigQuery_eval\"  >> beam.io.Read(beam.io.BigQuerySource(query=queries['eval'], use_standard_sql=True)) \n",
    "            signature_dataset = (signature_data, SIGNATURE_METADATA)\n",
    "\n",
    "            \n",
    "            #   Transform the eval dataset with the transform function derived above\n",
    "            #\n",
    "            t_dataset = ((signature_dataset, transform_fn) \n",
    "                         | \"TransformEval\" >> beam_impl.TransformDataset())\n",
    "            t_data, _ = t_dataset\n",
    "            \n",
    "            \n",
    "            # Encode back to CSV file(s)\n",
    "            #\n",
    "            eval_prefix = os.path.join(datadir, prefix + \"_eval\")\n",
    "            csv_encode = tft.coders.CsvCoder(output_columns, t_metadata.schema).encode    \n",
    "            res = (t_data \n",
    "                   | \"EncodeEval\" >> beam.Map(csv_encode)\n",
    "                   | \"WriteEval\" >> beam.io.WriteToText(file_path_prefix=eval_prefix, header=header))\n",
    "\n",
    "            \n",
    "            # save transformation function to disk for use at serving time\n",
    "            #\n",
    "            transform_fn | 'WriteTransformFn' >> transform_fn_io.WriteTransformFn(metadir)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## First stage: Run locally on a smaller sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up before we start\n",
    "We distinguish a sample scenario that we still want to run with DirectRunner, and then a full scenario. That's why we use two different file locations even in the local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(stage):\n",
    "    local_dirs = directories('local', stage)\n",
    "    gs_dirs = directories('gs', stage)\n",
    "\n",
    "    for path in local_dirs.values():\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "        os.mkdir(path)\n",
    "        res = !ls $path\n",
    "        print(\"{} contains {} files.\".format(path, len(res)))\n",
    "        \n",
    "    for path in gs_dirs.values():\n",
    "        _ = !gsutil -m rm -rf $path\n",
    "        res = !gsutil ls $path\n",
    "        print(\"{}: {}\".format(path, res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/atl_june/sample/tmp contains 0 files.\n",
      "/tmp/atl_june/sample/data contains 0 files.\n",
      "/tmp/atl_june/sample/metadata contains 0 files.\n",
      "gs://going-tfx/sample/tmp: CommandException: One or more URLs matched no objects.\n",
      "gs://going-tfx/sample/data: CommandException: One or more URLs matched no objects.\n",
      "gs://going-tfx/sample/metadata: CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "cleanup('sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the pipeline!\n",
    "This takes about two minutes. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dataset going-tfx:temp_dataset_d65d6a1c4175450d9e46bd47377712d4 does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Dataset going-tfx:temp_dataset_26e6717cde7644dfb4eac77de114f4da does not exist so we will create it as temporary with location=US\n"
     ]
    }
   ],
   "source": [
    "exec_pipeline_prod (\n",
    "    'gs', 'sample',\n",
    "    preprocessing_fn=pre_processor, \n",
    "    output_columns=ORDERED_TRAINING_COLUMNS, \n",
    "    fractions=[80, 10, 10], \n",
    "    sample_rate=0.1,\n",
    "    prefix='atl_june',\n",
    "    runner = 'DirectRunner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine and retrieve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'data': 'gs://going-tfx/sample/data',\n",
       "  'metadata': 'gs://going-tfx/sample/metadata',\n",
       "  'tmp': 'gs://going-tfx/sample/tmp'},\n",
       " {'data': '/tmp/atl_june/sample/data',\n",
       "  'metadata': '/tmp/atl_june/sample/metadata',\n",
       "  'tmp': '/tmp/atl_june/sample/tmp'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdirs = directories('gs', 'sample')\n",
    "localdirs = directories('local', 'sample')\n",
    "gsdirs, localdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying first 6 of gs://going-tfx/sample/data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gs://going-tfx/sample/data/atl_june_eval-00000-of-00003',\n",
       " 'gs://going-tfx/sample/data/atl_june_eval-00001-of-00003',\n",
       " 'gs://going-tfx/sample/data/atl_june_eval-00002-of-00003',\n",
       " 'gs://going-tfx/sample/data/atl_june_train-00000-of-00025',\n",
       " 'gs://going-tfx/sample/data/atl_june_train-00001-of-00025',\n",
       " 'gs://going-tfx/sample/data/atl_june_train-00002-of-00025']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdatadir = gsdirs['data']\n",
    "res = !gsutil ls $gsdatadir\n",
    "print(\"Displaying first 6 of {}.\".format(gsdatadir))\n",
    "res[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "localdatadir = localdirs['data']\n",
    "!mkdir -p $localdatadir\n",
    "_ = !gsutil -m cp $gsdatadir/*eval* $localdatadir\n",
    "_ = !gsutil -m cp $gsdatadir/*train* $localdatadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/atl_june/sample/data contains ['atl_june_eval-00000-of-00003', 'atl_june_eval-00001-of-00003', 'atl_june_eval-00002-of-00003', 'atl_june_train-00000-of-00025', 'atl_june_train-00001-of-00025', 'atl_june_train-00002-of-00025', 'atl_june_train-00003-of-00025', 'atl_june_train-00004-of-00025', 'atl_june_train-00005-of-00025', 'atl_june_train-00006-of-00025', 'atl_june_train-00007-of-00025', 'atl_june_train-00008-of-00025', 'atl_june_train-00009-of-00025', 'atl_june_train-00010-of-00025', 'atl_june_train-00011-of-00025', 'atl_june_train-00012-of-00025', 'atl_june_train-00013-of-00025', 'atl_june_train-00014-of-00025', 'atl_june_train-00015-of-00025', 'atl_june_train-00016-of-00025', 'atl_june_train-00017-of-00025', 'atl_june_train-00018-of-00025', 'atl_june_train-00019-of-00025', 'atl_june_train-00020-of-00025', 'atl_june_train-00021-of-00025', 'atl_june_train-00022-of-00025', 'atl_june_train-00023-of-00025', 'atl_june_train-00024-of-00025'].\n"
     ]
    }
   ],
   "source": [
    "res = !ls $localdatadir\n",
    "print(\"{} contains {}.\".format(localdatadir, res if len(res) > 0 else \"no files\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Have a look into the first training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 /tmp/atl_june/sample/data/atl_june_train-00000-of-00025\n"
     ]
    }
   ],
   "source": [
    "a_training_file = !ls $localdatadir/atl_june_train-00000-of-*\n",
    "a_training_file = a_training_file[0]\n",
    "!wc -l $a_training_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0,42.21,-83.35,0.10895884,5,12,33.63,-84.42,0.5638371,0.8007947,0.11696716,0.28985506,0.59663844,0.4784946,1.0,0.010901089,0.5658915\n",
      "28.0,26.07,-80.15,0.19612591,5,20,33.63,-84.42,0.19254656,0.83515894,0.113756314,0.6249999,0.59663844,0.4784946,1.0,0.0046004597,0.5658915\n",
      "-11.0,26.53,-81.75,0.11622277,7,13,33.63,-84.42,0.2031286,0.81797683,0.09888748,0.57971007,0.60924363,0.44623655,0.515625,0.0062006195,0.60465115\n",
      "-14.0,39.29,-94.71,0.125908,7,12,33.63,-84.42,0.49666438,0.67880154,0.13878365,0.6340579,0.60924363,0.29032257,0.515625,0.009200919,0.60465115\n"
     ]
    }
   ],
   "source": [
    "!head -4 $a_training_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_HOD</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>42.21</td>\n",
       "      <td>-83.35</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.563837</td>\n",
       "      <td>0.800795</td>\n",
       "      <td>0.116967</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.596638</td>\n",
       "      <td>0.478495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>0.565891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>26.07</td>\n",
       "      <td>-80.15</td>\n",
       "      <td>0.196126</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.192547</td>\n",
       "      <td>0.835159</td>\n",
       "      <td>0.113756</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.596638</td>\n",
       "      <td>0.478495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.565891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>26.53</td>\n",
       "      <td>-81.75</td>\n",
       "      <td>0.116223</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.203129</td>\n",
       "      <td>0.817977</td>\n",
       "      <td>0.098887</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.609244</td>\n",
       "      <td>0.446237</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARR_DELAY  ARR_LAT  ARR_LON  DEP_DELAY  DEP_DOW  DEP_HOD  DEP_LAT  DEP_LON  \\\n",
       "0       -3.0    42.21   -83.35   0.108959        5       12    33.63   -84.42   \n",
       "1       28.0    26.07   -80.15   0.196126        5       20    33.63   -84.42   \n",
       "2      -11.0    26.53   -81.75   0.116223        7       13    33.63   -84.42   \n",
       "\n",
       "   DIFF_LAT  DIFF_LON  DISTANCE  MEAN_TEMP_ARR  MEAN_TEMP_DEP  MEAN_VIS_ARR  \\\n",
       "0  0.563837  0.800795  0.116967       0.289855       0.596638      0.478495   \n",
       "1  0.192547  0.835159  0.113756       0.625000       0.596638      0.478495   \n",
       "2  0.203129  0.817977  0.098887       0.579710       0.609244      0.446237   \n",
       "\n",
       "   MEAN_VIS_DEP  WND_SPD_ARR  WND_SPD_DEP  \n",
       "0      1.000000     0.010901     0.565891  \n",
       "1      1.000000     0.004600     0.565891  \n",
       "2      0.515625     0.006201     0.604651  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = pd.read_csv(a_training_file, names=ORDERED_TRAINING_COLUMNS)\n",
    "t1[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Second stage: Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'data': 'gs://going-tfx/full/data',\n",
       "  'metadata': 'gs://going-tfx/full/metadata',\n",
       "  'tmp': 'gs://going-tfx/full/tmp'},\n",
       " {'data': '/tmp/atl_june/full/data',\n",
       "  'metadata': '/tmp/atl_june/full/metadata',\n",
       "  'tmp': '/tmp/atl_june/full/tmp'})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdirs = directories('gs', 'full')\n",
    "localdirs = directories('local', 'full')\n",
    "gsdirs, localdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/atl_june/full/tmp contains 0 files.\n",
      "/tmp/atl_june/full/data contains 0 files.\n",
      "/tmp/atl_june/full/metadata contains 0 files.\n",
      "gs://going-tfx/full/tmp: CommandException: One or more URLs matched no objects.\n",
      "gs://going-tfx/full/data: CommandException: One or more URLs matched no objects.\n",
      "gs://going-tfx/full/metadata: CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "cleanup('full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### This executes in dataflow and takes some 12 - 20 minutes\n",
    "But if you watch the graph in the dataflow console, you see that the job lives until the VM is shutdown. The files may be available a bit earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_pipeline_prod (\n",
    "    'gs', 'full',\n",
    "    preprocessing_fn=pre_processor, \n",
    "    output_columns=ORDERED_TRAINING_COLUMNS, \n",
    "    fractions=[90, 5, 5], \n",
    "    sample_rate=1.0, \n",
    "    prefix='atl_june',\n",
    "    runner = 'DataflowRunner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine and retrieve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying first 6 of gs://going-tfx/full/data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gs://going-tfx/full/data/atl_june_eval-00000-of-00001',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00000-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00001-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00002-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00003-of-00005',\n",
       " 'gs://going-tfx/full/data/atl_june_train-00004-of-00005']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdatadir = gsdirs['data']\n",
    "res = !gsutil ls $gsdatadir\n",
    "print(\"Displaying first 6 of {}.\".format(gsdatadir))\n",
    "res[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "localdatadir = localdirs['data']\n",
    "!mkdir -p $localdatadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = !gsutil -m cp $gsdatadir/*eval* $localdatadir\n",
    "_ = !gsutil -m cp $gsdatadir/*train* $localdatadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/atl_june/full/data contains ['atl_june_eval-00000-of-00001', 'atl_june_train-00000-of-00005', 'atl_june_train-00001-of-00005', 'atl_june_train-00002-of-00005', 'atl_june_train-00003-of-00005', 'atl_june_train-00004-of-00005'].\n"
     ]
    }
   ],
   "source": [
    "res = !ls $localdatadir\n",
    "print(\"{} contains {}.\".format(localdatadir, res if len(res) > 0 else \"no files\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Have a look into the first training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26137 /tmp/atl_june/full/data/atl_june_train-00000-of-00005\n"
     ]
    }
   ],
   "source": [
    "a_training_file = !ls $localdatadir/atl_june_train-00000-of-*\n",
    "a_training_file = a_training_file[0]\n",
    "!wc -l $a_training_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,9,33.63,-84.42,0.6932772,0.875,0.21705428,0.052527256,34.99,-78.88,-1.0,0.60439557,0.0075052534,0.0056005595,0.3977456,0.84879726,0.056765903\n"
     ]
    }
   ],
   "source": [
    "!head -1 $a_training_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_DOW</th>\n",
       "      <th>DEP_HOD</th>\n",
       "      <th>DEP_LAT</th>\n",
       "      <th>DEP_LON</th>\n",
       "      <th>MEAN_TEMP_DEP</th>\n",
       "      <th>MEAN_VIS_DEP</th>\n",
       "      <th>WND_SPD_DEP</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_LAT</th>\n",
       "      <th>ARR_LON</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>MEAN_TEMP_ARR</th>\n",
       "      <th>MEAN_VIS_ARR</th>\n",
       "      <th>WND_SPD_ARR</th>\n",
       "      <th>DIFF_LAT</th>\n",
       "      <th>DIFF_LON</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.693277</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.217054</td>\n",
       "      <td>0.052527</td>\n",
       "      <td>34.99</td>\n",
       "      <td>-78.88</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.397746</td>\n",
       "      <td>0.848797</td>\n",
       "      <td>0.056766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.693277</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.217054</td>\n",
       "      <td>0.051536</td>\n",
       "      <td>31.53</td>\n",
       "      <td>-84.19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.318150</td>\n",
       "      <td>0.791774</td>\n",
       "      <td>0.015087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-84.42</td>\n",
       "      <td>0.693277</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.217054</td>\n",
       "      <td>0.047572</td>\n",
       "      <td>35.21</td>\n",
       "      <td>-80.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.402807</td>\n",
       "      <td>0.826675</td>\n",
       "      <td>0.033353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEP_DOW  DEP_HOD  DEP_LAT  DEP_LON  MEAN_TEMP_DEP  MEAN_VIS_DEP  \\\n",
       "0        1        9    33.63   -84.42       0.693277         0.875   \n",
       "1        1       20    33.63   -84.42       0.693277         0.875   \n",
       "2        1       11    33.63   -84.42       0.693277         0.875   \n",
       "\n",
       "   WND_SPD_DEP  DEP_DELAY  ARR_LAT  ARR_LON  ARR_DELAY  MEAN_TEMP_ARR  \\\n",
       "0     0.217054   0.052527    34.99   -78.88       -1.0       0.604396   \n",
       "1     0.217054   0.051536    31.53   -84.19        8.0       0.604396   \n",
       "2     0.217054   0.047572    35.21   -80.94        0.0       0.604396   \n",
       "\n",
       "   MEAN_VIS_ARR  WND_SPD_ARR  DIFF_LAT  DIFF_LON  DISTANCE  \n",
       "0      0.007505     0.005601  0.397746  0.848797  0.056766  \n",
       "1      0.007405     0.002500  0.318150  0.791774  0.015087  \n",
       "2      0.008006     0.004900  0.402807  0.826675  0.033353  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = pd.read_csv(a_training_file, names=ORDERED_TRAINING_COLUMNS)\n",
    "t1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
