{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Models With Synthetic Data\n",
    "The advantage of synthetic data is that we know the prior or ground truth and we know exactly how concealed it is. That helps us to determine with certainty that an algorithm is per se capable of discovering the ground truth. If an algorithm fails on the easy task of learning from synthetic data, then it won't be good in real life. The opposite, unfortunately, is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "from tools import print_progress, array_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Noisy Samples From A Well-Known Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a*x+b\n",
    "def make_lin(a, b, rnd):\n",
    "    def _f_a(x):\n",
    "        mu = a*x + b\n",
    "        return rnd(mu)\n",
    "    return _f_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Two linear but noisy signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = make_lin(2, 1, lambda mu: np.random.normal(loc=mu, scale=1.0))\n",
    "f_b = make_lin(-.5, -1.5, lambda mu: np.random.normal(loc=mu, scale=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A look at one of the signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE/xJREFUeJzt3X+wX3V95/HnCxIaoVSU3NI0N7s3VIYdtO3KBmqHrctKrQg00I7LhrEWEZvubLbFtTM2sJ3S/cMZOtv1R9eWbRao0FJSRCxspbSRYt3OLOBNxKKAJQvB3AjmFquIipH43j++J3gbTrjfe+/3e8/3kudj5s495/M953tek4G8cn6nqpAk6WBHdB1AkjSaLAhJUisLQpLUyoKQJLWyICRJrSwISVIrC0KS1MqCkCS1siAkSa2WdR1gIVauXFkTExNdx5CkJWX79u3/UFVjsy23pAtiYmKCycnJrmNI0pKS5PF+lvMQkySplQUhSWplQUiSWi3pcxCS1JXvfOc7TE1N8eyzz3Yd5ZBWrFjB+Pg4y5cvn9f6FoQkzcPU1BTHHnssExMTJOk6zgtUFU899RRTU1OsXbt2Xt/hISZJmodnn32W448/fiTLASAJxx9//IL2cCwISZqnUS2HAxaaz4KQJLXyHIQkDcDE5o8P9Pt2XXXurMvceeedXHbZZezfv593vvOdbN68eaAZLAjpEBb6P3w//4NL87V//342bdrEtm3bGB8f57TTTmP9+vWccsopA9uGh5gkaQm67777eNWrXsWJJ57IUUcdxYYNG7jtttsGug0LQpKWoD179rBmzZrn58fHx9mzZ89At2FBSJJaWRCStAStXr2a3bt3Pz8/NTXF6tWrB7qNoRVEkuuS7E3yuZbPfi1JJVnZzCfJ7ybZmeTvkpw6rFyS9FJw2mmn8cgjj/DYY4+xb98+tm7dyvr16we6jWFexfRh4EPADTMHk6wBfgb44ozhNwMnNT8/AVzd/JakJWGxr1pbtmwZH/rQh3jTm97E/v37ecc73sGrX/3qwW5joN82Q1V9KslEy0fvB94DzDzdfj5wQ1UVcE+S45KsqqonhpVPkpa6c845h3POOWdo37+o5yCSnA/sqarPHvTRamD3jPmpZqztOzYmmUwyOT09PaSkkqRFK4gkRwNXAL+5kO+pqi1Vta6q1o2NzfpKVUnSPC3mHsSPAGuBzybZBYwDO5L8ELAHWDNj2fFmTJJGVu+o+OhaaL5FK4iqeqCqfrCqJqpqgt5hpFOr6kngduAXm6uZXgd8zfMPkkbZihUreOqpp0a2JA68D2LFihXz/o6hnaROchNwJrAyyRRwZVVde4jF7wDOAXYC3wQuGVYuHV4G/QC1xdq2z3EafePj40xNTTHK50IPvFFuvoZ5FdNFs3w+MWO6gE3DyiJJg7Z8+fJ5v6ltqfBOaklSKwtCktTKgpAktbIgJEmtLAhJUisLQpLUyoKQJLWyICRJrSwISVIrC0KS1GqYb5STNE8+x0mjwD0ISVIrC0KS1MqCkCS1siAkSa0sCElSKwtCktTKgpAktbIgJEmthlYQSa5LsjfJ52aM/bckDyf5uyQfS3LcjM8uT7IzyReSvGlYuSRJ/RnmHsSHgbMPGtsGvKaqfgz4e+BygCSnABuAVzfr/H6SI4eYTZI0i6EVRFV9CvjKQWN/VVXPNbP3AOPN9PnA1qr6dlU9BuwETh9WNknS7Lo8B/EO4C+a6dXA7hmfTTVjkqSOdFIQSf4L8Bxw4zzW3ZhkMsnk9PT04MNJkoAOCiLJ24HzgLdWVTXDe4A1MxYbb8ZeoKq2VNW6qlo3NjY21KySdDhb1IJIcjbwHmB9VX1zxke3AxuSfF+StcBJwH2LmU2S9E8N7X0QSW4CzgRWJpkCrqR31dL3AduSANxTVf+hqj6f5GbgQXqHnjZV1f5hZZMkzW5oBVFVF7UMX/siy78XeO+w8kiS5sY7qSVJrSwISVIrC0KS1MqCkCS1siAkSa0sCElSKwtCktTKgpAktbIgJEmtLAhJUisLQpLUyoKQJLWyICRJrSwISVIrC0KS1MqCkCS1siAkSa0sCElSKwtCktRqaO+kTnIdcB6wt6pe04y9EvhTYALYBVxYVf+YJMAHgXOAbwJvr6odw8qmpWVi88e7jiAdloa5B/Fh4OyDxjYDd1XVScBdzTzAm4GTmp+NwNVDzCVJ6sPQCqKqPgV85aDh84Hrm+nrgQtmjN9QPfcAxyVZNaxskqTZLfY5iBOq6olm+knghGZ6NbB7xnJTzZgkqSOdnaSuqgJqrusl2ZhkMsnk9PT0EJJJkmDxC+LLBw4dNb/3NuN7gDUzlhtvxl6gqrZU1bqqWjc2NjbUsJJ0OFvsgrgduLiZvhi4bcb4L6bndcDXZhyKkiR1YJiXud4EnAmsTDIFXAlcBdyc5FLgceDCZvE76F3iupPeZa6XDCuXJKk/QyuIqrroEB+d1bJsAZuGlUWSNHfeSS1JamVBSJJaWRCSpFYWhCSpVV8FkeRHhx1EkjRa+t2D+P0k9yX5j0lePtREkqSR0FdBVNVPAW+ld7fz9iR/kuSNQ00mSepU3+cgquoR4DeAXwf+DfC7SR5O8vPDCidJ6k5fN8ol+TF6dzefC2wDfraqdiT5YeD/ArcOL6KkuVjIC5Z2XXXuAJNoqev3Tur/AVwDXFFV3zowWFVfSvIbQ0kmSepUvwVxLvCtqtoPkOQIYEVVfbOq/mho6SRJnen3HMQngJfNmD+6GZMkvUT1WxArquqZAzPN9NHDiSRJGgX9FsQ3kpx6YCbJvwK+9SLLS5KWuH7PQbwL+EiSLwEBfgj490NLJUnqXF8FUVWfTvIvgJOboS9U1XeGF0uS1LW5vDDoNGCiWefUJFTVDUNJJUnqXL83yv0R8CPA/cD+ZrgAC0KSXqL63YNYB5zSvBpUknQY6Pcqps/ROzEtSTpM9LsHsRJ4MMl9wLcPDFbV+vlsNMl/Bt5J7zDVA/Se87QK2AocD2wH3lZV++bz/ZKkheu3IH5rUBtMshr4VXqHrL6V5GZgA3AO8P6q2prkfwKXAlcParuSpLnp930QfwPsApY3058Gdixgu8uAlyVZRu+O7CeANwC3NJ9fD1ywgO+XJC1Qv68c/SV6f3n/QTO0Gviz+WywqvYAvwN8kV4xfI3eIaWvVtVzzWJTzTbasmxMMplkcnp6ej4RJEl96Pck9SbgDOBpeP7lQT84nw0meQVwPrAW+GHgGODsftevqi1Vta6q1o2Njc0ngiSpD/0WxLdnnjBuDg3N95LXnwYeq6rp5m7sW+mVz3HN9wKMA3vm+f2SpAHotyD+JskV9M4bvBH4CPC/57nNLwKvS3J0kgBnAQ8CdwNvaZa5GLhtnt8vSRqAfgtiMzBN75LUXwbuoPd+6jmrqnvpnc/Y0XzfEcAWeu+6fneSnfQudb12Pt8vSRqMfh/W913gfzU/C1ZVVwJXHjT8KHD6IL5fkrRw/T6L6TFazjlU1YkDTyRJGglzeRbTASuAfwe8cvBxJEmjot8b5Z6a8bOnqj4AnDvkbJKkDvV7iOnUGbNH0NujmMu7JCRJS0y/f8n/9xnTz9F77MaFA08jSRoZ/V7F9G+HHUSSNFr6PcT07hf7vKreN5g4kqRRMZermE4Dbm/mfxa4D3hkGKEkSd3rtyDGgVOr6usASX4L+HhV/cKwgkmSutXvozZOAGa+3W1fMyZJeonqdw/iBuC+JB9r5i+g91IfSdJLVL9XMb03yV8AP9UMXVJVnxleLElS1/o9xAS9V4M+XVUfBKaSrB1SJknSCOj3laNX0nsc9+XN0HLgj4cVSpLUvX73IH4OWA98A6CqvgQcO6xQkqTu9VsQ+6qqaB75neSY4UWSJI2Cfgvi5iR/QO+90b8EfIIBvTxIkjSa+r2K6Xead1E/DZwM/GZVbRtqMklSp2YtiCRHAp9oHthnKUjSYWLWQ0xVtR/4bpKXD2qjSY5LckuSh5M8lOQnk7wyybYkjzS/XzGo7UmS5q7fO6mfAR5Iso3mSiaAqvrVeW73g8CdVfWWJEfRu8fiCuCuqroqyWZgM71LayVJHei3IG5tfhas2RN5PfB2gKraB+xLcj5wZrPY9cAnsSAkqTMvWhBJ/llVfbGqBvncpbXANPCHSX4c2A5cBpxQVU80yzyJDwOUpE7Ndg7izw5MJPnogLa5DDgVuLqqXkvvkNXmmQvMvOfiYEk2JplMMjk9PT2gSJKkg81WEJkxfeKAtjkFTFXVvc38LfQK48tJVgE0v/e2rVxVW6pqXVWtGxsbG1AkSdLBZiuIOsT0vFXVk8DuJCc3Q2cBD9J7W93FzdjFwG2D2J4kaX5mO0n940meprcn8bJmmma+quoH5rndXwFubK5gehS4hF5Z3ZzkUuBx4MJ5frekeZrY/PF5r7vrqnMHmESj4EULoqqOHMZGq+p+eu+5PthZw9ieJGnu5vI+CEnSYcSCkCS1siAkSa0sCElSKwtCktSq32cxSQuykMsnJXXDPQhJUisLQpLUyoKQJLWyICRJrSwISVIrC0KS1MqCkCS1siAkSa0sCElSKwtCktTKgpAktbIgJEmtLAhJUqvOCiLJkUk+k+TPm/m1Se5NsjPJnyY5qqtskqRu9yAuAx6aMf/bwPur6lXAPwKXdpJKkgR0VBBJxoFzgWua+QBvAG5pFrkeuKCLbJKknq5eGPQB4D3Asc388cBXq+q5Zn4KWN1FMEnzs9CXQu266twBJdGgLPoeRJLzgL1VtX2e629MMplkcnp6esDpJEkHdHGI6QxgfZJdwFZ6h5Y+CByX5MAezTiwp23lqtpSVeuqat3Y2Nhi5JWkw9KiF0RVXV5V41U1AWwA/rqq3grcDbylWexi4LbFziZJ+p5Rug/i14F3J9lJ75zEtR3nkaTDWlcnqQGoqk8Cn2ymHwVO7zKPJOl7RmkPQpI0QiwISVIrC0KS1MqCkCS1siAkSa0sCElSKwtCktTKgpAktbIgJEmtLAhJUisLQpLUyoKQJLXq9GF9Wly+8UvSXLgHIUlqZUFIklpZEJKkVhaEJKmVBSFJauVVTOrbQq+CkrS0uAchSWq16AWRZE2Su5M8mOTzSS5rxl+ZZFuSR5rfr1jsbJKk7+liD+I54Neq6hTgdcCmJKcAm4G7quok4K5mXpLUkUUviKp6oqp2NNNfBx4CVgPnA9c3i10PXLDY2SRJ39PpOYgkE8BrgXuBE6rqieajJ4ETDrHOxiSTSSanp6cXJackHY46K4gk3w98FHhXVT0987OqKqDa1quqLVW1rqrWjY2NLUJSSTo8dVIQSZbTK4cbq+rWZvjLSVY1n68C9naRTZLUs+j3QSQJcC3wUFW9b8ZHtwMXA1c1v29b7GySurOQ+2x80vBwdHGj3BnA24AHktzfjF1BrxhuTnIp8DhwYQfZJEmNRS+IqvpbIIf4+KzFzCJJOjTvpJYktbIgJEmtLAhJUisLQpLUyoKQJLWyICRJrSwISVIr3yi3xPhWN0mLxT0ISVIrC0KS1MpDTJKWPB/0NxzuQUiSWlkQkqRWFoQkqZXnIDrgpaqSlgL3ICRJrdyDkHRY8wqoQ3MPQpLUyoKQJLUauYJIcnaSLyTZmWRz13kk6XA1UucgkhwJ/B7wRmAK+HSS26vqwW6TSdLgjfr5j5EqCOB0YGdVPQqQZCtwPjDwgvBSU0l6caN2iGk1sHvG/FQzJklaZKO2BzGrJBuBjc3sM0m+0GWeWawE/qHrEH1YCjmXQkYw5yCNfMb8NtBRzmbbczEz5z/vZ4VRK4g9wJoZ8+PN2POqaguwZTFDzVeSyapa13WO2SyFnEshI5hzkJZCRnhp5xy1Q0yfBk5KsjbJUcAG4PaOM0nSYWmk9iCq6rkk/wn4S+BI4Lqq+nzHsSTpsDRSBQFQVXcAd3SdY0CWxKEwlkbOpZARzDlISyEjvIRzpqqGEUSStMSN2jkISdKIsCCGYKk8LiTJdUn2Jvlc11kOJcmaJHcneTDJ55Nc1nWmNklWJLkvyWebnP+160yHkuTIJJ9J8uddZzmUJLuSPJDk/iSTXec5lCTHJbklycNJHkryk11nminJyc2f4YGfp5O8q+/1PcQ0WM3jQv6eGY8LAS4axceFJHk98AxwQ1W9pus8bZKsAlZV1Y4kxwLbgQtG7c8zSYBjquqZJMuBvwUuq6p7Oo72AkneDawDfqCqzus6T5sku4B1VTXa90Ek1wP/p6quaa68PLqqvtp1rjbN3017gJ+oqsf7Wcc9iMF7/nEhVbUPOPC4kJFTVZ8CvtJ1jhdTVU9U1Y5m+uvAQ4zg3fXV80wzu7z5Gbl/fSUZB84Fruk6y1KX5OXA64FrAapq36iWQ+Ms4P/1Ww5gQQyDjwsZkiQTwGuBe7tN0q45dHM/sBfYVlWjmPMDwHuA73YdZBYF/FWS7c3TE0bRWmAa+MPmkN01SY7pOtSL2ADcNJcVLAgtCUm+H/go8K6qerrrPG2qan9V/Ut6TwA4PclIHbZLch6wt6q2d52lD/+6qk4F3gxsag6HjpplwKnA1VX1WuAbwEiec2wOf60HPjKX9SyIwZv1cSGam+aY/keBG6vq1q7zzKY5zHA3cHbXWQ5yBrC+Ob6/FXhDkj/uNlK7qtrT/N4LfIzeodtRMwVMzdhTvIVeYYyiNwM7qurLc1nJghg8HxcyQM3J32uBh6rqfV3nOZQkY0mOa6ZfRu8ihYe7TfVPVdXlVTVeVRP0/rv866r6hY5jvUCSY5oLEmgO2fwMMHJX2lXVk8DuJCc3Q2cxhFcTDMhFzPHwEozgndRL3VJ6XEiSm4AzgZVJpoArq+rablO9wBnA24AHmuP7AFc0d9yPklXA9c2VIkcAN1fVyF5GOuJOAD7W+7cBy4A/qao7u410SL8C3Nj8Y/BR4JKO87xAU7JvBH55zut6maskqY2HmCRJrSwISVIrC0KS1MqCkCS1siAkSa0sCElSKwtCktTKgpAktfr/W+uLriYnSPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([f_a(1) for i in range(1000)])\n",
    "df.plot.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we create a data set/frame representing $f_a(x)+f_b(y)$ as a random variable that depends on random variables $x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v1(size):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'f': f_data, 'p': f_perf})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, this is equivalent to saying that the ground truth is:\n",
    "\n",
    "$$ f(x, y) = 2x - \\frac{1}{2} y - \\frac{1}{2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.212584</td>\n",
       "      <td>-7.646901</td>\n",
       "      <td>-4.448781</td>\n",
       "      <td>-3.501323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.482974</td>\n",
       "      <td>7.485242</td>\n",
       "      <td>4.366242</td>\n",
       "      <td>1.494483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.321251</td>\n",
       "      <td>-1.696379</td>\n",
       "      <td>0.010224</td>\n",
       "      <td>2.433653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.904092</td>\n",
       "      <td>10.152548</td>\n",
       "      <td>4.517467</td>\n",
       "      <td>-3.235226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.184109</td>\n",
       "      <td>9.326299</td>\n",
       "      <td>4.134234</td>\n",
       "      <td>-3.115663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y\n",
       "0  -7.212584  -7.646901 -4.448781 -3.501323\n",
       "1   6.482974   7.485242  4.366242  1.494483\n",
       "2  -2.321251  -1.696379  0.010224  2.433653\n",
       "3  10.904092  10.152548  4.517467 -3.235226\n",
       "4   9.184109   9.326299  4.134234 -3.115663"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_data_frame_v1(NUM_RECORDS)\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Linear Regressor From Scratch With Tensorflow\n",
    "Let's train a self-made tensorflow linear regressor with the synthetic data to see whether it finds the coefficients above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Was already closed or didn't exist. That's fine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    print(\"OK. Was already closed or didn't exist. That's fine.\")\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating The Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, x_dim, lr):\n",
    "\n",
    "        # Variables for the parameters: weights M and bias b\n",
    "        self.M = tf.Variable(tf.zeros(shape=(1, x_dim)))\n",
    "        self.b = tf.Variable(0.)\n",
    "\n",
    "        # Placeholders for x and labels\n",
    "        self.x = tf.placeholder(shape=(x_dim,None), dtype=tf.float32)\n",
    "        self.lbls = tf.placeholder(shape=(1,None), dtype=tf.float32)\n",
    "\n",
    "        # The prediction and the distance (loss)\n",
    "        self.f = tf.matmul(self.M, self.x) + self.b\n",
    "        self.d = tf.losses.mean_squared_error(self.lbls, self.f)\n",
    "\n",
    "        # The gradients\n",
    "        self.nM = tf.gradients(self.d, self.M)\n",
    "        self.nb = tf.gradients(self.d, self.b)\n",
    "\n",
    "        # The optimizers\n",
    "        self.aM = tf.assign_add( self.M, tf.multiply(self.nM[0],-lr))\n",
    "        self.ab = tf.assign_add( self.b, tf.multiply(self.nb[0], -lr))\n",
    "\n",
    "        # The initializer\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def train(self, sess, x_data, labels_data, num_steps):        \n",
    "        sess.run(self.init)\n",
    "        for i in range(num_steps):\n",
    "            _, dist, _, _, _, _ = sess.run([self.f, self.d, self.nM, self.nb, self.aM, self.ab], \n",
    "                                           feed_dict = {self.x: x_data, self.lbls: labels_data})\n",
    "            print_progress(\"- Loss: {}\", dist)\n",
    "        return dist\n",
    "    \n",
    "    def predict(self, sess, x_data):\n",
    "        pred = sess.run(self.f, feed_dict={self.x: x_data})\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Perform The Training And Examine The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [list(df_train['x']), list(df_train['y'])]\n",
    "lbls_data = [list(df_train['f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.01935839653"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0193584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = Linear(x_dim=2, lr=0.01)\n",
    "linear1.train(sess, input_data, lbls_data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the parameters to be close to $2, -0.5, -0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.010115  , -0.50174767]], dtype=float32), -0.48766184]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([linear1.M, linear1.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now the tensor f represents the hypothesis. Let's evaluate it with some fresh test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = create_data_frame_v1(size=10000)\n",
    "test_data = [list(df_test['x']), list(df_test['y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear1.predict(sess=sess, x_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.785405</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>0.108922</td>\n",
       "      <td>1.562874</td>\n",
       "      <td>-1.052884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.988941</td>\n",
       "      <td>-2.660188</td>\n",
       "      <td>-1.344718</td>\n",
       "      <td>-1.058495</td>\n",
       "      <td>-2.659602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.377409</td>\n",
       "      <td>-4.578748</td>\n",
       "      <td>-1.006018</td>\n",
       "      <td>4.133424</td>\n",
       "      <td>-4.583809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.406679</td>\n",
       "      <td>9.873655</td>\n",
       "      <td>4.431079</td>\n",
       "      <td>-3.022996</td>\n",
       "      <td>9.936096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.250212</td>\n",
       "      <td>-3.087043</td>\n",
       "      <td>-0.424141</td>\n",
       "      <td>3.477524</td>\n",
       "      <td>-3.085073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.511145</td>\n",
       "      <td>6.415450</td>\n",
       "      <td>2.491810</td>\n",
       "      <td>-3.863660</td>\n",
       "      <td>6.459745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-6.665805</td>\n",
       "      <td>-6.964906</td>\n",
       "      <td>-3.560071</td>\n",
       "      <td>-1.310474</td>\n",
       "      <td>-6.986287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.475980</td>\n",
       "      <td>9.616496</td>\n",
       "      <td>4.037045</td>\n",
       "      <td>-4.084812</td>\n",
       "      <td>9.676807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.172631</td>\n",
       "      <td>-9.248996</td>\n",
       "      <td>-4.065293</td>\n",
       "      <td>1.236819</td>\n",
       "      <td>-9.279940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.570288</td>\n",
       "      <td>7.719288</td>\n",
       "      <td>3.646667</td>\n",
       "      <td>-1.851907</td>\n",
       "      <td>7.771748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f         p         x         y  predictions\n",
       "0  -0.785405 -1.063593  0.108922  1.562874    -1.052884\n",
       "1  -3.988941 -2.660188 -1.344718 -1.058495    -2.659602\n",
       "2  -4.377409 -4.578748 -1.006018  4.133424    -4.583809\n",
       "3  13.406679  9.873655  4.431079 -3.022996     9.936096\n",
       "4  -3.250212 -3.087043 -0.424141  3.477524    -3.085073\n",
       "5   2.511145  6.415450  2.491810 -3.863660     6.459745\n",
       "6  -6.665805 -6.964906 -3.560071 -1.310474    -6.986287\n",
       "7   9.475980  9.616496  4.037045 -4.084812     9.676807\n",
       "8  -8.172631 -9.248996 -4.065293  1.236819    -9.279940\n",
       "9   6.570288  7.719288  3.646667 -1.851907     7.771748"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'] = predictions[0]\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see without surprise that the predictions are typically closer to the ground truth than to the noisy signal. This means we have enough data to average out the noise and reveal the ground truth. A look at the distribution of the errors reveals pure noise around 0. That's typically a good sign that our network has understood the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test['f'] - df_test['predictions']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensorflow LinearRegressor Estimator\n",
    "Now we'll reproduce this with the high-level estimator API. Surprisingly, the calculations here take much longer than in the basic approach above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(df_train, shuffle=True, num_epochs=100, y=df_train['f'], batch_size=NUM_RECORDS)\n",
    "feature_columns = [\n",
    "    fc.numeric_column('x', dtype=tf.float32),\n",
    "    fc.numeric_column('y', dtype=tf.float32)\n",
    "]\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpMmRoCE\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8a2f753e50>, '_model_dir': '/tmp/tmpMmRoCE', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 5, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, config=config )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Perform the training on the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/wgiersche/workspace/jupyter/venv2/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpMmRoCE/model.ckpt.\n",
      "INFO:tensorflow:loss = 386943.2, step = 1\n",
      "INFO:tensorflow:global_step/sec: 21.3454\n",
      "INFO:tensorflow:loss = 187972.67, step = 6 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5462\n",
      "INFO:tensorflow:loss = 126301.125, step = 11 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2797\n",
      "INFO:tensorflow:loss = 91265.88, step = 16 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2811\n",
      "INFO:tensorflow:loss = 69757.305, step = 21 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8667\n",
      "INFO:tensorflow:loss = 55113.844, step = 26 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9469\n",
      "INFO:tensorflow:loss = 44679.63, step = 31 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0604\n",
      "INFO:tensorflow:loss = 37764.793, step = 36 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6056\n",
      "INFO:tensorflow:loss = 32934.387, step = 41 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6681\n",
      "INFO:tensorflow:loss = 29526.287, step = 46 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2415\n",
      "INFO:tensorflow:loss = 26950.156, step = 51 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8477\n",
      "INFO:tensorflow:loss = 25094.55, step = 56 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1079\n",
      "INFO:tensorflow:loss = 23673.729, step = 61 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0781\n",
      "INFO:tensorflow:loss = 22635.195, step = 66 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3508\n",
      "INFO:tensorflow:loss = 22035.543, step = 71 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4337\n",
      "INFO:tensorflow:loss = 21619.848, step = 76 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6805\n",
      "INFO:tensorflow:loss = 21232.613, step = 81 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.313\n",
      "INFO:tensorflow:loss = 20969.492, step = 86 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5265\n",
      "INFO:tensorflow:loss = 20773.982, step = 91 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7049\n",
      "INFO:tensorflow:loss = 20590.607, step = 96 (0.202 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpMmRoCE/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20433.008.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f8a2f76d8d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.train(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparing The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_test = tf.estimator.inputs.pandas_input_fn(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = regressor.predict(input_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpMmRoCE/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pred_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.785405</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>0.108922</td>\n",
       "      <td>1.562874</td>\n",
       "      <td>-1.052884</td>\n",
       "      <td>-1.060937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.988941</td>\n",
       "      <td>-2.660188</td>\n",
       "      <td>-1.344718</td>\n",
       "      <td>-1.058495</td>\n",
       "      <td>-2.659602</td>\n",
       "      <td>-2.586835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.377409</td>\n",
       "      <td>-4.578748</td>\n",
       "      <td>-1.006018</td>\n",
       "      <td>4.133424</td>\n",
       "      <td>-4.583809</td>\n",
       "      <td>-4.526997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.406679</td>\n",
       "      <td>9.873655</td>\n",
       "      <td>4.431079</td>\n",
       "      <td>-3.022996</td>\n",
       "      <td>9.936096</td>\n",
       "      <td>9.679969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.250212</td>\n",
       "      <td>-3.087043</td>\n",
       "      <td>-0.424141</td>\n",
       "      <td>3.477524</td>\n",
       "      <td>-3.085073</td>\n",
       "      <td>-3.061683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.511145</td>\n",
       "      <td>6.415450</td>\n",
       "      <td>2.491810</td>\n",
       "      <td>-3.863660</td>\n",
       "      <td>6.459745</td>\n",
       "      <td>6.313105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-6.665805</td>\n",
       "      <td>-6.964906</td>\n",
       "      <td>-3.560071</td>\n",
       "      <td>-1.310474</td>\n",
       "      <td>-6.986287</td>\n",
       "      <td>-6.788001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.475980</td>\n",
       "      <td>9.616496</td>\n",
       "      <td>4.037045</td>\n",
       "      <td>-4.084812</td>\n",
       "      <td>9.676807</td>\n",
       "      <td>9.442366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.172631</td>\n",
       "      <td>-9.248996</td>\n",
       "      <td>-4.065293</td>\n",
       "      <td>1.236819</td>\n",
       "      <td>-9.279940</td>\n",
       "      <td>-9.051394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.570288</td>\n",
       "      <td>7.719288</td>\n",
       "      <td>3.646667</td>\n",
       "      <td>-1.851907</td>\n",
       "      <td>7.771748</td>\n",
       "      <td>7.560855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f         p         x         y  predictions  pred_estimator\n",
       "0  -0.785405 -1.063593  0.108922  1.562874    -1.052884       -1.060937\n",
       "1  -3.988941 -2.660188 -1.344718 -1.058495    -2.659602       -2.586835\n",
       "2  -4.377409 -4.578748 -1.006018  4.133424    -4.583809       -4.526997\n",
       "3  13.406679  9.873655  4.431079 -3.022996     9.936096        9.679969\n",
       "4  -3.250212 -3.087043 -0.424141  3.477524    -3.085073       -3.061683\n",
       "5   2.511145  6.415450  2.491810 -3.863660     6.459745        6.313105\n",
       "6  -6.665805 -6.964906 -3.560071 -1.310474    -6.986287       -6.788001\n",
       "7   9.475980  9.616496  4.037045 -4.084812     9.676807        9.442366\n",
       "8  -8.172631 -9.248996 -4.065293  1.236819    -9.279940       -9.051394\n",
       "9   6.570288  7.719288  3.646667 -1.851907     7.771748        7.560855"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_estimator = [f['predictions'][0] for f in generator]\n",
    "df_test['pred_estimator'] = pred_estimator\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning From Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that the ground truth is a complex function of the week day and time of day. That could happen e.g., if you measure the humidity and fail to realize that your sensor is near a dry-cleaner's. Let's assume the dry-cleaner's have peek hours on Mon, Tue, Wed from 18:00h to 21:00 and Fri, Sat from 14:00h to 16:00h. During those hours humidity is significantly higher due to the steam produced there. \n",
    "\n",
    "First, let's create a dataset that reflects that situation. Day of week and hour of day shall be represented by categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a constant, if the hour of week \n",
    "conditions = np.array([\n",
    "    (0, 18), (0, 19), (0, 20), (0, 21), # Mondays\n",
    "    (1, 18), (1, 19), (1, 20), (1, 21), # Tuesdays\n",
    "    (2, 18), (2, 19), (2, 20), (2, 21), # Wednesdays\n",
    "    # closed on Thursdays\n",
    "    (4, 14), (4, 15), (4, 16),          # Fridays\n",
    "    (5, 14), (5, 15), (5, 16)           # Saturdays\n",
    "    # closed on Sundays\n",
    "    ])\n",
    "\n",
    "def make_noisy_amplitude_function(amplitude):\n",
    "    def _f(c1, c2):\n",
    "        zipped = np.array(zip(c1,c2))\n",
    "        res = array_in(zipped, conditions)        \n",
    "        return res * (np.random.normal( 0 * res, .2 ) + amplitude)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v2(size, amplitude=5.0):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    dow_data = np.random.randint(7, size=size)\n",
    "    hod_data = np.random.randint(24, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    \n",
    "    f_special = make_noisy_amplitude_function(amplitude)(dow_data, hod_data)\n",
    "\n",
    "    f_total = f_data + f_special\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'dow': dow_data, 'hod': hod_data, 'f_orig': f_data, 'p': f_perf, 'special': f_special, 'f': f_total})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>f</th>\n",
       "      <th>f_orig</th>\n",
       "      <th>hod</th>\n",
       "      <th>p</th>\n",
       "      <th>special</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.252364</td>\n",
       "      <td>0.252364</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.345822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.926230</td>\n",
       "      <td>-2.013277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2.521157</td>\n",
       "      <td>2.521157</td>\n",
       "      <td>11</td>\n",
       "      <td>1.406787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711581</td>\n",
       "      <td>-0.967250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.463014</td>\n",
       "      <td>-8.351817</td>\n",
       "      <td>19</td>\n",
       "      <td>-7.934377</td>\n",
       "      <td>9.814831</td>\n",
       "      <td>-4.843842</td>\n",
       "      <td>-4.506612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.283874</td>\n",
       "      <td>-0.283874</td>\n",
       "      <td>11</td>\n",
       "      <td>1.098578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.831774</td>\n",
       "      <td>4.129941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>-10.981873</td>\n",
       "      <td>-10.981873</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.504628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.768352</td>\n",
       "      <td>2.935850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.775622</td>\n",
       "      <td>-11.738721</td>\n",
       "      <td>21</td>\n",
       "      <td>-10.923140</td>\n",
       "      <td>9.963099</td>\n",
       "      <td>-4.209076</td>\n",
       "      <td>4.009976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4.818554</td>\n",
       "      <td>4.818554</td>\n",
       "      <td>19</td>\n",
       "      <td>3.351437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939211</td>\n",
       "      <td>0.053969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.686177</td>\n",
       "      <td>-2.686177</td>\n",
       "      <td>18</td>\n",
       "      <td>0.257614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.469166</td>\n",
       "      <td>-3.391890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>-8.646447</td>\n",
       "      <td>-8.646447</td>\n",
       "      <td>10</td>\n",
       "      <td>-10.006795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.894694</td>\n",
       "      <td>3.434814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>16.986018</td>\n",
       "      <td>6.966146</td>\n",
       "      <td>21</td>\n",
       "      <td>6.500303</td>\n",
       "      <td>10.019872</td>\n",
       "      <td>2.704407</td>\n",
       "      <td>-3.182979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.469645</td>\n",
       "      <td>-9.469645</td>\n",
       "      <td>10</td>\n",
       "      <td>-9.000444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.198482</td>\n",
       "      <td>0.206959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1.214982</td>\n",
       "      <td>1.214982</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.761154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.804478</td>\n",
       "      <td>-2.695602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>-8.783446</td>\n",
       "      <td>-8.783446</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.722741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.095472</td>\n",
       "      <td>2.063594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.026726</td>\n",
       "      <td>-2.026726</td>\n",
       "      <td>21</td>\n",
       "      <td>-3.292698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.501329</td>\n",
       "      <td>3.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.658526</td>\n",
       "      <td>-0.658526</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.653062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.014267</td>\n",
       "      <td>-3.750945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>10.468126</td>\n",
       "      <td>0.448018</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.886686</td>\n",
       "      <td>10.020108</td>\n",
       "      <td>-1.823047</td>\n",
       "      <td>-4.518814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>3.473504</td>\n",
       "      <td>3.473504</td>\n",
       "      <td>22</td>\n",
       "      <td>4.450814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.718636</td>\n",
       "      <td>-3.027084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>-11.240266</td>\n",
       "      <td>-11.240266</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.602840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.608280</td>\n",
       "      <td>-2.227442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>-8.837038</td>\n",
       "      <td>-8.837038</td>\n",
       "      <td>14</td>\n",
       "      <td>-9.383164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.808321</td>\n",
       "      <td>-1.466957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>2.367768</td>\n",
       "      <td>2.367768</td>\n",
       "      <td>6</td>\n",
       "      <td>3.378488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.960531</td>\n",
       "      <td>4.085147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dow          f     f_orig  hod          p    special         x         y\n",
       "0     2   0.252364   0.252364   14  -1.345822   0.000000 -0.926230 -2.013277\n",
       "1     6   2.521157   2.521157   11   1.406787   0.000000  0.711581 -0.967250\n",
       "2     0   1.463014  -8.351817   19  -7.934377   9.814831 -4.843842 -4.506612\n",
       "3     1  -0.283874  -0.283874   11   1.098578   0.000000  1.831774  4.129941\n",
       "4     3 -10.981873 -10.981873    9  -7.504628   0.000000 -2.768352  2.935850\n",
       "5     0  -1.775622 -11.738721   21 -10.923140   9.963099 -4.209076  4.009976\n",
       "6     6   4.818554   4.818554   19   3.351437   0.000000  1.939211  0.053969\n",
       "7     4  -2.686177  -2.686177   18   0.257614   0.000000 -0.469166 -3.391890\n",
       "8     1  -8.646447  -8.646447   10 -10.006795   0.000000 -3.894694  3.434814\n",
       "9     2  16.986018   6.966146   21   6.500303  10.019872  2.704407 -3.182979\n",
       "10    2  -9.469645  -9.469645   10  -9.000444   0.000000 -4.198482  0.206959\n",
       "11    2   1.214982   1.214982    7  -0.761154   0.000000 -0.804478 -2.695602\n",
       "12    5  -8.783446  -8.783446   11  -7.722741   0.000000 -3.095472  2.063594\n",
       "13    3  -2.026726  -2.026726   21  -3.292698   0.000000 -0.501329  3.580078\n",
       "14    3  -0.658526  -0.658526    3  -0.653062   0.000000 -1.014267 -3.750945\n",
       "15    0  10.468126   0.448018   21  -1.886686  10.020108 -1.823047 -4.518814\n",
       "16    6   3.473504   3.473504   22   4.450814   0.000000  1.718636 -3.027084\n",
       "17    1 -11.240266 -11.240266    8  -8.602840   0.000000 -4.608280 -2.227442\n",
       "18    6  -8.837038  -8.837038   14  -9.383164   0.000000 -4.808321 -1.466957\n",
       "19    5   2.367768   2.367768    6   3.378488   0.000000  2.960531  4.085147"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v2 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "df_train_v2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we'll try do develop an algorithm that's able to identify this particular pattern. Our assumption that it is particular hours on particular days makes this problem a candidate for the categorical features 'hour of day' and 'day of week'. Hence, in a first step, let's take those two features into account. We begin once more with a self-made algorithm. Below is the code that we hade previously, only this time augmented by the 24 + 7 new input features from the categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the numerical features with the categorical weekdays and hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinals = list(df_train_v2['dow'])\n",
    "one_hot_dows = np.transpose(np.eye(7)[ordinals])\n",
    "one_hot_dows[:7,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = list(df_train_v2['hod'])\n",
    "one_hot_hods = np.transpose(np.eye(24)[ordinals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (2, 1000) + (7, 1000) + (24, 1000) = (33, 1000)\n"
     ]
    }
   ],
   "source": [
    "input_numerical = [list(df_train_v2['x']), list(df_train_v2['y'])]\n",
    "lbls_data = [list(df_train_v2['f'])]\n",
    "input_data = np.append(input_numerical, one_hot_dows, axis=0)\n",
    "input_data = np.append(input_data, one_hot_hods, axis=0)\n",
    "print(\"shapes: {} + {} + {} = {}\".format(np.shape(input_numerical), np.shape(one_hot_dows), np.shape(one_hot_hods), np.shape(input_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create the network and start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_DIM = 2 # namely x and y\n",
    "WEEKDAY_DIM = 7 # obviously\n",
    "HOUR_OF_DAY_DIM = 24\n",
    "X_DIM = NUMERICAL_DIM + WEEKDAY_DIM + HOUR_OF_DAY_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 8.76392936707"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.763929"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear2 = Linear(X_DIM, .01)\n",
    "linear2.train(sess, input_data, lbls_data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That loss is significantly larger than the one that we experienced in the simple case. So either the signal/noise ratio is worse (we know it isn't) or there's some signal in the data that we don't recognize yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Predictions on a large test set to get sufficient statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v2 = create_data_frame_v2(size = 20000, amplitude=10)\n",
    "\n",
    "ordinals = list(df_test_v2['dow'])\n",
    "one_hot_dows = np.transpose(np.eye(7)[ordinals])\n",
    "\n",
    "ordinals = list(df_test_v2['hod'])\n",
    "one_hot_hods = np.transpose(np.eye(24)[ordinals])\n",
    "\n",
    "input_numerical = [list(df_test_v2['x']), list(df_test_v2['y'])]\n",
    "test_data = np.append(input_numerical, one_hot_dows, axis=0)\n",
    "test_data = np.append(test_data, one_hot_hods, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predicted</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.412187</td>\n",
       "      <td>9.135580</td>\n",
       "      <td>10.745915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.634105</td>\n",
       "      <td>-2.188982</td>\n",
       "      <td>-2.473977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.752271</td>\n",
       "      <td>-3.358464</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>9.875978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.873469</td>\n",
       "      <td>1.676607</td>\n",
       "      <td>2.894675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.779717</td>\n",
       "      <td>-5.831125</td>\n",
       "      <td>-6.354161</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.376840</td>\n",
       "      <td>-4.666063</td>\n",
       "      <td>-3.840397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.821125</td>\n",
       "      <td>9.426605</td>\n",
       "      <td>9.424401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.754152</td>\n",
       "      <td>0.392042</td>\n",
       "      <td>0.193839</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-10.724510</td>\n",
       "      <td>-11.780829</td>\n",
       "      <td>-11.405705</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.809926</td>\n",
       "      <td>5.291529</td>\n",
       "      <td>4.997434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p  predicted   special\n",
       "0   7.412187   9.135580  10.745915  0.000000\n",
       "1  -2.634105  -2.188982  -2.473977  0.000000\n",
       "2   5.752271  -3.358464   0.010306  9.875978\n",
       "3   2.873469   1.676607   2.894675  0.000000\n",
       "4  -6.779717  -5.831125  -6.354161  0.000000\n",
       "5  -5.376840  -4.666063  -3.840397  0.000000\n",
       "6  10.821125   9.426605   9.424401  0.000000\n",
       "7   1.754152   0.392042   0.193839  0.000000\n",
       "8 -10.724510 -11.780829 -11.405705  0.000000\n",
       "9   5.809926   5.291529   4.997434  0.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = linear2.predict(x_data=test_data, sess=sess)\n",
    "df_test_v2['predicted'] = pred[0]\n",
    "df_test_v2[['f', 'p', 'predicted', 'special']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEF9JREFUeJzt3XusZWV9xvHvI4iAtaAyoh3QwUq19GKlo6Whlyhab9VBo5TEVkqJY1KstTYpaE0lsW20sSKaljiCDVgtIl6YKrEFvDT9Q3BQIgIaJ4gyI8pouXhH4Nc/9jp4GN45Zx3mrLP22ef7SXbOuu09v9nZZz/nfd+13pWqQpKk3T1o7AIkSdPJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpad+xC9gbhxxySG3YsGHsMiRpVbnqqqu+U1XrFjtuVQfEhg0b2LZt29hlSNKqkuTrfY6zi0mS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktS0qq+klrT3Npz+8XuXb3zz80esRNPGFoQkqcmAkCQ12cUkrUHzu5WkPTEgJDU5NiG7mCRJTQaEJKnJLiZJ93JsQvPZgpAkNdmCkLSoPbUsHLyebbYgJElNBoQkqcmAkCQ1OQYhzTAvdtPesAUhSWoaNCCS/FWSa5N8Kcl/JNk/yRFJrkiyPckHkuzXHfuQbn17t3/DkLVJkhY2WEAkWQ+8GthYVb8K7AOcCLwFOLOqngDcCpzSPeUU4NZu+5ndcZKkkQzdxbQvcECSfYEDgZuBZwAXdfvPA47vljd163T7j0uSgeuTJO3BYAFRVTuBtwLfYBIMtwNXAbdV1V3dYTuA9d3yeuCm7rl3dcc/cqj6JEkLG+wspiQPZ9IqOAK4Dfgg8JxleN3NwGaAxz72sXv7ctKa4TxLWqohu5ieCXytqnZV1U+BDwPHAgd3XU4AhwE7u+WdwOEA3f6DgO/u/qJVtaWqNlbVxnXr1g1YviStbUMGxDeAY5Ic2I0lHAdcB3wKeEl3zEnAxd3y1m6dbv8nq6oGrE+StIAhxyCuYDLY/Hngmu7f2gKcBrw2yXYmYwzndk85F3hkt/21wOlD1SZJWtygV1JX1RuBN+62+QbgaY1jfwy8dMh6JEn9eSW1JKnJgJAkNTlZn6QHzMkAZ5stCElSkwEhSWoyICRJTY5BSDPGKTW0XGxBSJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTU21IWhZO/T17bEFIkpoMCElSk11M0gxwBlcNwRaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpOnuUqrlKe2ami2ICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlq8kI5ScvO24/OBlsQkqSmQQMiycFJLkry5STXJ/ntJI9IcmmSr3Y/H94dmyTvSLI9yReTHD1kbZKkhQ3dgjgL+ERVPQl4MnA9cDpweVUdCVzerQM8Fziye2wGzh64NknSAgYLiCQHAb8HnAtQVXdW1W3AJuC87rDzgOO75U3A+TXxWeDgJI8Zqj5J0sKGbEEcAewC/i3JF5Kck+ShwKFVdXN3zLeAQ7vl9cBN856/o9smSRrBkAGxL3A0cHZVPQX4AT/rTgKgqgqopbxoks1JtiXZtmvXrmUrVpJ0X0MGxA5gR1Vd0a1fxCQwvj3XddT9vKXbvxM4fN7zD+u23UdVbamqjVW1cd26dYMVL0lr3WABUVXfAm5K8sRu03HAdcBW4KRu20nAxd3yVuDl3dlMxwC3z+uKkiStsKEvlPsL4H1J9gNuAE5mEkoXJjkF+DpwQnfsJcDzgO3AD7tjJUkjGTQgqupqYGNj13GNYws4dch6pNXO24xqJXkltSSpyYCQJDUZEJKkpl4BkeTXhi5EkjRd+rYg/jXJlUn+vJtCQ5I043oFRFX9LvAyJheyXZXk/UmeNWhlkqRR9R6DqKqvAm8ATgN+H3hHN433i4cqTpI0nr5jEL+e5Ewm03U/A3hBVf1yt3zmgPVJkkbS90K5dwLnAK+vqh/NbayqbyZ5wyCVSZJG1Tcgng/8qKruBkjyIGD/qvphVb13sOokrXren3r16jsGcRlwwLz1A7ttkqQZ1Tcg9q+q78+tdMsHDlOSJGka9A2IHyQ5em4lyW8CP1rgeEnSKtd3DOI1wAeTfBMI8GjgjwarSpI0ul4BUVWfS/IkYO7mP1+pqp8OV5YkaWxLuR/EU4EN3XOOTkJVnT9IVZKk0fUKiCTvBX4RuBq4u9tcgAEhDcybBGksfVsQG4Gjuru+SZLWgL5nMX2JycC0JGmN6NuCOAS4LsmVwE/mNlbVCwepSpI0ur4BccaQRUhaG3YfT3HqjenW9zTXzyR5HHBkVV2W5EBgn2FLkySNqe90368ALgLe1W1aD3x0qKIkSePrO0h9KnAscAfce/OgRw1VlCRpfH0D4idVdefcSpJ9mVwHIUmaUX0D4jNJXg8c0N2L+oPAfw5XliRpbH0D4nRgF3AN8ErgEib3p5Ykzai+ZzHdA7y7e0iS1oC+czF9jcaYQ1U9ftkrkiRNhaXMxTRnf+ClwCOWvxxJ0rToNQZRVd+d99hZVW8HvARSkmZY3y6mo+etPohJi2Ip95KQJK0yfb/k/3ne8l3AjcAJy16NJMB7QGg69D2L6elDFyJJmi59u5heu9D+qnrb8pQjaS2Z31JyZtfps5SzmJ4KbO3WXwBcCXx1iKIkSePrGxCHAUdX1fcAkpwBfLyq/niowiRJ4+o71cahwJ3z1u/stkmSZlTfgDgfuDLJGV3r4QrgvD5PTLJPki8k+Vi3fkSSK5JsT/KBJPt12x/SrW/v9m9Y8v9GkrRs+l4o9w/AycCt3ePkqvrHnv/GXwLXz1t/C3BmVT2he61Tuu2nALd228/sjpMkjaRvCwLgQOCOqjoL2JHkiMWekOQwJldcn9OtB3gGk7vTwaQVcny3vImftUouAo7rjpckjaDvLUffCJwGvK7b9GDg33s89e3A3wD3dOuPBG6rqru69R1Mbl9K9/MmgG7/7d3xkqQR9G1BvAh4IfADgKr6JvCwhZ6Q5A+BW6rqqr2q8P6vuznJtiTbdu3atZwvLUmap29A3FlVRTfld5KH9njOscALk9wIXMCka+ks4ODulqUwOX12Z7e8Ezi8e/19gYOA7+7+olW1pao2VtXGdevW9SxfkrRUfQPiwiTvYvLl/grgMha5eVBVva6qDquqDcCJwCer6mXAp4CXdIedBFzcLW/t1un2f7ILJUnSCPrOxfTW7l7UdwBPBP6uqi59gP/macAFSf4e+AJwbrf9XOC9SbYD/8ckVKQ1wwn6NG0WDYgk+wCXdRP2PaBQqKpPA5/ulm8AntY45sdMbkQkSZoCi3YxVdXdwD1JDlqBeiRJU6LvXEzfB65JcindmUwAVfXqQaqStOY4s+v06RsQH+4ekqQ1YsGASPLYqvpGVfWad0mSNDsWG4P46NxCkg8NXIskaYosFhDz50J6/JCFSJKmy2IBUXtYliTNuMUGqZ+c5A4mLYkDumW69aqqnx+0OknSaBYMiKraZ6UKkaQ5nvI6HZZyPwhJ0hpiQEiSmgwISVJT3yupJQ3AGVw1zWxBSJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1Od23pKnm7UfHY0BIK8x7QGi1sItJktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUNNiV1EkOB84HDgUK2FJVZyV5BPABYANwI3BCVd2aJMBZwPOAHwJ/WlWfH6o+SauP026srCFbEHcBf11VRwHHAKcmOQo4Hbi8qo4ELu/WAZ4LHNk9NgNnD1ibJGkRgwVEVd081wKoqu8B1wPrgU3Aed1h5wHHd8ubgPNr4rPAwUkeM1R9kqSFrchkfUk2AE8BrgAOraqbu13fYtIFBZPwuGne03Z0225GWuWcoE+r0eCD1El+DvgQ8JqqumP+vqoqJuMTS3m9zUm2Jdm2a9euZaxUkjTfoAGR5MFMwuF9VfXhbvO357qOup+3dNt3AofPe/ph3bb7qKotVbWxqjauW7duuOIlaY0bLCC6s5LOBa6vqrfN27UVOKlbPgm4eN72l2fiGOD2eV1RkqQVNuQYxLHAnwDXJLm62/Z64M3AhUlOAb4OnNDtu4TJKa7bmZzmevKAtUmSFjFYQFTV/wLZw+7jGscXcOpQ9UiSlsYrqSVJTd6TWhqAp7UOz6uqh2cLQpLUZAtC0qpna2IYtiAkSU0GhCSpyYCQJDUZEJKkJgeppWXiqa2aNbYgJElNBoQkqckuJmkv2K2kWWZAaK/s/gXpRUrS7DAgtOK86lVaHRyDkCQ1GRCSpCa7mDQ17HqSposBocHszRk+hoU0PgNCy2qpoeBpolpu/nGxfAwI9eIXuVYjw2LvGBDaI0NBWts8i0mS1GRASJKa7GLSfUxjt9KealrJPmX7srUWGRDSEk1jiGpxhvzSGRBatfyFl4ZlQMi/iCU1OUgtSWqyBSHtgS2r2WX3ZD8GhGbCNJzpJM0aA2IN8S/ixfkerT22JvbMgJhxfuFJeqAMiBlkKEhaDgaEZprdB1oKPy/3ZUBozdjTL78tLrUYFgaE1ihDQVqcF8pJkppsQawydpNIWilTFRBJngOcBewDnFNVbx65pKlmKEga0tQERJJ9gH8BngXsAD6XZGtVXTduZeMzCKRx9blSfxYHtacmIICnAdur6gaAJBcAm4CZCAi7hqTZM+u/v9MUEOuBm+at7wB+a6RaHrA+f0XM+odKWuuW2prY/TthWlog0xQQvSTZDGzuVr+f5Ctj1rOQvGWwlz4E+M5gr756+b7cn+9J24q9Lw/ke2DA7445j+tz0DQFxE7g8Hnrh3Xb7qOqtgBbVqqoaZRkW1VtHLuOaeP7cn++J22+L/1M03UQnwOOTHJEkv2AE4GtI9ckSWvW1LQgququJK8C/ovJaa7vqaprRy5LktasqQkIgKq6BLhk7DpWgTXdxbYA35f78z1p833pIVU1dg2SpCk0TWMQkqQpYkCsEklemuTaJPck2bjbvtcl2Z7kK0mePVaNY0tyRpKdSa7uHs8bu6YxJXlO95nYnuT0seuZFkluTHJN9xnZNnY902yqxiC0oC8BLwbeNX9jkqOYnPH1K8AvAJcl+aWqunvlS5wKZ1bVW8cuYmxOXbOop1eV14cswhbEKlFV11dV66LATcAFVfWTqvoasJ3JtCVa2+6duqaq7gTmpq6RejMgVr/WFCXrR6plGrwqyReTvCfJw8cuZkR+LvasgP9OclU3M4P2wC6mKZLkMuDRjV1/W1UXr3Q902ih9wg4G3gTky+ANwH/DPzZylWnVeJ3qmpnkkcBlyb5clX9z9hFTSMDYopU1TMfwNN6TVEyK/q+R0neDXxs4HKm2Zr6XCxFVe3sft6S5CNMuuMMiAa7mFa/rcCJSR6S5AjgSODKkWsaRZLHzFt9EZOB/bXKqWsakjw0ycPmloE/YG1/ThZkC2KVSPIi4J3AOuDjSa6uqmdX1bVJLmRy34y7gFPX8BlM/5TkN5h0Md0IvHLccsbj1DV7dCjwkSQw+f57f1V9YtySppdXUkuSmuxikiQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnp/wEiVGVKKLP3bgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test_v2['predicted'] - df_test_v2['f']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the error distribution that there's a skew towards larger errors. This is almost certainly a hint that our data contains structure that we didn't discover yet. This distribution is telling: For the majority of the data - the large bump - we have a tendency to over-predict. For some minority though we significantly under-predict. This is a typical sign that the linear regression is finding a weak compromise between two distinct and somehow unrelated distributions that make up our total input data.\n",
    "\n",
    "Obviously, simply adding the categorical features didn't allow the network to learn the specific characteristic, namely the \"and\" relationship like in: \"The humidity is higher, when it's Wednesday *and* it's 18:00h\". Feature crossings and embeddings to the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
