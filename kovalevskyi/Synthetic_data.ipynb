{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Models With Synthetic Data\n",
    "The advantage of synthetic data is that we know the prior or ground truth and we know exactly how concealed it is. That helps us to determine with certainty that an algorithm is per se capable of discovering the ground truth. If an algorithm fails on the easy task of learning from synthetic data, then it won't be good in real life. The opposite, unfortunately, is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "from tools import print_progress, array_in, create_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Noisy Samples From A Well-Known Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a*x+b\n",
    "def make_lin(a, b, rnd):\n",
    "    def _f_a(x):\n",
    "        mu = a*x + b\n",
    "        return rnd(mu)\n",
    "    return _f_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Two linear but noisy signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = make_lin(2, 1, lambda mu: np.random.normal(loc=mu, scale=1.0))\n",
    "f_b = make_lin(-.5, -1.5, lambda mu: np.random.normal(loc=mu, scale=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A look at one of the signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc154e5a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([f_a(1) for i in range(1000)])\n",
    "df.plot.hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we create a data set/frame representing $f_a(x)+f_b(y)$ as a random variable that depends on random variables $x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v1(size):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'f': f_data, 'p': f_perf})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, this is equivalent to saying that the ground truth is:\n",
    "\n",
    "$$ f(x, y) = 2x - \\frac{1}{2} y - \\frac{1}{2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.970338</td>\n",
       "      <td>5.778182</td>\n",
       "      <td>2.782283</td>\n",
       "      <td>-1.427232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.129813</td>\n",
       "      <td>-4.751812</td>\n",
       "      <td>-1.972888</td>\n",
       "      <td>0.612072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.338176</td>\n",
       "      <td>-10.653818</td>\n",
       "      <td>-4.274494</td>\n",
       "      <td>3.209659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.639845</td>\n",
       "      <td>9.255940</td>\n",
       "      <td>4.953560</td>\n",
       "      <td>0.302361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.836743</td>\n",
       "      <td>-3.501605</td>\n",
       "      <td>-1.923769</td>\n",
       "      <td>-1.691864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y\n",
       "0   3.970338   5.778182  2.782283 -1.427232\n",
       "1  -5.129813  -4.751812 -1.972888  0.612072\n",
       "2 -11.338176 -10.653818 -4.274494  3.209659\n",
       "3   7.639845   9.255940  4.953560  0.302361\n",
       "4  -0.836743  -3.501605 -1.923769 -1.691864"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_data_frame_v1(NUM_RECORDS)\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Linear Regressor From Scratch With Tensorflow\n",
    "Let's train a self-made tensorflow linear regressor with the synthetic data to see whether it finds the coefficients above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Was already closed or didn't exist. That's fine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    print(\"OK. Was already closed or didn't exist. That's fine.\")\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating The Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, x_dim, lr):\n",
    "\n",
    "        # Variables for the parameters: weights M and bias b\n",
    "        self.M = tf.Variable(tf.zeros(shape=(1, x_dim)))\n",
    "        self.b = tf.Variable(0.)\n",
    "\n",
    "        # Placeholders for x and labels\n",
    "        self.x = tf.placeholder(shape=(x_dim,None), dtype=tf.float32)\n",
    "        self.lbls = tf.placeholder(shape=(1,None), dtype=tf.float32)\n",
    "\n",
    "        # The prediction and the distance (loss)\n",
    "        self.f = tf.matmul(self.M, self.x) + self.b\n",
    "        self.d = tf.losses.mean_squared_error(self.lbls, self.f)\n",
    "\n",
    "        # The gradients\n",
    "        self.nM = tf.gradients(self.d, self.M)\n",
    "        self.nb = tf.gradients(self.d, self.b)\n",
    "\n",
    "        # The optimizers\n",
    "        self.aM = tf.assign_add( self.M, tf.multiply(self.nM[0],-lr))\n",
    "        self.ab = tf.assign_add( self.b, tf.multiply(self.nb[0], -lr))\n",
    "\n",
    "        # The initializer\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def train(self, sess, x_data, labels_data, num_steps):        \n",
    "        sess.run(self.init)\n",
    "        for i in range(num_steps):\n",
    "            _, dist, _, _, _, _ = sess.run([self.f, self.d, self.nM, self.nb, self.aM, self.ab], \n",
    "                                           feed_dict = {self.x: x_data, self.lbls: labels_data})\n",
    "            print_progress(\"- Loss: {}\", dist)\n",
    "        return dist\n",
    "    \n",
    "    def predict(self, sess, x_data):\n",
    "        pred = sess.run(self.f, feed_dict={self.x: x_data})\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Perform The Training And Examine The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [list(df_train['x']), list(df_train['y'])]\n",
    "lbls_data = [list(df_train['f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.036376476287842"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0363765"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = Linear(x_dim=2, lr=0.01)\n",
    "linear1.train(sess, input_data, lbls_data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the parameters to be close to $2, -0.5, -0.5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9984715, -0.5004317]], dtype=float32), -0.5025198]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([linear1.M, linear1.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now the tensor f represents the hypothesis. Let's evaluate it with some fresh test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = create_data_frame_v1(size=10000)\n",
    "test_data = [list(df_test['x']), list(df_test['y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear1.predict(sess=sess, x_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.018779</td>\n",
       "      <td>-5.170907</td>\n",
       "      <td>-2.480310</td>\n",
       "      <td>-0.579424</td>\n",
       "      <td>-5.169386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.243796</td>\n",
       "      <td>-4.395184</td>\n",
       "      <td>-3.108451</td>\n",
       "      <td>-4.643437</td>\n",
       "      <td>-4.390948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.984971</td>\n",
       "      <td>-3.646574</td>\n",
       "      <td>-1.278153</td>\n",
       "      <td>1.180534</td>\n",
       "      <td>-3.647650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.903392</td>\n",
       "      <td>-2.819337</td>\n",
       "      <td>-0.068276</td>\n",
       "      <td>4.365570</td>\n",
       "      <td>-2.823637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.554818</td>\n",
       "      <td>-8.884180</td>\n",
       "      <td>-3.476079</td>\n",
       "      <td>2.864045</td>\n",
       "      <td>-8.882624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.222886</td>\n",
       "      <td>6.465856</td>\n",
       "      <td>2.546166</td>\n",
       "      <td>-3.747048</td>\n",
       "      <td>6.461062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.829820</td>\n",
       "      <td>0.175177</td>\n",
       "      <td>1.443376</td>\n",
       "      <td>4.423151</td>\n",
       "      <td>0.168541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-12.741029</td>\n",
       "      <td>-11.746977</td>\n",
       "      <td>-4.625421</td>\n",
       "      <td>3.992269</td>\n",
       "      <td>-11.744150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-9.442065</td>\n",
       "      <td>-9.335680</td>\n",
       "      <td>-3.550269</td>\n",
       "      <td>3.470283</td>\n",
       "      <td>-9.334271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3.552182</td>\n",
       "      <td>-2.827383</td>\n",
       "      <td>-0.735511</td>\n",
       "      <td>1.712722</td>\n",
       "      <td>-2.829518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions\n",
       "0  -4.018779  -5.170907 -2.480310 -0.579424    -5.169386\n",
       "1  -4.243796  -4.395184 -3.108451 -4.643437    -4.390948\n",
       "2  -5.984971  -3.646574 -1.278153  1.180534    -3.647650\n",
       "3  -2.903392  -2.819337 -0.068276  4.365570    -2.823637\n",
       "4 -10.554818  -8.884180 -3.476079  2.864045    -8.882624\n",
       "5   4.222886   6.465856  2.546166 -3.747048     6.461062\n",
       "6   1.829820   0.175177  1.443376  4.423151     0.168541\n",
       "7 -12.741029 -11.746977 -4.625421  3.992269   -11.744150\n",
       "8  -9.442065  -9.335680 -3.550269  3.470283    -9.334271\n",
       "9  -3.552182  -2.827383 -0.735511  1.712722    -2.829518"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'] = predictions[0]\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see without surprise that the predictions are typically closer to the ground truth than to the noisy signal. This means we have enough data to average out the noise and reveal the ground truth. A look at the distribution of the errors reveals pure noise around 0. That's typically a good sign that our network has understood the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc150057a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test['f'] - df_test['predictions']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensorflow LinearRegressor Estimator\n",
    "Now we'll reproduce this with the high-level estimator API. Surprisingly, the calculations here take much longer than in the basic approach above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(df_train, shuffle=True, num_epochs=100, y=df_train['f'], batch_size=NUM_RECORDS)\n",
    "feature_columns = [\n",
    "    fc.numeric_column('x', dtype=tf.float32),\n",
    "    fc.numeric_column('y', dtype=tf.float32)\n",
    "]\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1_0v5bsq\n",
      "INFO:tensorflow:Using config: {'_is_chief': True, '_task_id': 0, '_protocol': None, '_train_distribute': None, '_model_dir': '/tmp/tmp1_0v5bsq', '_num_ps_replicas': 0, '_save_summary_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_service': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_eval_distribute': None, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_experimental_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc1484f9eb8>, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_worker_replicas': 1, '_evaluation_master': '', '_log_step_count_steps': 5, '_device_fn': None, '_keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor( feature_columns=feature_columns, config=config )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Perform the training on the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp1_0v5bsq/model.ckpt.\n",
      "INFO:tensorflow:loss = 376386.75, step = 0\n",
      "INFO:tensorflow:global_step/sec: 15.5951\n",
      "INFO:tensorflow:loss = 182129.66, step = 5 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5254\n",
      "INFO:tensorflow:loss = 122119.945, step = 10 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0751\n",
      "INFO:tensorflow:loss = 88577.195, step = 15 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4599\n",
      "INFO:tensorflow:loss = 67258.805, step = 20 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8035\n",
      "INFO:tensorflow:loss = 53325.707, step = 25 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5465\n",
      "INFO:tensorflow:loss = 43844.195, step = 30 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7049\n",
      "INFO:tensorflow:loss = 37142.934, step = 35 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8777\n",
      "INFO:tensorflow:loss = 32354.453, step = 40 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3943\n",
      "INFO:tensorflow:loss = 28956.66, step = 45 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8431\n",
      "INFO:tensorflow:loss = 26568.438, step = 50 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7628\n",
      "INFO:tensorflow:loss = 24904.014, step = 55 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5776\n",
      "INFO:tensorflow:loss = 23581.398, step = 60 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9787\n",
      "INFO:tensorflow:loss = 22728.766, step = 65 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0522\n",
      "INFO:tensorflow:loss = 22120.584, step = 70 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8831\n",
      "INFO:tensorflow:loss = 21576.305, step = 75 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0317\n",
      "INFO:tensorflow:loss = 21262.977, step = 80 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7861\n",
      "INFO:tensorflow:loss = 21079.484, step = 85 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.004\n",
      "INFO:tensorflow:loss = 20772.031, step = 90 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0043\n",
      "INFO:tensorflow:loss = 20690.297, step = 95 (0.250 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmp1_0v5bsq/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20634.871.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7fc1485735c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.train(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparing The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn_test = tf.estimator.inputs.pandas_input_fn(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = regressor.predict(input_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp1_0v5bsq/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pred_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.018779</td>\n",
       "      <td>-5.170907</td>\n",
       "      <td>-2.480310</td>\n",
       "      <td>-0.579424</td>\n",
       "      <td>-5.169386</td>\n",
       "      <td>-5.037508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.243796</td>\n",
       "      <td>-4.395184</td>\n",
       "      <td>-3.108451</td>\n",
       "      <td>-4.643437</td>\n",
       "      <td>-4.390948</td>\n",
       "      <td>-4.226859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.984971</td>\n",
       "      <td>-3.646574</td>\n",
       "      <td>-1.278153</td>\n",
       "      <td>1.180534</td>\n",
       "      <td>-3.647650</td>\n",
       "      <td>-3.580405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.903392</td>\n",
       "      <td>-2.819337</td>\n",
       "      <td>-0.068276</td>\n",
       "      <td>4.365570</td>\n",
       "      <td>-2.823637</td>\n",
       "      <td>-2.820740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.554818</td>\n",
       "      <td>-8.884180</td>\n",
       "      <td>-3.476079</td>\n",
       "      <td>2.864045</td>\n",
       "      <td>-8.882624</td>\n",
       "      <td>-8.694776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.222886</td>\n",
       "      <td>6.465856</td>\n",
       "      <td>2.546166</td>\n",
       "      <td>-3.747048</td>\n",
       "      <td>6.461062</td>\n",
       "      <td>6.317466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.829820</td>\n",
       "      <td>0.175177</td>\n",
       "      <td>1.443376</td>\n",
       "      <td>4.423151</td>\n",
       "      <td>0.168541</td>\n",
       "      <td>0.089094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-12.741029</td>\n",
       "      <td>-11.746977</td>\n",
       "      <td>-4.625421</td>\n",
       "      <td>3.992269</td>\n",
       "      <td>-11.744150</td>\n",
       "      <td>-11.493112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-9.442065</td>\n",
       "      <td>-9.335680</td>\n",
       "      <td>-3.550269</td>\n",
       "      <td>3.470283</td>\n",
       "      <td>-9.334271</td>\n",
       "      <td>-9.142079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3.552182</td>\n",
       "      <td>-2.827383</td>\n",
       "      <td>-0.735511</td>\n",
       "      <td>1.712722</td>\n",
       "      <td>-2.829518</td>\n",
       "      <td>-2.791579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f          p         x         y  predictions  pred_estimator\n",
       "0  -4.018779  -5.170907 -2.480310 -0.579424    -5.169386       -5.037508\n",
       "1  -4.243796  -4.395184 -3.108451 -4.643437    -4.390948       -4.226859\n",
       "2  -5.984971  -3.646574 -1.278153  1.180534    -3.647650       -3.580405\n",
       "3  -2.903392  -2.819337 -0.068276  4.365570    -2.823637       -2.820740\n",
       "4 -10.554818  -8.884180 -3.476079  2.864045    -8.882624       -8.694776\n",
       "5   4.222886   6.465856  2.546166 -3.747048     6.461062        6.317466\n",
       "6   1.829820   0.175177  1.443376  4.423151     0.168541        0.089094\n",
       "7 -12.741029 -11.746977 -4.625421  3.992269   -11.744150      -11.493112\n",
       "8  -9.442065  -9.335680 -3.550269  3.470283    -9.334271       -9.142079\n",
       "9  -3.552182  -2.827383 -0.735511  1.712722    -2.829518       -2.791579"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_estimator = [f['predictions'][0] for f in generator]\n",
    "df_test['pred_estimator'] = pred_estimator\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pre-canned estimator arrives at (almost) the same results as our hand-made linear regressor. Not that we had a doubt, though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning From Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assume that the ground truth is a totally unexpected function of the week day and time of day. That could happen e.g., if you measure the humidity and fail to realize that your sensor is near a dry-cleaner's. Let's assume the dry-cleaner's have peek hours on Mon, Tue, Wed from 18:00h to 21:00 and Fri, Sat from 14:00h to 16:00h. During those hours humidity is significantly higher due to the steam produced there. \n",
    "\n",
    "First, let's create a dataset that reflects that situation. Day of week and hour of day shall be represented by categorical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe with days of week and hour-of-day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function of x that returns random samples around a constant, if the hour of week \n",
    "conditions = np.array([\n",
    "    (0, 18), (0, 19), (0, 20), (0, 21), # Mondays\n",
    "    (1, 18), (1, 19), (1, 20), (1, 21), # Tuesdays\n",
    "    (2, 18), (2, 19), (2, 20), (2, 21), # Wednesdays\n",
    "    # closed on Thursdays\n",
    "    (4, 14), (4, 15), (4, 16),          # Fridays\n",
    "    (5, 14), (5, 15), (5, 16)           # Saturdays\n",
    "    # closed on Sundays\n",
    "    ])\n",
    "\n",
    "def make_noisy_amplitude_function(amplitude):\n",
    "    def _f(c1, c2):\n",
    "        zipped = zip(c1,c2)\n",
    "        res = array_in(zipped, conditions)        \n",
    "        return res * (np.random.normal( 0 * res, .2 ) + amplitude)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_v2(size, amplitude=5.0):\n",
    "    x_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    y_data = np.random.uniform(high=5, low=-5, size=size)\n",
    "    dow_data = np.random.randint(7, size=size)\n",
    "    hod_data = np.random.randint(24, size=size)\n",
    "    f_data = f_a(x_data) + f_b(y_data)\n",
    "    \n",
    "    f_special = make_noisy_amplitude_function(amplitude)(dow_data, hod_data)\n",
    "\n",
    "    f_total = f_data + f_special\n",
    "    f_perf = -.5 * y_data - 1.5 + 2 * x_data + 1\n",
    "    df = pd.DataFrame({'x': x_data, 'y': y_data, 'dow': dow_data, 'hod': hod_data, 'f_orig': f_data, 'p': f_perf, 'special': f_special, 'f': f_total})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>f</th>\n",
       "      <th>f_orig</th>\n",
       "      <th>hod</th>\n",
       "      <th>p</th>\n",
       "      <th>special</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.623160</td>\n",
       "      <td>2.623160</td>\n",
       "      <td>14</td>\n",
       "      <td>3.707175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.334754</td>\n",
       "      <td>0.924666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-7.738056</td>\n",
       "      <td>-7.738056</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.932339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.998904</td>\n",
       "      <td>0.869061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-5.412227</td>\n",
       "      <td>-5.412227</td>\n",
       "      <td>16</td>\n",
       "      <td>-2.943108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.367813</td>\n",
       "      <td>-0.585037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6.976065</td>\n",
       "      <td>6.976065</td>\n",
       "      <td>6</td>\n",
       "      <td>4.723307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.371272</td>\n",
       "      <td>3.038475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.422939</td>\n",
       "      <td>-0.422939</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.453791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.929382</td>\n",
       "      <td>-3.809946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.978455</td>\n",
       "      <td>0.978455</td>\n",
       "      <td>6</td>\n",
       "      <td>0.050830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.164551</td>\n",
       "      <td>-1.759865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>6.639236</td>\n",
       "      <td>6.639236</td>\n",
       "      <td>3</td>\n",
       "      <td>5.847419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.353026</td>\n",
       "      <td>4.717266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>5.224704</td>\n",
       "      <td>5.224704</td>\n",
       "      <td>7</td>\n",
       "      <td>5.139870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.927844</td>\n",
       "      <td>0.431637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.164713</td>\n",
       "      <td>-5.164713</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.621998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.523865</td>\n",
       "      <td>-3.851466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>-5.362787</td>\n",
       "      <td>-5.362787</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.322708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.119103</td>\n",
       "      <td>-0.830995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.903042</td>\n",
       "      <td>-0.903042</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.323034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.346279</td>\n",
       "      <td>-1.739048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>8.153559</td>\n",
       "      <td>8.153559</td>\n",
       "      <td>2</td>\n",
       "      <td>9.565386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.719006</td>\n",
       "      <td>-1.254748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>7.072501</td>\n",
       "      <td>-2.966765</td>\n",
       "      <td>15</td>\n",
       "      <td>-5.093116</td>\n",
       "      <td>10.039265</td>\n",
       "      <td>-3.130059</td>\n",
       "      <td>-3.334004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.997744</td>\n",
       "      <td>-3.997744</td>\n",
       "      <td>10</td>\n",
       "      <td>-4.316687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.827828</td>\n",
       "      <td>0.322061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>18.679755</td>\n",
       "      <td>8.610573</td>\n",
       "      <td>21</td>\n",
       "      <td>7.319883</td>\n",
       "      <td>10.069182</td>\n",
       "      <td>4.182971</td>\n",
       "      <td>1.092118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>-4.408151</td>\n",
       "      <td>-4.408151</td>\n",
       "      <td>22</td>\n",
       "      <td>-3.259227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.513806</td>\n",
       "      <td>-4.536769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>8.127995</td>\n",
       "      <td>8.127995</td>\n",
       "      <td>10</td>\n",
       "      <td>7.941987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.738702</td>\n",
       "      <td>2.070832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>9.714008</td>\n",
       "      <td>9.714008</td>\n",
       "      <td>14</td>\n",
       "      <td>8.732001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.964324</td>\n",
       "      <td>-2.606707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>6.046523</td>\n",
       "      <td>6.046523</td>\n",
       "      <td>6</td>\n",
       "      <td>4.318532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.072575</td>\n",
       "      <td>-1.346764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>11.784260</td>\n",
       "      <td>1.740800</td>\n",
       "      <td>20</td>\n",
       "      <td>1.419518</td>\n",
       "      <td>10.043461</td>\n",
       "      <td>1.233262</td>\n",
       "      <td>1.094014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dow          f    f_orig  hod         p    special         x         y\n",
       "0     1   2.623160  2.623160   14  3.707175   0.000000  2.334754  0.924666\n",
       "1     3  -7.738056 -7.738056   11 -6.932339   0.000000 -2.998904  0.869061\n",
       "2     2  -5.412227 -5.412227   16 -2.943108   0.000000 -1.367813 -0.585037\n",
       "3     2   6.976065  6.976065    6  4.723307   0.000000  3.371272  3.038475\n",
       "4     0  -0.422939 -0.422939   23 -0.453791   0.000000 -0.929382 -3.809946\n",
       "5     2   0.978455  0.978455    6  0.050830   0.000000 -0.164551 -1.759865\n",
       "6     2   6.639236  6.639236    3  5.847419   0.000000  4.353026  4.717266\n",
       "7     6   5.224704  5.224704    7  5.139870   0.000000  2.927844  0.431637\n",
       "8     0  -5.164713 -5.164713    4 -5.621998   0.000000 -3.523865 -3.851466\n",
       "9     3  -5.362787 -5.362787    9 -6.322708   0.000000 -3.119103 -0.830995\n",
       "10    3  -0.903042 -0.903042   11 -0.323034   0.000000 -0.346279 -1.739048\n",
       "11    2   8.153559  8.153559    2  9.565386   0.000000  4.719006 -1.254748\n",
       "12    5   7.072501 -2.966765   15 -5.093116  10.039265 -3.130059 -3.334004\n",
       "13    0  -3.997744 -3.997744   10 -4.316687   0.000000 -1.827828  0.322061\n",
       "14    0  18.679755  8.610573   21  7.319883  10.069182  4.182971  1.092118\n",
       "15    3  -4.408151 -4.408151   22 -3.259227   0.000000 -2.513806 -4.536769\n",
       "16    0   8.127995  8.127995   10  7.941987   0.000000  4.738702  2.070832\n",
       "17    3   9.714008  9.714008   14  8.732001   0.000000  3.964324 -2.606707\n",
       "18    1   6.046523  6.046523    6  4.318532   0.000000  2.072575 -1.346764\n",
       "19    0  11.784260  1.740800   20  1.419518  10.043461  1.233262  1.094014"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v2 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "df_train_v2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create a data set suitable for training\n",
    "In the following, our assumption that it is particular hours on particular days makes this problem a candidate for the categorical features 'hour of day' and 'day of week'. Hence, in a first step, let's take those two features into account. For that, we have to one-hot encode those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinals = list(df_train_v2['dow'])\n",
    "one_hot_dows = np.transpose(np.eye(7)[ordinals])\n",
    "one_hot_dows[:7,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = list(df_train_v2['hod'])\n",
    "one_hot_hods = np.transpose(np.eye(24)[ordinals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (2, 20000) + (7, 20000) + (24, 20000) = (33, 20000)\n"
     ]
    }
   ],
   "source": [
    "input_numerical = [list(df_train_v2['x']), list(df_train_v2['y'])]\n",
    "lbls_data = [list(df_train_v2['f'])]\n",
    "input_data = np.append(input_numerical, one_hot_dows, axis=0)\n",
    "input_data = np.append(input_data, one_hot_hods, axis=0)\n",
    "print(\"shapes: {} + {} + {} = {}\".format(np.shape(input_numerical), np.shape(one_hot_dows), np.shape(one_hot_hods), np.shape(input_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 33 columns, 31 of which only sparsely populated. That's ok for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.33475424, -2.99890442, -1.36781304,  3.3712725 ],\n",
       "       [ 0.92466645,  0.86906099, -0.58503708,  3.03847542],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  1.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hereafter, we'll use create_input_data from the tools file to achieve just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def create_input_data(df, select_feats=[], oh_feats={}, cross_feats=[]):    \n",
      "    \"\"\"\n",
      "    create a list of input columns from pandas raw data\n",
      "    df: a pandas dataframe containing raw input data\n",
      "    select_feats: an array containing the names of features to be selected without transformation\n",
      "    oh_feats: a dictionary containing the names and sizes of discrete numerical features that are to be one-hot encoded\n",
      "    cross_feats: a list of oh_feats consisting of two discrete features to cross\n",
      "    \"\"\"\n",
      "\n",
      "    def _safe_append(l, r):\n",
      "        if l == [] or l is None:\n",
      "            return r\n",
      "        else:\n",
      "            return np.append(l, r, axis=0)\n",
      "\n",
      "    res = [list(df[n]) for n in select_feats]\n",
      "    \n",
      "    for k in oh_feats:\n",
      "        res = _safe_append(res, one_hot(df[k], oh_feats[k]))\n",
      "\n",
      "    for c in cross_feats:\n",
      "        keys = list(c.keys())\n",
      "        keys.sort()\n",
      "        \n",
      "        lk, ls = keys[0], c[keys[0]]\n",
      "        rk, rs = keys[1], c[keys[1]]\n",
      "        lhs = one_hot(df[lk], ls)\n",
      "        rhs = one_hot(df[rk], rs)\n",
      "        cross = [(lhs[:,i].reshape(ls,1) * rhs[:,i].reshape(1,rs)).reshape(rs*ls) for i in range(len(df))]\n",
      "        cross = np.transpose(cross)\n",
      "        res = _safe_append(res, cross)\n",
      "\n",
      "    return res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(create_input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create the network and start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use once more our self-made linear regressor. Below is the code that we hade previously, only this time augmented by the 24 + 7 new input features from the categorical columns. Observe that we train a long time with a lot more data, and the training loss still doesn't improve much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_DIM = 2 # namely x and y\n",
    "WEEKDAY_DIM = 7 # obviously\n",
    "HOUR_OF_DAY_DIM = 24\n",
    "X_DIM = NUMERICAL_DIM + WEEKDAY_DIM + HOUR_OF_DAY_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 8.168704986572266"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.168705"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear2 = Linear(X_DIM, .01)\n",
    "linear2.train(sess, input_data, lbls_data, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That loss is significantly larger than the one that we experienced in the simple case. So either the signal/noise ratio is worse (we know it isn't) or there's some signal in the data that we don't recognize yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sometimes the distribution of the prediction errors reveals additional facts of the problems that our network has. Usually we'll need large enough samples to allow for sufficient statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>predicted</th>\n",
       "      <th>special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.885633</td>\n",
       "      <td>7.407261</td>\n",
       "      <td>7.683997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.649635</td>\n",
       "      <td>0.875752</td>\n",
       "      <td>-0.217967</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.843319</td>\n",
       "      <td>2.470205</td>\n",
       "      <td>3.217860</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.663954</td>\n",
       "      <td>2.903841</td>\n",
       "      <td>3.460528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.265493</td>\n",
       "      <td>6.178854</td>\n",
       "      <td>9.367396</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-8.369458</td>\n",
       "      <td>-8.028739</td>\n",
       "      <td>-7.299976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.395462</td>\n",
       "      <td>9.504584</td>\n",
       "      <td>8.363781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.888909</td>\n",
       "      <td>6.983145</td>\n",
       "      <td>7.216205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.535154</td>\n",
       "      <td>1.950408</td>\n",
       "      <td>0.855240</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.707397</td>\n",
       "      <td>-3.214684</td>\n",
       "      <td>1.280937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f         p  predicted  special\n",
       "0   5.885633  7.407261   7.683997      0.0\n",
       "1   2.649635  0.875752  -0.217967      0.0\n",
       "2   2.843319  2.470205   3.217860      0.0\n",
       "3   1.663954  2.903841   3.460528      0.0\n",
       "4   6.265493  6.178854   9.367396      0.0\n",
       "5  -8.369458 -8.028739  -7.299976      0.0\n",
       "6  12.395462  9.504584   8.363781      0.0\n",
       "7   5.888909  6.983145   7.216205      0.0\n",
       "8   2.535154  1.950408   0.855240      0.0\n",
       "9  -1.707397 -3.214684   1.280937      0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_v2 = create_data_frame_v2(size = 20000, amplitude=10)\n",
    "test_data = create_input_data(df=df_test_v2, select_feats=['x','y'], oh_feats={'dow': 7, 'hod': 24})\n",
    "\n",
    "pred = linear2.predict(x_data=test_data, sess=sess)\n",
    "df_test_v2['predicted'] = pred[0]\n",
    "df_test_v2[['f', 'p', 'predicted', 'special']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1487da5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_errors = df_test_v2['predicted'] - df_test_v2['f']\n",
    "df_errors.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the error distribution that there's some really interesting stuff going on. This is almost certainly a hint that our data contains structure that we didn't discover yet. This distribution is telling: For the majority of the data - the large bump - we have a tendency to over-predict. For some minority though we significantly under-predict. This is a typical sign that the linear regression is finding a weak compromise between two distinct and somehow unrelated distributions that make up our total input data.\n",
    "\n",
    "Obviously, although or network actually had all the information it needed, simply adding the categorical features didn't allow it to learn the specific characteristic, namely the \"and\" relationship like in: \"The humidity is higher, when it's Wednesday *and* it's 18:00h\". \n",
    "\n",
    "Feature crossings and embeddings to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example: This is Wednesday, 08:00h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday = np.array([[0,0,1,0,0,0,0]])\n",
    "at_0800 = np.zeros((1,24))\n",
    "at_0800[0,8] = 1\n",
    "wednesday, at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossing categorical features $a$ and $b$ means: Put a 1 only where both $a$ and $b$ have a one. Put zeros anywhere else. Python broadcasting helps us achieve that with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wednesday_at_0800 = wednesday.T * at_0800\n",
    "wednesday_at_0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = np.reshape(wednesday_at_0800, newshape=(1,-1))\n",
    "np.argmax(cross) == 2 * 24 + 8 # Wed * 24 + at_0800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets a little more involved when dealing with a batch of feature pairs as you can see in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dows = np.array([[0,0,1,0,0,0,0],[0,0,0,0,0,1,0]])\n",
    "hods = np.zeros((2,24))\n",
    "hods[0,8] = 1\n",
    "hods[1,16] = 1\n",
    "dows, hods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(dows[i].reshape(7,1) * hods[i].reshape(1,24)).reshape(168) for i in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now, instead of feeding both features independently we feed the feature cross into our linear regression model. Note that we need a lot of data to have sufficient statistics for each hour of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 20000), 20000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_RECORDS = 20000\n",
    "\n",
    "df_train_v3 = create_data_frame_v2(size = NUM_RECORDS, amplitude=10.0)\n",
    "input_data_v3 = create_input_data(df=df_train_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "lbls_data_v3 = [list(df_train_v3['f'])]\n",
    "input_data_v3.shape, len(lbls_data_v3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loss: 2.0821192264556885"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0821192"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_v3 = Linear(lr=.05, x_dim=170)\n",
    "regressor_v3.train(sess=sess, num_steps=4000, x_data=input_data_v3, labels_data=lbls_data_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can see that the loss function has indeed gone down dramatically. Now let's examine the error statistics on some fresh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc148732160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_v3 = create_data_frame_v2(size = 20000, amplitude=10.0)\n",
    "input_data_test_v3 = create_input_data(df=df_test_v3, select_feats=['x', 'y'], cross_feats=[{'dow': 7, 'hod': 24}])    \n",
    "preds = regressor_v3.predict(sess=sess, x_data=input_data_test_v3)\n",
    "\n",
    "errors = preds[0] - df_test_v3['f']\n",
    "df_test_v3['preds'] = preds[0]\n",
    "df_test_v3['err'] = errors\n",
    "df_test_v3['err'].plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, there's some subtle asymmetry in the error distribution, depending on how long you trained, but we can see that the characteristic second bump has disappeared. When we look at the weights associated with the 168 different hours of a week, we spot a few larger positive values amongst otherwise smaller negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9416599 , -1.150707  , -1.024278  , -1.0384841 , -1.1588407 ,\n",
       "       -1.0064317 , -0.93671495, -1.0196651 , -0.78946966, -0.95432585,\n",
       "       -1.1265155 , -1.0827231 , -0.73885965, -0.84872276, -0.92836607,\n",
       "       -0.7366344 , -0.7304884 , -1.0132955 ,  7.9361215 ,  7.74829   ,\n",
       "        8.009253  ,  8.592185  , -0.8758608 , -0.9945748 , -0.888224  ,\n",
       "       -1.2976695 , -1.0797281 , -1.1520555 , -0.87807256, -0.97681385,\n",
       "       -0.87708586, -1.0517477 , -1.0153389 , -0.80801725, -0.89689183,\n",
       "       -1.0086497 , -1.003182  , -1.0935588 , -1.0512513 , -0.9731082 ,\n",
       "       -0.9221308 , -0.92308474,  8.495395  ,  8.209105  ,  8.163413  ,\n",
       "        8.240393  , -0.9263163 , -0.90685296, -0.9658931 , -1.0083321 ,\n",
       "       -0.91035193, -0.9704872 , -1.0132937 , -1.1665287 , -1.1947752 ,\n",
       "       -1.1297113 , -1.0561062 , -1.0329889 , -1.0642911 , -0.94757056,\n",
       "       -1.0153666 , -0.92868847, -1.0030642 , -1.1371716 , -1.029838  ,\n",
       "       -0.9350208 ,  8.2024765 ,  7.7710714 ,  7.9357886 ,  8.123897  ,\n",
       "       -1.062589  , -1.0641683 , -1.0697305 , -0.6173869 , -0.742169  ,\n",
       "       -0.9657745 , -0.8156351 , -0.9041509 , -0.82496434, -1.0422816 ,\n",
       "       -0.89888227, -1.2378275 , -0.83366084, -1.2276196 , -0.9677848 ,\n",
       "       -0.97023904, -1.0752797 , -1.2112259 , -1.0797296 , -0.79276586,\n",
       "       -1.0479704 , -0.9545672 , -0.9005994 , -0.7946087 , -1.005834  ,\n",
       "       -1.024833  , -0.93535316, -1.0842824 , -1.0613711 , -0.9982034 ,\n",
       "       -1.15665   , -1.1786919 , -1.0443697 , -0.9711858 , -0.9861032 ,\n",
       "       -1.0251853 , -0.9254046 , -0.90175647, -0.9449173 , -0.9752675 ,\n",
       "        8.193852  ,  7.6886272 ,  8.006938  , -1.0852268 , -1.0487133 ,\n",
       "       -0.8559047 , -0.9384403 , -0.82413554, -0.9511769 , -0.76428884,\n",
       "       -0.9411708 , -0.7558975 , -0.8737115 , -0.9075669 , -1.0691164 ,\n",
       "       -0.9804275 , -0.8821377 , -0.8897945 , -1.0005169 , -0.8668204 ,\n",
       "       -1.0249127 , -0.88479644, -1.017101  , -1.098112  ,  8.43681   ,\n",
       "        8.170056  ,  8.39657   , -1.0179813 , -0.8566074 , -0.9859253 ,\n",
       "       -1.0304973 , -0.87790185, -1.027801  , -0.5832909 , -1.0316529 ,\n",
       "       -0.9436239 , -0.8542041 , -0.77566725, -0.96353924, -0.9529057 ,\n",
       "       -0.96740144, -1.1606034 , -1.0250174 , -0.9772049 , -1.0226192 ,\n",
       "       -1.0516796 , -1.038147  , -0.8745232 , -1.0117068 , -1.1203015 ,\n",
       "       -0.89784205, -1.0123343 , -0.9733709 , -0.8233906 , -0.8227691 ,\n",
       "       -0.8031704 , -0.9486472 , -1.0014557 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = regressor_v3.M.eval()\n",
    "weights_t = weights.squeeze()[2:]\n",
    "weights_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes of the larger values allow us to discover exactly those hours of week during which the dry-cleaner anomalies are observed. The network truly learned when these anomalies are typically observed and adds some more humidity in its prediction during those times of the week. Ain't that cool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 18), array([ 0, 18])),\n",
       " ((0, 19), array([ 0, 19])),\n",
       " ((0, 20), array([ 0, 20])),\n",
       " ((0, 21), array([ 0, 21])),\n",
       " ((1, 18), array([ 1, 18])),\n",
       " ((1, 19), array([ 1, 19])),\n",
       " ((1, 20), array([ 1, 20])),\n",
       " ((1, 21), array([ 1, 21])),\n",
       " ((2, 18), array([ 2, 18])),\n",
       " ((2, 19), array([ 2, 19])),\n",
       " ((2, 20), array([ 2, 20])),\n",
       " ((2, 21), array([ 2, 21])),\n",
       " ((4, 14), array([ 4, 14])),\n",
       " ((4, 15), array([ 4, 15])),\n",
       " ((4, 16), array([ 4, 16])),\n",
       " ((5, 14), array([ 5, 14])),\n",
       " ((5, 15), array([ 5, 15])),\n",
       " ((5, 16), array([ 5, 16]))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [i for i in range(168) if weights_t[i] > 1]\n",
    "how_detected = [(i // 24, i % 24 ) for i in indexes]\n",
    "how_detected = sorted(how_detected, key=lambda d: d[0])\n",
    "list(zip(how_detected, conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the left, the hours of the week as detected by the network, to the left the conditions that lead to the anomalies in the data. A perfect fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
